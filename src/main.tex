\documentclass[a4paper, 12pt]{report}

\input{prelude.tex}

\title{{\Huge Analisi 3}\\{\small Appunti di Analisi 3 del corso di Giovanni Alberti e Maria Stella Gelli}}
\author{Arianna Carelli e Antonio De Lucreziis}
\date{I Semestre 2021/2021}

\begin{document}

%
% Removes initial indentation from paragraphs.
%
\parskip 1ex
\setlength{\parindent}{0pt}

% Initial page
\maketitle

% Table of contents
\tableofcontents
\newpage

\chapter{Teoria della misura}

\section{Misure astratte}

\textbf{Definizione.} 
Uno spazio misurabile è una terna $(X, \mc A, \mu)$ tale che
\begin{itemize}
	
	\item $X$ è un insieme qualunque.

	\item $\mc{A}$ è una $\sigma$-algebra di sottoinsiemi di $X$, ovvero una famiglia di sottoinsiemi di $X$ che rispetta le seguenti proprietà:
		\begin{itemize}
			\item $\emptyset, X \in \mc{A}$.
			\item $\mc{A}$ è chiusa per complementare, unione e intersezione numerabile.
		\end{itemize}
	
	\item $\mu$ è una misura su $X$, ossia una funzione $\mu \colon \mc A \to [0, +\infty]$ $\sigma$-addittiva, cioè tale che data una famiglia numerabile $\left\{ E_k \right\} \subset \mc A$ disgiunta e posto $E \coloneqq \bigcup E_n $, allora
		$$
		\mu(E) = \sum_{n} \mu (E_n).
		$$

\end{itemize}


\textbf{Notazione.}
Data una crescente di insiemi $E_1 \subset E_2 \subset \cdots E_n \subset \cdots$ con $\bigcup E_n = E$, scriviamo $E_n \uparrow E$.

\textbf{Proprietà.}
\begin{itemize}
	\item $\mu(\emptyset) = 0$
	\item \textit{Monotonia}: Dati $E,E' \in \mc{A}$ e $E \subset E'$, allora $\mu(E) \leq \mu(E')$.
	\item Data una successione crescente di insiemi $E_n \uparrow E$, allora $\mu(E) = \lim_{n \to \infty} \mu(E_n) = \sup_{n} \mu(E_n)$.
	\item Se $E_n \uparrow E$ e $\mu (E_{\bar{n}}) < +\infty$ per qualche $\bar{n}$, allora $\mu(E) = \lim_{n \to + \infty} \mu(E_n) = \inf_{n} \mu(E_n)$.
	\item \textit{Subadditività}: Se $\bigcup E_n \supset E$, allora $\mu(E) \leq \sum_{n} \mu(E_n)$.
\end{itemize}

\textbf{Osservazione.} 
Dato $X' \in \mc A$ si possono restringere $\mc A$ e $\mu$ a $X'$ nel modo ovvio.

\textbf{Definizioni}.
\begin{itemize}
	\item $\mu$ si dice \textbf{completa} se $F \subset E, E \in \mc{A}$ e $\mu(E) = 0$, allora $F \in \mc{A}$ (e di conseguenza $\mu(F) = 0$).
	\item $\mu$ si dice \textbf{finita} se $\mu(X) < + \infty$.
	\item $\mu$ si dice \textbf{$\sigma$-finita} se esiste una successione $\{ E_n \}$ con $E_n \subset E_{n+1}$ tale che $\bigcup E_n = X$ con $\mu(E_n) < +\infty$ per ogni $n$.
\end{itemize}

\textbf{Notazione.}
Sia $P(X)$ un predicato che dipende da $x \in X$ allora si dice che \textbf{$P(X)$ vale $\mu$-quasi ogni $x \in X$} se l'insieme $\left\{ x \mid P(x) \text{ è falso}  \right\}$ è (contenuto in) un insieme di misura $\mu$ nulla.

D'ora in poi consideriamo solo misure complete.

\section{Esempi di misure}

\begin{itemize}
	
	\item \textbf{Misura che conta i punti.}
		$$
		X \text{ insieme}
		\qquad
		\mc A \coloneqq \mc P(X)
		\qquad
		\mu(E) \coloneqq \# E \in \N \cup \left\{ +\infty \right\}
		$$

	\item \textbf{Delta di Dirac in $x_0$.}
		$$
		X \text{ insieme, } x_0 \in X \text{ fissato}
		\qquad
		\mc A \coloneqq \mc P(X)
		\qquad
		\mu(E) \coloneqq \delta_{x_0}(E) = \One_E (x_0)
		$$

	\item \textbf{Misura di Lebesgue.}
		$$
		X = \R^n
		\qquad
		\mc{M}^n \text{ $\sigma$-algebra dei misurabili secondo Lebesgue}
		\qquad
		\mathscr L^n \text{ misura di Lebesgue}
		$$
		Dato $R$ parallelepipedo in $\R^n$, cioè $R = \prod_{k=1}^{n} I_k $ con $I_k$ intervalli in $\R$.
		Si pone
		$$
		\mathrm{vol}_n (R) \coloneqq \prod_{k=1}^{n}  \mathrm{lungh} (I_k)
		$$ 
		per ogni $E \subset \R^n$ (assumendo $\mathrm{lungh}([a, b]) = b - a$). Infine poniamo
		$$
		\mathscr L^n(E) \coloneqq \inf \left\{ \sum_{i} \mathrm{vol}_n (R_i) \mymid \left\{ R_i \right\} \text{tale che } E \subset \bigcup_i R_i  \right\}.
		$$
\end{itemize}
 
\textbf{Osservazioni.}
\begin{itemize}
	\item $\mathscr L^n(R) = \mathrm{vol}_n (R)$.
	\item $\mathscr L^n$ è così definita se $\mc{P}(\R^n)$ ma non è $\sigma$-addittiva.
	\item $\mathscr L^n$ è $\sigma$-addittiva su $\mc{M}^n$ (è per questo che bisogna introdurre $\mc{M}^n$).
\end{itemize}

Il terzo punto giustifica l'introduzione dei \textbf{misurabili secondo Lebesgue}. Dunque definiamo $\mc{M}^n$, dato $E \subset \R^n$ si dice che $E$ è misurabile (secondo Lebesgue) se
$$
\forall \epsilon > 0 \; \exists A \text{ aperto e } C \text{ chiuso con }
C \subset E \subset A 
\text{tali che}
\mathscr L^n (A \smallsetminus C) \leq \epsilon
$$

\textbf{Osservazioni.}
\begin{itemize}
	\item Per ogni $E$ misurabile vale
$$
	\mathscr L^n(E) = \inf \left\{ \mathscr L^n \colon A \ \text{aperto}, A \supset E \right\} = \sup \left\{ \mathscr L^n \colon K \ \text{compatto}, K \subset E \right\}.
$$
	\item Notiamo che se $F \subset E$ con $E \subset \mc{M}^n$ e $\mathscr L^n(E) = 0$, allora $F \in \mc{M}^n$. Ovvero la misura di Lebesgue è completa!
\end{itemize}

\textbf{Notazione.} $\left| E \right| \coloneqq \mathscr L^n (E)$

\section{Funzioni misurabili}

\textbf{Definizione.}
Dato $(X, \mc{A}, \mu)$ e $f \colon X \to \R$ (o al posto di $\R$ in $Y$ spazio topologico), diciamo che $f$ è \textbf{misurabile} (più precisamente $\mc{A}$-misurabile), se
$$
\forall A \text{ aperto} \; f^{-1} (A) \in \mc{A}
$$ 


\textbf{Osservazioni.}
\nopagebreak
\begin{itemize}
	\item Dato $E \subset X$, vale $E \in \mc{A}$ se solo se $\One_E$ è misurabile.
	\item La classe delle funzioni misurabili è chiusa rispetto a molte operazioni
	\begin{itemize}
		\item \textit{Somma}, \textit{prodotto} (se hanno senso nello spazio immagine della funzione).
		\item \textit{Composizione con funzione continua}: Se $f \colon X \to Y$ continua e $g \colon  Y \to Y'$ continua, allora $g \circ f$ è misurabile.
		\item \textit{Convergenza puntuale}: data una successione di $f_n$ misurabili e $f_n \to f$ puntualmente, allora $f$ è misurabile.
		\item $\liminf$ e $\limsup$ (almeno nel caso $Y = \R$).
	\end{itemize}
\end{itemize}


\subsection{Funzioni semplici}

% Indico con $\mc{S}$ la classe delle funzioni $f \colon  X \to \R$ \textit{semplici}, cioè della forma $f = \sum_{i}^{n} \alpha_i \One_{E_i}$ con $\{E_i \}_{1 \leq i \leq n}$ misurabili e $\alpha_i \in \R$.
\textbf{Definizione.}
Definiamo la classe delle \textbf{funzione semplici} come
$$
\mc S := \left\{ f \colon X \to \R \mymid f = \sum_i \alpha_i \One_{E_i} \text{ con $E_i$ misurabili e $\{\alpha_i\}$ finito} \right\}
$$

\textbf{Osservazione.} La rappresentazione di una funzione semp/alice come combinazione lineare di indicatrici di insiemi \textit{non è unica}, però se necessario possiamo prendere gli $E_i$ disgiunti.

\section{Integrale}

\textbf{Definizione.}
Diamo la definizione di $\ds\int_X f \dd \mu$ per passi
\begin{enumerate}
	\item \label{item:def_int_1} 
		Se $f \in \mc{S}$ e $f \geq 0$ cioè $f = \sum_i \alpha_i \One_{E_i}$ con $\alpha_i \geq 0$ allora poniamo
$$
			\int_{X} f \dd \mu \coloneqq \sum_{i} \alpha_i \mu(E_i),
$$
		convenendo che $0 \cdot +\infty = 0$ in quanto la misura di un insieme non è necessariamente finita.
	
	\item \label{item:def_int_2} 
		Se $f \colon  X \to [0,+\infty]$ misurabile si pone
$$
			\int_{X} f \dd \mu \coloneqq \sup_{\substack{g \in \mc{S} \\ 0 \leq g \leq f}} \int_{X} g \dd \mu.
$$
		
	\item 
		$f \colon X \to \overline{\R}$ misurabile si dice \textbf{integrabile} se 
$$
			\int_{X} f^+ \dd \mu < + \infty \quad \text{oppure} \quad \int_{X} f^- \dd \mu < +\infty.
$$
		e per tali $f$ si pone
$$
			\int_{X} f \dd \mu \coloneqq  \int_{X} f^+ \dd \mu - \int_{X} f^- \dd \mu.
$$
	
	\item 
		$f \colon X \to \R^n$ si dice \textbf{sommabile} (o di \textbf{classe} $\mathscr L^1$) se $\int_X \left| f \right| \dd \mu < +\infty$. In tal caso, se $\int_X f_i^{\pm} \dd \mu < +\infty$ per ogni $f_i$ componente di $f$, allora $\int_X f \dd \mu$ esiste ed è finito.
\end{enumerate}

Per tali $f$ si pone
$$
	\int_{X} f \dd \mu \coloneqq  \left( \int_X f_1 \dd \mu, \ldots , \int_X f_n \dd \mu \right).
$$

\textbf{Notazione.}
Scriveremo spesso $\ds \int_E f(x) \dd x$ invece di $\ds \int_E f \dd \mathscr L^n$ .

\textbf{Osservazioni.}
\begin{itemize}
	\item L'integrale è lineare (sulle funzioni sommabili).
	
	\item I passaggi \ref{item:def_int_1} e \ref{item:def_int_2} danno lo stesso risultato per $f$ semplice $\geq 0$.
	
	\item La definizione in \ref{item:def_int_2} ha senso per ogni $f \colon X \to [0,+\infty]$ anche non misurabile. Ma in generale vale solo che
		$$
		\int_{X} f_1 + f_2 \dd \mu \geq \int_X f_1 \dd \mu + \int_X f_2 \dd \mu.
		$$
	
	\item Dato $E \in \mc{A}$, $f$ misurabile su $E$, notiamo che vale l'uguaglianza
		$$
		\int_E f \dd \mu \coloneqq \int_X f \cdot \One_E \dd \mu.
		$$ 
	
	\item Si può definire l'integrale anche per $f \colon X \to Y$ con $Y$ \textit{spazio vettoriale normato finito dimensionale}\footnote{È necessario avere uno spazio vettoriale, perché serve la linearità e la moltiplicazione per scalare} ed $f$ sommabile.
	
	\item Se $f_1 = f_2$ $\mu$-q.o. allora $\ds \int_X f_1 \dd \mu = \int_X f_2 \dd \mu$.
	
	\item Si definisce $\ds \int_X f \dd \mu$ anche se  $f$ è misurabile e definita su $X \setminus N$ con $\mu(N) = 0$.
	
	\item Se $f \colon [a,b] \to \R$ è integrabile secondo Riemann allora è misurabile secondo Lebesgue e le due nozioni di integrale coincidono. 
		
		\textbf{Nota.} Lo stesso vale per integrali impropri di funzioni positive. Ma nel caso più generale non vale: se consideriamo la funzione
		$$
		f \colon (0,+\infty) \to \R 
		\qquad
		f(x) \coloneqq \dfrac{\sin x}{x}
		$$
		allora l'integrale di $f$ definito su $(0,+\infty)$ esiste come integrale improprio ma non secondo Lebesgue, infatti
		$$
		\int_0^{+\infty} f^+ \dd x = \int_0^{+\infty} f^- \dd x = +\infty
		$$
	
	\item $\ds \int_X f \dd \delta_{x_0} = f(x_0)$
	
	\item Se $X = \N$ e $\mu$ è la misura che conta i punti l'integrale è 
		$$
		\int_X f \dd \mu = \sum_{n = 0}^{\infty} f(n) 
		$$ 
		per le $f$ positive o tali che $\sum f^+(n) < +\infty $ oppure $\sum f^-(n) < +\infty $.
		
		\textbf{Nota.} Come prima nel caso di funzioni non sempre positive ci sono casi in cui la serie solita non è definita come integrale di una misura, ad esempio
		$$
		\sum_{n=1}^{\infty} \frac{(-1)^n}{n}
		$$
		esiste come serie ma non come integrale.
		
	\item Dato $X$ qualunque, $\mu$ misura che conta i punti e $f \colon  X \to [0,+\infty] $ possiamo definire la somma di tutti i valori di $f$ 
		$$
		\sum_{x \in X} f(x) \coloneqq \int_{X} f \dd \mu.  
		$$ 
\end{itemize}

\section{Teoremi di convergenza}

Sia $(X, \mc{A}, \mu)$ come in precedenza.

\textbf{Teorema} (di convergenza monotona o Beppo-Levi).
Date $f_n \colon  X \to [0,+\infty]$ misurabili, tali che $f_n \uparrow f$ ovunque in $X$, allora
$$
\lim_{n \to +\infty} \int_{X} f_n \dd \mu = \int_X f \dd \mu,
$$
dove
$$
\lim_{n \to +\infty} \int_{X} f_n \dd \mu = \sup_n \int f_n \dd \mu.
$$


\textbf{Teorema} (lemma di Fatou).
Date $f_n \colon X \to [0,+\infty]$ misurabili, allora
$$
\liminf_{n \to +\infty} \int_X f \dd \mu \geq \int_{X} \left( \liminf_{n \to +\infty} f_n \right) \dd \mu.
$$ 

\textbf{Teorema} (di convergenza dominata o di Lebesgue).
Date $f_n \colon  X \to \R$ (o anche $\R^n$) con le seguenti proprietà
\begin{itemize}
	\item \textit{Convergenza puntuale:} $f_n (x) \to f(x)$ per ogni $x \in X$.
	\item \textit{Dominazione:} Esiste $g \colon X \to [0,+\infty]$ sommabile tale che $\left| f_n (x) \right| \leq g(x)$ per ogni $x \in X$ e per ogni $n \in \N$.
\end{itemize}
allora
$$
\lim_{n \to \infty} \int_{X} f_n \dd \mu = \int_X f \dd \mu. 
$$ 

\textbf{Nota.}
La seconda proprietà è essenziale; sostituirla con $\ds \int_X \left| f_n \right| \dd \mu \leq C < + \infty$ non basta!

\textbf{Definizione.}
Data una ``densità'' $\rho \colon  \R^n \to [0,+\infty]$ misurabile, la \textbf{misura $\mu$ con densità $\rho$} è data da
$$
\forall E \in \mc A \quad \mu(E) \coloneqq \int_{E} \rho \dd x
$$ 

\textbf{Osservazioni.}
\begin{itemize}
	\item $\R^n$ e $\mathscr L^n$ possono essere sostituiti da $X$ e $\widetilde{\mu}$.
	\item il fatto che $\mu$ è una misura segue da Beppo Levi, in particolare serve per mostrare la subadditività.
\end{itemize}


\textbf{Teorema} (di cambio di variabile).
Siano $\Omega$ e $\Omega'$ aperti di $\R^n$, $\Phi \colon \Omega \to \Omega' $ un diffeomorfismo di classe $C^1$ e $f \colon \Omega' \to [0,+\infty]$ misurabile. Allora
$$
\int_{\Omega'} f(x') \dd x' = \int_{\Omega} f(\Phi(x)) \left| \det(\Lambda \Phi(x)) \right| \dd x.
$$

La stessa formula vale per $f$ a valori in $\overline{\R}$ integrabile e per $f$ a valori in $\R^n$ sommabile.

\textbf{Osservazioni.}
\begin{itemize}
	\item Se $n = 1$, $\left| \det(\Lambda \Phi(x)) \right| = \left| \Phi'(x) \right|$ e non $\Phi'(x)$ come nella formula vista ad Analisi 1 (l'informazione del segno viene data dall'inversione degli estremi).
	
	\item Indebolire le ipotesi su $\Phi$ è delicato. Basta $\Phi$ di classe $C^1$ e $\foralmostall x' \in \Omega' \; \# \Phi^{-1}(x') = 1$ (supponendo $\Phi$ iniettiva la proprietà precedente segue immediatamente).
	Se $\Phi$ non è "quasi" iniettiva bisogna correggere la formula per tenere conto della molteplicità.

	\item Quest'ultima osservazione serve giusto per far funzionare il cambio in coordinate polari che non è iniettivo solo nell'origine.
\end{itemize}

\subsection{Fubini-Tonelli}

Di seguito riportiamo il teorema di Fubini-Tonelli per la misura di Lebesgue.

\textbf{Teorema} (di Fubini-Tonelli).
Sia $\R^{n_1} \times \R^{n_2} \simeq \R^n$ con $n = n_1 + n_2$, $ E \coloneqq E_1 \times E_2 $ dove $E_1, E_2$ sono misurabili e $f$ è una funzione misurabile definita su $E$.
Se $f$ ha valori in $[0,+\infty]$ allora
$$
\int_X f \dd \mu 
= \int_{E_2} \int_{E_1} f(x_1,x_2) \dd x_1 \dd x_2 
= \int_{E_1} \int_{E_2} f(x_1,x_2) \dd x_2 \dd x_1
$$ 

Vale lo stesso per $f$ a valori in $\R$ o in $\R^n$ sommabile.

\textbf{Osservazioni.}
Possiamo generalizzare il teorema di Fubini-Tonelli a misure generiche ed ottenere alcuni risultati utili che useremo ogni tanto.
\begin{itemize}
	\item Se $X_1, X_2$ sono spazi con misure $\mu_1,\mu_2$ (con opportune ipotesi) vale:
		$$
		\int_{E_2} \int_{E_1} f(x_1,x_2) \dd \mu_1(x_1)  \dd \mu_2(x_2) 
		= \int_{E_1} \int_{E_2} f(x_1,x_2) \dd \mu_2(x_2)  \dd \mu_1(x_1).
		$$ 
		se $f\geq 0$ oppure $\ds \int_{X_1} \int_{x_2} \left| f \right| \dd \mu_2(x_2)  \dd \mu_1(x_1) < + \infty $.
	
	\item \textbf{Teorema} (di scambio serie-integrale). Se $X_1 \subset \R$ (oppure $X_1 \subset \R^n$), $\mu_1 = \mathscr L^n$ e $X_2 = \N$, $\mu_2$ è la misura che conta i punti, allora la formula sopra diventa
		$$
		\sum_{n=0}^{\infty} \, \int_{X_1} f_n(x) \dd x  
		= \int_{X_1} \sum_{n=0}^{\infty} f_n(x)  \dd x.
		$$ 
		se $f_i \geq 0$ oppure $\ds \sum_{i} \int_{X_1} \left| f_i(x) \right| \dd x  < + \infty $.
	
	\item \textbf{Teorema} (di scambio di serie). Se $X_1 = X_2 = \N$ e $\mu_1 = \mu_2$ è la misura che conta i punti la formula sopra diventa
		$$
		\sum_{j=0}^{\infty} \sum_{i=0}^{\infty} a_{i,j}  
		= \sum_{i=0}^{\infty} \sum_{j=0}^{\infty} a_{i,j} 
		$$ 
		se $a_{i,j} \geq 0$ oppure $\ds \sum_{i} \sum_{j} \left| a_{i,j} \right| < +\infty $.
\end{itemize}

\chapter{Spazi $L^p$ e convoluzione}

\section{Disuguaglianze}

\subsection{Disuguaglianza di Jensen}

Ricordiamo che una funzione $f \colon \R^d \to [-\infty, +\infty]$ è \textbf{convessa} se e solo se dati $x_1, \dots, x_n \in \R^d$ e $\lambda_1, \dots, \lambda_n \in [0, 1]$ con $\sum_i \lambda_i = 1$ abbiamo che
$$
f \left(\sum_i \lambda_i x_i \right) \leq \sum_i \lambda_i f(x_i)
$$

\textbf{Teorema} (Jensen).
Dato $(X, \mc A, \mu)$ con $\mu(X) = 1$ e $f \colon \R^d \to [-\infty, +\infty]$ convessa e semi-continua inferiormente (S.C.I.) e $u \colon X \to \R^d$ sommabile allora vale
$$
\int_X f \compose u \dd \mu \geq f \left( \int_X u \dd \mu \right)
$$
e $f \compose u$ è integrabile.

\textbf{Osservazioni.}
\begin{itemize}
	\item $(f \compose u)^-$ ha integrale finito.

	\item Interpretando $\mu$ come probabilità si riscrive come $\mathbb E[f \compose \mu] \geq f(\mathbb[u])$.

	\item Se $u$ è una funzione semplice, cioè $u = \sum_i y_i \cdot \One_{E_i}$ con $E_i$ disgiunti e $\bigcup E_i = X$ allora posti $\lambda_i = \mu(E_i)$ abbiamo
		$$
		\int_X f \compose u \dd \mu = \int_X \sum_i f(y_i) \cdot \One_{E_i} \dd \mu = \sum_i \lambda_i f(y_i) \geq f \left( \sum_i \lambda_i y_i \right) = f \left( \int_X u \dd \mu \right)
		$$

		Questo ci darebbe una strada per dimostrare in generale per passi il teorema di Jensen ma in realtà si presentano vari problemi tecnici.

	\item Ogni funzione convessa e S.C.I su $\Omega$ convesso in $\R^d$ si estende a $\tilde f \colon \R \to (-\infty, +\infty]$ convessa e S.C.I., ad esempio se $\Omega = (0, +\infty)$
		$$
		f(y) = \frac{1}{y}
		\quad\rightsquigarrow\quad
		\tilde f(y) = 
		\begin{cases}
$$
			\dfrac{1}{y} & y > 0
		\end{cases}
		$$

	\item La semi-continuità inferiore serve perché le funzioni convesse sono continue solo se a valori in $\R$, ad esempio per $k$ costante la funzione
		$$
		f(y) := 
		\begin{cases}
			k & y < 0 \\
			+\infty & y \geq 0
		\end{cases}
		$$
		è convessa ma non semi-continua inferiormente (e neanche continua).
\end{itemize}

\textbf{Dimostrazione.}
Poniamo $y_0 \coloneqq \int_X u \dd \mu$, allora la tesi diventa
$$
\int_X f \compose u \dd \mu \geq f(y_0)
$$
Prendiamo $\phi \colon \R^d \to \R$ affine (ovvero $\phi(y) = a \cdot y + b$ con $a \in \R^d$ e $b \in \R$) tale che $\phi \leq f$, allora
$$
\int_X f \compose u \dd \mu \geq \int_X \phi \compose u \dd \mu = \int_X a \cdot u + b \dd \mu = a y_0 + b = \phi(y_0)
$$

Infine concludiamo usando il seguente lemma di caratterizzazione delle funzioni convesse ed S.C.I.

\textbf{Lemma.}
Ogni $f \colon \R^d \to (-\infty, +\infty]$ convessa e S.C.I è tale che
$$
\forall y_0 \in \R^d \quad \sup_{\substack{\phi \text{ affine} \\ \phi \leq f}} \phi(y_0) = f(y_0)
$$

Nel caso $d = 1$ e $f \colon \R \to \R$ possiamo appoggiarci al fatto che le funzioni convesse sono ammettono sempre derivata destra o sinistra, il $\sup$ diventa un massimo e ci basta prendere come $\phi$ la retta tangente in $(y_0, f(y_0))$ o una con pendenza compresa tra $f'(y_0^-)$ e $f'(y_0^+)$.

Rileggendo meglio la dimostrazione segue che $(f \compose u)^- < (\phi \compose u)^- \implies (f \compose u)^-$. 

\qed

\textbf{Definizione.} Dati $p_1, p_2 \in [1, +\infty]$ diciamo che sono \textbf{coniugati} se
$$
\frac{1}{p_1} + \frac{1}{p_2} = 1
$$
convenendo che $\sfrac{1}{\infty} = 0$.

Fissiamo $p \in [1, +\infty]$ detto ``esponente di sommabilità'' e sia $(X, \mc A, \mu)$ come sempre.

\textbf{Definizione.} $f \colon X \to \overline \R$ o $\R^d$ misurabile, allora la \textbf{norma $p$ di $f$} è per $p \in [1, +\infty)$
$$
\norm{f}_p \coloneqq \left( \int_X |f|^p \dd \mu \right)^p
$$
mentre per $p = +\infty$ poniamo
$$
\norm{f}_\infty \coloneqq \inf \{ m \in [0, +\infty] \mid |f(x)| \leq m \text{ per $\mu$-q.o. } x \}
$$
in realtà queste sono solo delle semi-norme\footnote{Vedremo meglio più avanti questo dettaglio}.

\begin{itemize}
	\item $\ds \norm{f}_\infty \leq \sup_{x \in X} |f(x)|$

	\item $\norm{f}_p = 0 \iff f = 0$ quasi ovunque

		\textbf{Dimostrazione.}
		\begin{itemize}
			\item[$\boxed{\Rightarrow}$] [TODO: Facile ma non ovvia]
			\item[$\boxed{\Leftarrow}$] Ovvio.
		\end{itemize}
		\qed

	\item Se $f_1 = f_2$ quasi ovunque $\implies \norm{f_1}_p = \norm{f_2}_p$.

		\textbf{Dimostrazione.} 
		$f_1 = f_2$ quasi ovunque $\implies \exists D \subset X$ con $\mu(D) = 0$ tale che $f_1(x) = f_2(x)$ su $X \setminus D$, usiamo il fatto che l'integrale non cambia se modifichiamo la funzione su un insieme di misura nulla
		$$
		\norm{f_1}_p^p
		= \int_X |f_1|^p \dd \mu 
		= \int_{X \setminus D} |f_1|^p \dd \mu 
		= \int_{X \setminus D} |f_2|^p \dd \mu 
		= \int_{X} |f_2|^p \dd \mu 
		= \norm{f_2}_p^p
		$$ 
		\qed
\end{itemize}

\subsection{Disuguaglianza di Young}

\textbf{Proposizione.}
Per ogni $a_1, a_2 \geq 0$ e $\lambda_1, \lambda_2 > 0$ con $\lambda_1 + \lambda_2 > 0$ abbiamo che
$$
a_1^{\lambda_1} a_2^{\lambda_2} \leq \lambda_1 a_1 + \lambda_2 a_2
$$
inoltre vale l'uguale se e solo se $a_1 = a_2$.

\textbf{Dimostrazione.}
Se $a_1 = a_2 = 0$ allora è ovvia. Supponiamo dunque $a_1, a_2 > 0$, ma sappiamo che 
% e passiamo $a_1^{\lambda_1} a_2^{\lambda_2}$ al logaritmo
$$
\lambda_1 \log a_1 + \lambda_2 \log a_2 \leq \log(\lambda_1 a_2 + \lambda_2 a_2)
$$
per concavità del logaritmo e quindi segue la tesi.

Il se e solo se per l'uguale segue dal fatto che il logaritmo è \textit{strettamente concavo}. 
\qed

\subsection{Disuguaglianza di H\"older}

\textbf{Proposizione.}
Date $f_1, f_2 \colon X \to \overline\R$ o $\R^d$ e $p_1, p_2$ esponenti coniugati allora
$$
\int_X |f_1| \cdot |f_2| \dd \mu \leq \norm{f_1}_{p_1} \cdot \norm{f_2}_{p_2}
$$ 
vale anche per $p = +\infty$ convenendo che $+\infty \cdot 0 = 0$ a destra dell'uguale.

\textbf{Dimostrazione.}
Se $\norm{f_1}_{p_1} = 0$ o $+\infty$ e anche $\norm{f_2}_{p_2} = 0$ o $+\infty$ la dimostrazione è immediata, supponiamo dunque $\norm{f_1}_{p_1}, \norm{f_2}_{p_2} > 0$ e finiti.

\begin{itemize}
	\item \textit{Caso 1:} se $p_1 = 1, p_2 = +\infty$ allora
		$$
		\int_X |f_1| \cdot |f_2| \dd \mu 
		\leq \int_X |f_1| \cdot \norm{f_2}_{\infty} \dd \mu
		= \norm{f_2}_{\infty} \cdot \int_X |f_1| \dd \mu
		= \norm{f_2}_{\infty} \cdot \norm{f_1}_{1} 
		$$

	\item \textit{Caso 2:} se $1 < p_1, p_2 < +\infty$, introduciamo un parametro $\gamma > 0$ allora
		$$
		\int_X |f_1| \cdot |f_2| \dd \mu 
		= \int_X \left( \gamma^{p_1} \cdot |f_1|^{p_1} \right)^{1/p_1} \cdot \left( \gamma^{-p_2} \cdot |f_1|^{p_2} \right)^{1/p_2} \dd \mu
		$$
		a questo punto chiamiamo per comodità $g_1 := \gamma^{p_1} \cdot |f_1|^{p_1}$, $\lambda_1 := 1 / p_1$ e $g_2 := \gamma^{-p_2} \cdot |f_1|^{p_2}$, $\lambda_2 := 1 / p_2$ da cui
		$$
		= \int_X g_1^{\lambda_1} \cdot g_2^{\lambda_2} 
		\overset{\text{Young}}{\leq} \int_X \lambda_1 g_1 + \lambda_2 g_2 \dd \mu
		= \lambda_1 \gamma^{p_1} \int_X |f_1|^{p_1} + \lambda_2 \gamma^{-p_2} \int_X |f_1|^{p_2} \dd \mu
		$$
		$$
		= \lambda_1 \gamma^{p_1} \cdot \norm{f_1}_{p_1}^{p_1} + \lambda_2 \gamma^{-p_2} \cdot \norm{f_1}_{p_2}^{p_2}
		$$
		posti ora $a_1 := \gamma^{p_1} \norm{f_1}_{p_1}^{p_1}$ e $a_2 := \gamma^{-p_2} \norm{f_1}_{p_2}^{p_2}$, per $\gamma \to 0$ abbiamo che $a_1 \to 0, a_2 \to +\infty$ mentre per $\gamma \to +\infty$ abbiamo che $a_1 \to +\infty, a_2 \to 0$ dunque per il teorema del valor medio esisterà $\gamma$ tale che $a_1 = a_2$, ma allora siamo nel caso dell'uguaglianza per la disuguaglianza di Young dunque
		$$
		\lambda_1 \gamma^{p_1} \norm{f_1}_{p_1}^{p_1} + \lambda_2 \gamma^{-p_2} \norm{f_1}_{p_2}^{p_2} 
		= \lambda_1 a_1 + \lambda_2 a_2 = a_1^{\lambda_1} \cdot a_2^{\lambda_2} 
		= \norm{f_1}_{p_1} \cdot \norm{f_2}_{p_2}
		$$
\end{itemize}
In particolare, vale l'uguaglianza se prendiamo un valore di $\gamma$ tale che $a_1 = a_2$. Resta da verificare che tale valore di $\gamma$ esista [TODO].
\qed

\textbf{Osservazione.}
La disuguaglianza di H\"older può essere generalizzata a $n$ funzioni, date $f_1, \dots, f_n$ e $p_1, \dots, p_n$ con $\frac{1}{p_1} + \dots + \frac{1}{p_2} = 1$ allora
$$
\int_X \prod_i |f_i| \dd \mu \leq \prod_i \norm{f_i}_{p_i} 
$$

\subsection{Disuguaglianza di Minkowski}

\textbf{Proposizione.} 
Consideriamo sempre $(X, \mc A, \mu)$ e sia $p \in [1, +\infty]$ un esponente di sommabilità ed $f_1, f_2 \colon X \to \R$ oppure $\R^d$ allora vale la disuguaglianza triangolare
$$
\norm{f_1 + f_2}_p \leq \norm{f_1}_p + \norm{f_2}_p
$$
%
\textbf{Dimostrazione.}
\begin{itemize}
	\item \textit{Caso 1:} se $p = 1$ o $p = +\infty$, allora basta fare il calcolo diretto
		
		\begin{itemize}
			\item Se $p = 1$
				$$
				\norm{f_1 + f_2}_1 
				= \int_X |f_1 + f_2| \dd \mu 
				\leq \int_X |f_1| + |f_2| \dd \mu 
				= \int_X |f_1| \dd \mu + \int_X |f_2| \dd \mu
				= \norm{f_1}_1 + \norm{f_2}_1
				$$
			\item Se $p = +\infty$
				$$
				\norm{f_1 + f_2}_\infty
				= \mathrm{supess}_X |f_1 + f_2| 
				= \mathrm{supess}_{X \setminus D} 
				\leq \mathrm{supess}_{X \setminus D} (|f_1| + |f_2|)
				$$
				$$
				= \mathrm{supess}_{X \setminus D} |f_1| + \mathrm{supess}_{X \setminus D} |f_2|
				= \mathrm{supess}_X |f_1| + \mathrm{supess}_X |f_2|
				= \norm{f_1}_\infty + \norm{f_2}_\infty
				$$
		\end{itemize}

	\item \textit{Caso 2:} se $1 < p < +\infty$ e $0 < \norm{f_1 + f_2}_p < +\infty$
		$$
		\begin{aligned}
			\norm{f_1 + f_2}_p^p 
			&= \int_X |f_1 + f_2|^p 
			\leq \int_X (|f_1| + |f_2|) \cdot |f_1 + f_2|^{p-1} \dd \mu = \\
			&= \int_X |f_1| \cdot |f_1 + f_2|^{p-1} \dd \mu + \int_X |f_2| \cdot |f_1 + f_2|^{p-1} \dd \mu = \\
			&\overset{\text{H\"older}}{\leq} \norm{f_1}_p \cdot \norm{|f_1 + f_2|^{p-1}}_q + \norm{f_2}_p \cdot \norm{|f_1 + f_2|^{p-1}}_q = \\
			& = (\norm{f_1}_p + \norm{f_2}_p) \cdot \norm{|f_1 + f_2|^{p-1}}_q 
			= (\norm{f_1}_p + \norm{f_2}_p) \cdot \norm{f_1 + f_2}_p^{p-1}  \\
		\end{aligned}
		$$
		e poiché $\norm{f_1 + f_2}_p > 0$ possiamo portare l'ultimo fattore dall'altra parte
		$$
		\implies \frac{\norm{f_1 + f_2}_p^p }{\norm{f_1 + f_2}_p^{p-1}} \leq \norm{f_1}_p + \norm{f_2}_p
		\implies \norm{f_1 + f_2}_p \leq \norm{f_1}_p + \norm{f_2}_p
		$$

	\item \textit{Caso 3:} se $1 < p < +\infty$ ma $\norm{f_1 + f_2} = 0$ o $+\infty$ allora se $\norm{f_1 + f_2} = 0$ la disuguaglianza è banale mentre se $\norm{f_1 + f_2} = +\infty$ si usa la seguente disuguaglianza
		$$
		\norm{f_1 + f_2}_p^p \leq 2^{p-1} (\norm{f_1}_p^p + \norm{f_2}_p^p)
		$$
		che si ottiene usando la convessità della funzione $y \mapsto y^p$
		$$
		\norm{f_1 + f_2}_p^p 
		= \int_X |f_1 + f_2|^p \dd \mu 
		= 2^p \int_X \left| \frac{f_1 + f_2}{2} \right|^p \dd \mu 
		$$
		$$
		\leq 2^p \int_X \frac{1}{2} |f_1|^p + \frac{1}{2}|f_2|^p \dd \mu 
		= 2^{p-1} (\norm{f_1}_p^p + \norm{f_2}_p^p)
		$$
		da cui possiamo ricavare subito che almeno uno dei due termini deve essere $+\infty$.

\end{itemize}

% lezione del 4 ottobre 2021
\section{Esercitazione del 4 ottobre}

\subsection*{Teoria della misura}

Di seguito riportiamo alcune proprietà di base di teoria della misura.

\textbf{Proprietà.}

\begin{enumerate}
\item Se $A \subset B$, allora $\mu(A) \leq \mu(B)$.

\textbf{Dimostrazione.}
Scomponiamo $B = (B \setminus A) \cup (A \cap B)$. Per ipotesi $A \cap B = A$ ed essendo la misura positiva segue che
$$
	\mu(B) = \underbrace{\mu(B \setminus A)}_{\geq 0} + \mu(A) \geq \mu(A).
$$

\item \label{item:misura_unione_finita} Dati due insiemi $A,B$ misurabili, vale
$$
	\mu(A \cup B) \leq \mu(A) + \mu(B).
$$

\textbf{Dimostrazione.}
La disuguaglianza segue dalle seguenti uguaglianze.

\begin{align*}
	\mu(A) & = \mu(A \setminus B) + \mu(A \cap B) \\
	\mu(B) & = \mu(B \setminus A) + \mu(A \cap B) \\
	\mu(A \cup B) & = \mu(A \setminus B ) + \mu(B \setminus A) + \mu(A \cap B).
\end{align*}

\item Data una successione di insiemi $E_1 \subset E_2 \subset \cdots \subset \cdots$, si ha
$$
	\mu \left( \bigcup_{i} E_i \right) = \sup_i \mu(E_i) = \lim_i \mu (E_i).
$$

\item Data una successione di insiemi $E_1 \supset E_2 \supset \cdots \supset \cdots$ e $\mu(E_1) < +\infty$, si ha
$$
	\mu \left( \bigcap_{i} E_i \right) = \lim_i \mu (E_i).
$$
\end{enumerate}

\textbf{Esercizio} (Numerabile subaddittività).
Dato $\ds E \in \mc{A}, E \subset \bigcup_i E_i$ dove $E_i \in \mc{A}$. Allora
$$
	\mu(E) \leq \sum_{i}^{} \mu(E_i).
$$

\textbf{Dimostrazione} (Idea).
Basta dimostrare che $\ds \mu \left( \bigcup_i E_i \right) \leq \sum_{i}^{} \mu(E_i)$. Infatti per quanto visto prima $\ds \mu(E) \leq \mu \left( \bigcup_i E_i \right)$. Prima dimostriamo per induzione $\ds \mu \left( \bigcup_{i = 1}^N E_i \right) \leq \sum_{i=1}^{N} \mu(E_i)$. 

Il passo base $n = 2$ è stato visto al punto \ref{item:misura_unione_finita}. Una volta dimostrata la proprietà sopra, si nota che $\ds \sum_{i=1}^{N} \mu(E_i) $ è limitata per ogni $N$, e dunque è limitato anche il suo limite, da cui la tesi.
\qed

\subsection*{Funzioni misurabili rispetto alla misura di Lebesgue}

Si ricorda che le funzioni \textit{continue}, \textit{semplici} e \textit{semicontinue} sono classi di funzioni misurabili.
Due osservazioni sulle funzioni semicontinue.
\begin{itemize}
\item Le funzioni semicontinue sono \textit{boreliane}.

\item La proprietà di misurabilità delle funzioni semicontinue è necessaria per l'enunciato della disuguaglianza di Jensen.
\end{itemize}

\textbf{Controesempio} (disuguaglianza di Jensen).
Notiamo che l'ipotesi di semicontinuità inferiore della funzione $f$ è necessaria per la validità della disuguaglianza di Jensen.
Infatti, definiamo $f$ come segue
%
$$
f(x) = 
\begin{cases}
0 \qquad \; x \in (0,1) \\
+ \infty \quad \text{altrimenti} 
\end{cases}.
$$
%
Osserviamo che la funzione $f$ così definita è convessa ma non semicontinua inferiormente.

Ora definiamo la funzione $u : X \to \R$ con $X = (0,2)$, come la funzione costante di valore $1/2$.
Calcoliamo l'integrale di $u(x)$ su $X$.
%
$$
	\int_{X} u(x) \dd x = 1. 
$$
%
In tal caso vale $\ds f \left( \int_X u(x) \dd x \right) = + \infty$.
D'altra parte $\ds \int_X f \compose u \dd x = 0$, dunque l'ipotesi di semicontinuità inferiore è necessaria.

\textbf{Fatto.}
Date $\myphi_1, \myphi_2$ funzioni semplici su $\R$ con misura di Lebesgue.
Allora $\myphi_1 \vee \myphi_2$ e $\myphi_1 \wedge \myphi_2$ sono ancora funzioni semplici.

\textbf{Lemma.}
Data $f \colon X \to [0, +\infty]$ misurabile
$$
\int_X f \dd \mu = 0 \quad \longiff \quad f = 0 \; \text{q.o. su } X.
$$

\textbf{Dimostrazione.}
\begin{itemize}

\item[$\boxed{\Rightarrow}$] Dato che $f$ è non negativa, il dominio $X$ può essere riscritto come
$$
	X = \left\{ x \in X \mymid f(x) \geq 0 \right\} = \left\{ x \in X \mymid f(x) > 0 \right\} \cup \left\{ x \in X \mymid f(x) = 0 \right\}
$$
ricordiamo che $(0, +\infty) = \bigcup_{n \geq 1} (\frac{1}{n}, +\infty)$ da cui segue
$$
	\left\{ x \in X \mymid f(x) > 0 \right\} =  \bigcup_{n \in \N \setminus \left\{ 0 \right\}} \left\{ x \in X \mymid f(x) \geq \frac{1}{n} \right\},
$$
e passiamo alle misure
$$
	\mu \left( \left\{ x \in X \mymid f(x) > 0 \right\} \right) 
	= \lim_{n \to +\infty} \mu\left(\left\{ x \in X \mymid f(x) \geq \frac{1}{n} \right\}\right),
$$
in questo modo otteniamo la seguente caratterizzazione dell'insieme su cui $f$ è positiva
$$
	\mu \left( \left\{ x \in X \mymid f(x) > 0 \right\} \right) >0 
	\longiff
	\exists \bar{n} \mid \mu \left( \left\{ x \in X \mymid f(x) \geq 1 / \bar{n} \right\} \right) > 0.
$$

% X @aziis98: Boh magari potremmo definire tipo L_n := { blob sotto l'integrale } per rendere un po' più leggibile quel dominio di integrazione.
% OK @aziis98: Oppure anche in notazione "probabilistica" $\{ f \geq \frac{1}{n} \}$ che è più corto
Allora possiamo maggiorare come segue
$$
	0 = \int_X f \dd \mu 
	\geq \;\int_{\left\{ f \,\geq\, \frac{1}{n} \right\}} \; f \dd \mu \geq	\frac{1}{n} \mu \left(  \left\{ x \mymid f(x) \geq \frac{1}{n} \right\} \right). 
$$
Dunque abbiamo
$$
	\mu \left(  \left\{ x \mymid f(x) \geq \frac{1}{n} \right\} \right) = 0 \qquad \forall n.
$$
Si conclude osservando che
$$
	\mu \left(  \left\{ x \mymid f(x) > 0 \right\} \right) = \lim_n \mu \left( \left\{ x \mymid f(x) \geq \frac{1}{n} \right\} \right) = 0.
$$

\item[$\boxed{\Leftarrow}$]
Dal fatto che $f$ è positiva possiamo scrivere
$$
	\int_X f \dd \mu = \sup_{\substack{g \leq f \\ g \; \text{semplice}}} \int_X g \dd \mu = \sup \sum_{i}^{} \alpha_i \mu(E_i) = 0. 
$$
\qed

\end{itemize}

\textbf{Osservazione} (sup essenziale di funzioni misurabili).
Data $f$ misurabile, definiamo
$$
	\norm{ f }_{\infty, X} \coloneqq \inf \left\{ m \in [0,+\infty] \mymid \left| f(x) \right| \leq m \quad \text{quasi ovunque}  \right\}.
$$

Se $\norm{ f }_{\infty} < + \infty$, allora diciamo che esiste una costante $L > 0$ con $L = \norm{ f }_{\infty, X}$, tale che 
$$
	\left| f(x) \right| \leq L
$$
quasi ovunque. 
Infatti, per definizione di $\inf$, $L = \lim_n m_n$, dove $m_n$ verificano
$$
	\left| f(x) \right| \leq m_n \quad \forall x \in X \setminus N_m, \quad \mu(N_m) = 0.
$$
Definiamo $N = \bigcup_{m} N_m$, da cui si ottiene
$$
	\mu(N) \leq \sum_{n=1}^{\infty} \mu (N_m) = 0. 
$$
Ovvero $N$ è trascurabile.
Preso $x \in X \setminus N$, vale
$$
	\left| f(x) \right| \leq m_n \quad \forall n \in \N.
$$


\subsection*{Formula di cambio di variabile applicata a funzioni radiali}

Sia $f \colon [0,+\infty) \to \R$ misurabile (di solito si richiede misurabile e positiva oppure sommabile).
Vala la seguente
$$
	\int_{0}^{+\infty} f\left( \left| x \right| \right) \dd x = c_n \cdot \int_{0}^{+\infty} f(\rho) \rho^{n-1} \dd \rho,
$$
dove $\ds c_n = n \mathscr L^n \left( \mc{B}(0,1) \right)$.

Applichiamo questa formula alla stima di integrali di funzioni positive.

\textbf{Esercizio.}
Sia
$$
	\psi (x) = \frac{1}{\norm{ x }^{\alpha}}
$$
% X @aziis98: Boh secondo me possiamo usare anche solo B(0, 1) invece di \mc B(0, 1), sempre sul tema di fare con \mc solo l'insieme delle parti e le sigma-algebre?
su $\mc{B}(0,1) \in \R^n$. Notiamo che $\psi(x) = f(\norm{ x })$ con $f = 1 / t^\alpha$.
Usiamo la formula appena introdotta per determinare gli $\alpha \in \R$ per i quali $\psi$ è sommabile su $\mc{B}(0,1)$.
%
$$
\int_{\mc{B(0,1)}}^{} \psi(x) \dd x 
= c_n \int_0^1 \frac{1}{\rho^\alpha} \rho^{n -1} \dd \rho 
= c_n \int_0^1 \rho^{n-1-\alpha} \dd \rho =
\begin{cases}
	\log (\rho) \quad n = \alpha \\
	\dfrac{\rho^{n-\alpha}}{n - \alpha} \quad \text{altrimenti} 
\end{cases} 
$$
%
Concludendo,
%
$$
	\int_{B}(0,1)^{} \frac{1}{\norm{ x }^\alpha} \dd x < + \infty \longiff n > \alpha.
$$
%
\textbf{Esercizio.}
Con passaggi analoghi al precedente otteniamo
%
$$
	\int_{\R^n \setminus \; \mc{B}(0,1)} \frac{1}{\norm{ x }^\alpha} \dd x < + \infty \longiff n < \alpha.
$$
%
\textbf{Esercizio.}
Vediamo per quali valori di $\beta$ l'integrale
%
$$
	\int_{\mc{B}(0,1)}^{} \frac{1}{\left( \norm{ x } + \norm{ x }^2 \right)^\beta} \dd x
$$
%
converge.

Vale la seguente catena di uguaglianze.
%
$$
\int_{\R^n}^{} \frac{1}{\left( \norm{ x } + \norm{ x }^2 \right)^\beta} \dd x 
= \int_{\mc{B}(0,1)}^{} \frac{1}{\left( \norm{ x } + \norm{ x }^2 \right)^\beta} \dd x 
+ \int_{\R^n \setminus \; \mc{B}(0,1)}^{} \frac{1}{\left( \norm{ x } + \norm{ x }^2 \right)^\beta} \dd x.
$$
%
Studiamo separatamente i due pezzi dell'integrale.
%
\begin{align*}
	\int_{\mc{B}(0,1)}^{} \frac{1}{\left( \norm{ x } + \norm{ x }^2 \right)^\beta} \dd x 
	& = c_n \int_{\mc{B}(0,1)}^{} \frac{1}{(\rho + \rho^2)^\beta} \rho^{n-1} \dd \rho
	= c_n \int_{0}^{1} \frac{1}{\rho^\beta} \cdot \frac{\rho^{n-1}}{(1 + \rho)^\beta} \dd \rho \\
	& \approx \int_{0}^{1} \rho^{n-1-\beta} \dd \rho < + \infty \longiff  \beta < n.
\end{align*}
%
Inoltre,
%
$$
	\int_{\mc{B}(0,1)}^{} \frac{1}{\left( \norm{ x } + \norm{ x }^2 \right)^\beta} \dd x 
	= \int_{\R^n \setminus \; \mc{B}(0,1)}^{} \frac{1}{\rho^{2\beta}} \cdot \frac{\rho^{n-1}}{\left( \frac{1}{\rho} + 1 \right)^\beta} \dd \rho 
	\approx \int_{1}^{+\infty} \frac{\rho^{n-1}}{\rho^{2\beta}} \dd rho < + \infty \longiff 2\beta > \alpha.  
$$
%
In conclusione, l'integrale è finito se $n > \beta > n / 2$.

% @aziis98: Molto probabilmente metterò un disegnino con assi $n$ e $\beta$ per far vedere "meglio" l'insieme dei valori buoni

\textbf{Esercizio.}
Studiare l'insieme di finitezza al variare del parametro $\alpha$ dell'integrale
$$
	\int_{[0,1]^n}^{} \frac{1}{\norm{ x }_1^\alpha} \dd x 
$$
Osserviamo che la norma 1 e 2 sono legate dalle seguenti disuguglianze
$$
	\frac{\norm{ x }_1}{n} \leq \norm{ x }_2 \leq \norm{ x }_1.
$$
%
Studiamo una maggiorazione per l'integrale
%
$$
	\int_{[0,1]^n}^{} \, \frac{1}{\norm{ x }_1^\alpha} \dd x 
	\leq \;\int_{[0,1]^n}^{} \, \frac{1}{\norm{ x }^\alpha} \dd x 
	\leq \;\;\int_{B(0,\sqrt{n})}^{}\;\; \frac{1}{\norm{ x }^\alpha} \dd x < + \infty \longiff \alpha < n,
$$
%
dunque
%
$$
\int_{[0,1]^n}^{} \, \frac{1}{\norm{ x }_1^\alpha} \dd x < +\infty \quad \text{se} \; \alpha < n.
$$
%
Vediamo ora una minorazione.

$$
	\int_{[0,1]^n}^{} \frac{1}{\norm{ x }_1^\alpha} \dd x 
= \frac{1}{2^n}	\int_{[-1,1]^n}^{} \frac{1}{\norm{ x }_1^\alpha} \dd x 
\geq \frac{1}{2^n} \ \int_{\mc{B}(0,1)}^{} \frac{1}{\norm{ x }_1^\alpha} \dd x 
\approx \int_{\mc{B}(0,1)}^{} \frac{1}{\norm{ x }^\alpha} \dd x < + \infty 
\longiff \alpha < n.
$$

Dunque l'integrale $\ds \int_{[0,1]^n}^{} \frac{1}{\norm{x}_1^\alpha} \dd x$ converge se solo se $\alpha < n$.

\newpage

\textbf{Esercizi per casa.}
\begin{enumerate}[label=(\arabic*)]

\item Dimostrare che date $f,g$ misurabili ed $r,p_1,p_2 > 0$ tali che  $1 / r = 1 / p_1 + 1 / p_2$.
Allora vale
$$
	\norm{ f \cdot g }_r \leq \norm{ f }_{p_1} + \norm{ g }_{p_2}.
$$
\textit{Suggerimento.} Usare Hölder osservando che $\ds 1 = \frac{r}{p_1} + \frac{r}{p_2} = \frac{1}{\left( p_1/r \right)} + \frac{1}{\left( p_2/r \right)}$.

\item Dimostrare che date $f_1,\ldots, f_n$ misurabili e $p_i > 0$ tali che $1/p_1 + \ldots + 1/p_n = 1$ si ha
$$
	\norm{ f_1 \cdots f_n }_1 \leq \norm{ f_1 }_{p_1} \cdots \norm{ f_n }_{p_n}.
$$
\textit{Suggerimento.} Fare il primo passo dell'induzione e usare la formula precedente scegliendo $r$ in modo corretto.

\end{enumerate}

% @aziis98: Forse ci conviene aggiungere commenti del genere almeno per noi, poi magari aggiungiamo meglio i link per lezione con le date.

%
% Lezione del 6 Ottobre 2021
%

\section{Costruzione spazi $L^p$}

Fissiamo $(X, \mc A, \mu)$ come sempre.

\textbf{Definizione.}
Sia $\mathscr L^p$ l'insieme delle funzioni $f \colon X \to \R$ o $\R^d$ misurabili tali che $\norm{f}_p < +\infty$.

\textbf{Osservazioni.}
\begin{itemize}
	\item $\mathscr L^p$ è un sottospazio vettoriale dello spazio vettoriale dato da $\{ f \colon X \to \R \mid f \text{ misurabile} \}$ e $\norm{\curry}_p$ è una semi-norma.

		\textbf{Dimostrazione.}
		\begin{itemize}
			\item $\mathscr L^p$ è chiuso per moltiplicazione per scalari.

			\item $f_1, f_2 \in \mathscr L^p \implies f_1 + f_2 \in \mathscr L^p$

			\item Dalla definizione segue subito $\norm{\lambda f}_p = |\lambda| \cdot \norm{f}_p$ l'omogeneità della norma.

			\item Dalla disuguaglianza di Minkowski segue che $\norm{\curry}_p$ è una semi-norma.
		\end{itemize}

	\item In particolare non è una norma se $\{ 0 \} \subsetneq \{ f \mid \norm{f}_p = 0 \}$ ovvero se $\mc A$ contiene insiemi non vuoti di misura nulla.

	\item In generale dato $V$ spazio vettoriale e $\norm{\curry}$ semi-norma su $V$ possiamo inotrdurre $N \coloneqq \{ v \mid \norm{v} = 0 \}$. $N$ risulta essere un sottospazio di $V$ e la norma data da $\norm{[v]} \coloneqq \norm{v}$ per $[v] \in \sfrac{V}{N}$ è ben definita ed è proprio una norma su $\sfrac{V}{N}$.

	\item Nel caso della della norma $\norm{\curry}_p$ abbiamo che $[f_1] = [f_2] \iff [f_1 - f_2] = 0 \iff f_1 - f_2 = 0$ quasi ovunque. 
\end{itemize}

\textbf{Definizione.}
Poniamo $N \coloneqq \{ f \mid \norm{f}_p = 0 \}$ e definiamo gli \textbf{spazi $L^p$} come
$$
L^p := \sfrac{\mathscr L^p}{N} = \sfrac{\mathscr L^p}{\sim} 
\qquad
\norm{[f]}_p \coloneqq \norm{f}_p
$$

\textbf{Notazione.}
Ogni tanto serve precisare meglio l'insieme di partenza e di arrivo degli spazi $L^p$ ed in tal caso useremo le seguenti notazioni
$$
L^p = L^p(X) = L^p(X, \mu) = L^p(X, \mc A, \mu) = L^p(X, \mu; \R^d)
$$

\textbf{Nota.}
Nella pratica non si parla mai di ``classi di funzioni'' e si lavora direttamente parlando di ``funzioni in $L^p$''. Le ``operazioni'' comuni non creano problemi però in certi casi bisogna stare attenti di star lavorando con oggetti ben definiti ad esempio:
\begin{itemize}
	\item Preso $x_0 \in X$ consideriamo l'insieme $\{ f \in L^p \mid f(x_0) = 0 \}$ non è un sottoinsieme ben definito (a meno che $\mu(\{ x_0 \}) > 0$) di $L^p$ in quanto possiamo variare $f$ su un insieme di misura nulla.

	\item Invece l'insieme $\{ f \in L^1 \mid \int_X f \dd \mu = 0 \}$ è ben definito.
\end{itemize}

\section{Completezza degli spazi $L^p$}

Vediamo ora la proprietà più importante degli spazi $L^p$.

\textbf{Teorema.}
Per $p \in [1, +\infty]$ lo spazio $L^p$ è completo.

% @aziis98: Per ora mi pare non si possano usare direttamente \label e \ref in questi punti, cioè linka alla sezione.
\hypertarget{prop:completeness_lemma_1}{}
\textbf{Lemma 1.} 
Dato $(Y, d)$ spazio metrico, allora
\begin{enumerate}
	\item
		Ogni successione $(y_n)$ tale che
		$$
		\sum{\infty}_{n=1} d(y_n, y_{n+1}) < +\infty
		$$
		è di Cauchy, e in particolare converge a qualche $y \in Y$ se $Y$ è completo.

	\item \label{item:def_completeness_1}
		Se ogni $(y_n)$ tale che $\sum{\infty}_{n=1} d(y_n, y_{n+1}) < +\infty$ converge allora $Y$ è completo.	
\end{enumerate}

\textbf{Osservazione.} Non tutte le successioni di Cauchy $(y_n)$ soddisfano quella condizione, ad esempio su $\R$ la successione $\sfrac{(-1)^n)}{n}$ è di Cauchy però
$$
\sum_{n=1}^\infty \left| \frac{(-1)^{n+1}}{n+1} - \frac{(-1)^n}{n} \right| 
= \sum_{n=1}^\infty \frac{2n + 1}{n^2 + n}
\approx \sum_{n=1}^\infty \frac{1}{n} \to \infty
$$
ma come abbiamo visto nella \ref{item:def_completeness_1} ci basta per mostrare la completezza dello spazio che è ciò che ci interessa veramente.

\textbf{Dimostrazione.}
\begin{enumerate}
	\item 
		Dati $n > m$ abbiamo che 
		$$
		d(y_m, y_n) \leq \sum_{k=m}^{n-1} d(y_k, y_{k+1}) \leq \sum_{k=m}^\infty d(y_k, y_{k+1}) \to 0
		$$
		in quanto è la \textit{coda di una serie convergente} quindi 
		$$
		\forall \epsilon > 0 \; \exists m_\epsilon \text{ tale che } \sum_{k = m_\epsilon}^\infty d(y_k, y_{k+1})< \epsilon \implies \forall n > m \geq m_\epsilon \; d(y_m, y_n) \leq \epsilon
		$$ 

	\item
		Basta far vedere che data $(y_n)$ di Cauchy esiste una sottosuccessione $y_{n_k}$ tale che
		$$
		\sum_{k=1}^\infty d(y_{n_k}, y_{n_{k+1}}) < +\infty
		$$
		ma $\forall k \; \exists n_k$ tale che $\forall n, m \geq n_k \; d(y_m, y_n) \leq \frac{1}{2^k}$ dunque $d(y_{n_k}, y_{n_{k+1}}) \leq \frac{1}{2^k}$.

		Quindi per ipotesi $y_{n_k}$ converge a qualche $y \in Y$ ed anche $y_n \to y$.
\end{enumerate}
\qed

% @aziis98: Il latex mi vuole male e mi metteva solo Corollario e la prima frase alla fine della pagina e l'enumerate alla nuova, però se aggiungiamo cose prima poi lo togliamo.
\newpage

\hypertarget{prop:completeness_lemma_2}{}
\textbf{Lemma 2.} 
Dato $Y$ spazio normato, i seguenti fatti sono equivalenti
\begin{enumerate}
	\item $Y$ è completo.

	\item $\sum_{n=1}^\infty y_n$ converge in $Y$ per ogni $(y_n)$ tale che $\sum_{n=1}^\infty \norm{y_n} < +\infty$ ovvero $\norm{y - \sum_{n=1}^N y_n} \to 0$.
\end{enumerate}

\textbf{Dimostrazione.} 
È un corollario del lemma precedente. 
\qed

\hypertarget{prop:completeness_lemma_3}{}
\textbf{Lemma 3} 
(Minkowski per somme infinite). 
Date delle funzioni $(g_n)$ funzioni positive su $X$ allora
$$
\norm{\sum_{n=1}^\infty g_n}_p \leq \sum_{n=1}^\infty \norm{g_n}_p
$$

% @aziis98: Si bisognerebbe scrivere qualche parola in più magari a questa dimostrazione.
\textbf{Dimostrazione.}
Per ogni $N$ abbiamo che
$$
\norm{\sum_{n=1}^N g_n}_p^p 
\leq \left( \,\sum_{n=1}^N \norm{g_n}_p \right)^p 
\leq \left( \,\sum_{n=1}^\infty \norm{g_n}_p \right)^p 
$$
e
$$
\norm{\sum_{n=1}^N g_n}_p^p 
= \int_X \left( \sum_{n=1}^N g_n(x) \right)^p \dd \mu(x)
\xrightarrow{\;N\;} \int_X \left( \sum_{n=1}^\infty g_n(x) \right)^p \dd \mu(x)
$$
per \textit{convergenza monotona}.
\qed

\textbf{Dimostrazione} (Completezza spazi $L^p$).
\begin{itemize}
	\item 
		Se $p = +\infty$: si tratta di vedere che data $(f_n)$ di Cauchy in $L^\infty(X)$ esiste $E$ con $\mu(E) = 0$ tale che $(f_n)$ è di Cauchy rispetto allora norma del sup in $X \setminus E$. [TODO: Finire]

	\item 
		Se $p < +\infty$: per il \hyperlink{prop:completeness_lemma_2}{Lemma 2}, basta far vedere che data $(f_n) \subset L^p(X)$ tale che $\sum_{n=1}^\infty \norm{f_n}_p < +\infty$ allora $\sum_n f_n$ converge a qualche $f \in L^p(X)$.

		La dimostrazione è suddivisa in tre passi, prima costruiamo $f$, poi mostriamo che $f_n$ convege a $f$ ed infine mostriamo $f \in L^p(X)$.

		\begin{itemize}
			\item 
				\textit{Passo 1:} 
				Per ipotesi abbiamo
				$$
				\infty 
				> \sum_{n=1}^\infty \norm{f_n}_p 
				= \sum_{n=1}^\infty \norm{|f_n|}_p 
				\geq \norm{\sum_{n=1}^\infty |f_n|}_p 
				= \left( \int \left( \sum_{n=1}^\infty |f_n(x)| \right)^p \dd \mu(x) \right)^{1/p}
				$$
				quindi $\sum_{n=1}^\infty |f_n(x)| < +\infty$ per ogni $x \in X \setminus E$ con $\mu(E) = 0$. Quindi $\sum_{n=1}^\infty f_n(x)$ converge a qualche $f(x)$ per ogni $x \in X \setminus E$ ed a questo punto ci basta estendere $f$ a zero\footnote{Una costruzione alternativa degli spazi $L^p$ potrebbe anche partire da \textit{funzioni definite quasi ovunque}, questo ovvierebbe al problema di estendere a $0$ la funzione $f$ appena costruita. Però diventa più complicato mostrare di essere in uno spazio vettoriale poiché per esempio serve ridefinire $+$ per funzioni definite quasi ovunque.}.
			
			\item 
				\textit{Passo 2:}
				Fissiamo $N$ ed osserviamo che $\forall x \in X \setminus E$ abbiamo
				$$
				\left| f(x) - \sum_{n=1}^N f_n(x) \right| 
				= \left| \sum_{n=N+1}^\infty f_n(x) \right| 
				\leq \sum_{n=N+1}^\infty |f_n(x)|
				$$
				da cui otteniamo
				$$
				\norm{f - \sum_{n=1}^N f_n}_p 
				\leq \norm{\sum_{n=N+1}^\infty |f_n|}_p
				\leq \sum_{n=N+1}^\infty \norm{f_n}_p
				$$
				dove l'ultimo termine è la coda di una serie convergente.
			
			\item 
				\textit{Passo 3:}
				In particolare rileggendo il passo precedente per $N = 0$ otteniamo
				$$
				\norm{f}_p \leq \sum_{n=1}^\infty \norm{f_n}_p < +\infty \implies f \in L^p
				$$

		\end{itemize}
\end{itemize}
\qed

\textbf{Esercizio.}\footnote{In questo corso non è strettamente necessario ricordarsi come si facciano tutti questi esercizietti di teoria della misura ma è bene saperli applicare in automatico quando serve.}
Sia $f \colon X \to [0, +\infty]$ allora $\ds \int_X f \dd \mu < +\infty \implies f(x) < +\infty$ per quasi ogni $x$.

\textbf{Dimostrazione.}
Sia $E := \{ x \mid f(x) = +\infty \}$, allora l'idea è che
$$
\infty > \int_X f \dd \mu \geq \int_E f \dd \mu = +\infty \cdot \mu(E)
$$
più precisamente osserviamo che $\forall m \in [0, +\infty)$ abbiamo $f \cdot \One_E \geq m \cdot \One_E$ quindi integrando ricaviamo
$$
\underbrace{\int_E f \dd \mu}_{I} \geq m \cdot \mu(E) 
\implies \mu(E) \leq \frac{I}{m} \xrightarrow{m \to +\infty} 0
$$
\qed

\section{Nozioni di convergenza per successioni di funzioni}
Fissiamo $X,\mc{A},\mu$ e prendiamo $f, f_n \colon X \to \R$ (o $\R^k$) misurabili.

\textbf{Definizione.}
Riportiamo le definizioni di alcune nozioni di convergenza.

\begin{itemize}

\item \textbf{Uniforme} : $\forall \epsilon \; \exists n_{\epsilon}$ tale che $\norm{f(x) - f_n(x)} < \epsilon \mquad n > n_\epsilon$.

\item \textbf{Puntuale} : $f_n \to f \mquad \forall x \in X$.

\item \textbf{Puntuale} $\mu$\textbf{-quasi ovunque} : $f_n \to f$ per $\mu$-q.o. $x \in X$.

\item \textbf{In} $L^p$ : $\norm{f_n - f}_p \to 0$.

\item \textbf{In misura} : $\ds \forall \epsilon > 0 \quad \mu \left( \left\{ x \mymid \left| f_n(x) - f(x) \right| \geq \epsilon \right\} \right) \xrightarrow{n \to +\infty} 0$.

\end{itemize}

\textbf{Osservazione.}
Abbiamo le seguenti implicazioni ovvie delle diverse nozioni di convergenza:

\begin{center}
	uniforme $\Rightarrow$ puntuale $\Rightarrow$ puntuale $\mu \almosteverywhere$
\end{center}

\textbf{Proposizione.}
Valgono le seguenti.
\begin{enumerate}

\item \label{item:convergenza_i} Data $f_n \to f$ q.o. e $\mu(X) < +\infty$, allora $f_n \to f$ in misura.

\item \label{item:convergenza_ii} (\textit{Severini-Egorov}): Data $f_n \to f$ q.o. e $\mu(X) < +\infty$, allora $\forall \delta > 0$ esiste  $E \in \mc{A}$ tale che $\mu(E) < \delta$ e $f_n \to f$ uniformemente su $X \setminus E$.

\item \label{item:convergenza_iii} $f_n \to f $ in $L^p$, $p < +\infty$, allora $f_n \to f$ in misura.

\item[iii')] \label{item:convergenza_iv} $f_n \to f \in L^\infty$, allora $\exists E $ tale che $\mu(E) = 0$ e $f_n \to f$ uniformemente su $X \setminus E$.

\item $f_n \to f$ in misura, allora $\exists n_k$ tale che $f_{n_k} \to f$ $\mu$-q.o.

\item $f_n \to f$ in $L^p$, allora $\exists n_k$ tale che $f_{n_k} \to f$ $\mu$-q.o.

\end{enumerate}

\textbf{Osservazione.}
In i) e ii) l'ipotesi $\mu(X) < +\infty$ è necessaria.
Infatti, preso $X = \R$ e $f_n = \One_{[n,+\infty)}$ si ha che $f_n \to 0$ ovunque ma $f_n$ non converge a $0$ in misura, e $f_n$ non converge a $0$ uniformemente in $\R \setminus E$ per ogni $E$ di misura finita.

\textbf{Lemma} (disuguaglianza di Markov).
Data $g \colon X \to [0,+\infty]$ misurabile e $m > 0$ si ha
%
$$
\mu \left( \left\{ x \in X \mymid g(x) \geq m \right\} \right) \leq \frac{1}{m} \int_X g \dd \mu
$$
%

\textbf{Dimostrazione.}
Poniamo $\ds E \coloneqq \left\{ x \in X \mymid g(x) \geq m \right\}$.
Osserviamo che $g \geq m \cdot \One_E$.
Dunque vale
%
$$
\int_X g \dd \mu \geq \int_X m \cdot \One_E \dd \mu = m \cdot \mu \left( \left\{ x \in X \mymid g(x) \geq m \right\} \right)
$$
%
da cui la tesi.
\qed

\textbf{Lemma} (Borel-Cantelli).
Dati $(E_n) \subset \mc{A}$ tali che $\sum \mu(E_n) \leq +\infty$, l'insieme
%
$$
E \coloneqq \left\{ x \in X \mymid x \in E_n \; \text{frequentemente} \right\}
$$
%
ha misura nulla.
Cioè per $\mu$-q.o. $x$, $x \notin E_n$ definitivamente (in $n$.)

\textbf{Dimostrazione.}
Osserviamo che
%
$$
E = \bigcap_{m=1}^\infty \Big( \underbrace{\bigcup_{n=m}^\infty E_n}_{F_m} \Big).
$$
%
Allora
%
$$
\mu(E) \quad \underbrace{=}_{F_m \downarrow E \; \& \; \mu(F_1) < +\infty} \quad  \lim_{m \to \infty} \mu(F_m) \leq \lim_{m \to \infty} \underbrace{\sum_{n=m}^{\infty} \mu(E_n)}_{\mathclap{\text{coda di serie convergente}}} = 0.
$$
%

\textbf{Osservazione.}
L'ipotesi $\sum \mu(E_n) < +\infty$ non può essere sostituita con $\mu(E_n) \to 0$.

Ora dimostriamo la proposizione.

\textbf{Dimostrazione.}

Definiamo gli insiemi
\begin{align*}
A_n^\epsilon & \coloneqq \left\{ x \mymid \left| f_n(x) - f(x) \right| \geq \epsilon \right\}, \\
B_m^\epsilon & \coloneqq \left\{ x \mymid \left| f_n(x) - f(x) \right| \geq \epsilon \; \text{per qualche} \; n \geq m\right\} = \bigcup_{n = m}^\infty A_n^\epsilon, \\
A_n^\epsilon & \coloneqq \left\{ x \mymid \left| f_n(x) - f(x) \right| \geq \epsilon \; \text{frequentemente}  \right\} = \left\{ x \in A_n^\epsilon \; \text{frequentemente}  \right\} = \bigcap_{m = 1}^\infty B_m^\epsilon.
\end{align*}

\begin{enumerate}
\item Per ipotesi, $f_n \to f$ quasi ovunque, cioè $\mu(B^\epsilon) = 0$ per ogni $\epsilon > 0$, ma $B_m^\epsilon \downarrow B^\epsilon$ e $\mu(X) < +\infty$.
Allora
%
$$
\lim_{m \to +\infty} \mu(B_m^\epsilon) = \mu(B^\epsilon) = 0 \Rightarrow \lim_{m \to \infty} \mu(A_m^\epsilon) = 0.
$$
%

\item Dalla dimostrazione precedente, abbiamo $\ds \lim_{m \to \infty} \mu(B_m^\epsilon) = 0$. 
Allora per ogni $k$ esiste un $m_k$ tale che $\mu \left( B_m^{1/k} \right) \leq \delta / 2^k$.
Pongo $E \coloneqq  \bigcup_{k} B_{m_k}^{1/k}$ per ogni $k$; allora $\mu(E) \leq \delta$.
Inoltre,
\begin{align*}
x \in X \setminus E & \Rightarrow x \notin B_{m_k}^{1/k} \; \forall k \iff x \notin A_n^{1/k} \mquad \forall k,n \geq m_ k \\
& \Rightarrow \left| f(x) f_n(x) \right| < \frac{1}{k} \mquad \forall k,n \geq m_k \\
& \Rightarrow \sup_{x \in X \setminus E} \left| f(x) - f_n(x) \right| \leq \frac{1}{k} \mquad \forall k,n \geq m_k \\
& \Rightarrow f - f_m \; \text{uniformemente su} \; X \setminus E.
\end{align*}

\item Dobbiamo mostrare che per ogni $\epsilon > 0$ $\mu(A_n^\epsilon) \xrightarrow{n} 0$.
Usando la disuguaglianza di Markov ottengo

%
$$
\mu \Big( A_n^\epsilon= \Big\{ x \Big| \overbrace{\left| f_n(x) - f(x) \right|}^{g} \geq \epsilon^p \Big\} \Big)
\leq \frac{1}{m} \int_{X}^{} g \dd \mu = \frac{1}{\epsilon^p} \norm{f_n - f}_p^p \xrightarrow{n \to +\infty} 0.
$$
%

\item[iii')] Definiamo $\ds E_n \coloneqq  \left\{ x \mymid \left| f_n(x) - f(x) \right| > \norm{f_n - f}_\infty \right\}$ per ogni $n$, allora $\mu(E_n) = 0$.
Poniamo $E = \bigcup_{n} E_n$ e $\mu(E) = 0$, dunque
%
$$
\sup_{x \in X\setminus E} \left| f_n(x) - f(x) \right| \leq \norm{f_n - f}_\infty \to 0.
$$
%


\item per ipotesi, $f_n \to f$ in misura, cioè
\begin{align*}
& \forall \epsilon > 0 \quad \mu \left( A_n^\epsilon \right) \xrightarrow{n \to +\infty} 0 \\
& \Rightarrow \forall k \; \exists n_k \colon \mu \left( A_{n_k}^{1/k} \right) \leq \frac{1}{2^k} \\
& \Rightarrow \sum_{k}^{} \mu \left( A_{n_k}^{1/k} \right) < +\infty. 
\end{align*}
Allora per Borel-Cantelli, si ha per $\mu$-quasi ogni $x$, $x \notin A_{n_k}^{1/k}$ definitivamente in $k$, cioè $\norm{f_{n_k}(x) - f(x)} < 1/k$ definitivamente in $k$, cioè $\ds f_{n_k}(x) \xrightarrow{k} f(x)$.

\item[v)] [TODO].

\end{enumerate}

\subsection{Prodotto scalare su $L^2$}

Date $f_1,f_2 \in L^2(X)$ si pone
%
$$
\left<f_1, f_2 \right> \coloneqq \int_{X}^{} f_1 \cdot f_2 \dd \mu.
$$
%
\textbf{Osservazioni.}

\begin{itemize}
\item La definizione di $\left<f_1, f_2 \right>$ è ben posta.
Infatti, basta far vedere che $\ds \int_X \left| f_1 f_2 \right| \dd \mu < +\infty$, che segue da H\"{o}lder.
%
$$
\int_{X}^{} \left| f_1 f_2 \right| \dd \mu \leq \norm{f_1}_2 \norm{f_2}_2 < +\infty
$$
%

\item $\norm{f}_2^2 = \left<f,f \right>$ per ogni $f \in L^2(X)$.

\item Inoltre, $\ds \left| \int_X f_1 f_2 \right| \dd \mu \leq \int_X \left| f_1 f_2 \right| \dd \mu$ quindi
%
$$
\left| \left<f_1, f_2 \right> \right| \leq \norm{f_1}_2 \norm{f_2}_2 \quad \; \text{(\textit{Cauchy-Schwartz})}.
$$
%

\item L'operatore $\left< \ , \ \right>$ è un prodotto scalare definito positivo.

\end{itemize}

\textbf{Osservazioni.}
\begin{itemize}
\item Dato $C$ spazio vettoriale reale con prodotto scalare $\left<\ ,\ \right>$, allora $\left<\ ,\ \right>$ si ricava dalla norma associata $\norm{\cdot}$ tramite l'identità di polarizzazione:
%
$$
\left<v_1, v_2 \right> = \frac{1}{4} \left( \norm{v_1 + v_2}^2 - \norm{v_1 - v_2}^2 \right).
$$
%

\item  Dato $V$ come sopra, vale l'identità del parallelogramma:
%
$$
\norm{v_1 + v_2}^2 + \norm{v_1 - v_2}^2 = 2 \norm{v_1}^2 + 2 \norm{v_2}^2 \quad \forall v_1,v_2 \in V.
$$
%
 Usando questa identità di dimostra che la norma di $L^p$ deriva da un prodotto scalare solo per $p=2$.

\end{itemize}

\textbf{Proprietà.}
Sia $V$ uno spazio vettoriale normato con norma $\norm{\cdot}$. Allora vale l'identità del parallelogramma se solo se $\norm{\cdot}$ deriva da un prodotto scalare.

\textbf{Esempio.}
La norma di $L^p \left( [-1,1] \right)$, deriva da un prodotto scalare solo per $p=2$.
Prendiamo $f_1 = \One_{[-1,0]}$ e $f_2 = \One_{[0,+1]}$.
Allora
%
\vspace{-5mm}
%
\begin{align*}
\norm{f_1 + f_2}_p^p = \int_{-1}^{1} 1 \dd x = 2 \Rightarrow \norm{f_1 + f_2}_p = 2^{1/p} \\
\norm{f_1 - f_2}_p = \norm{f_1 + f_2}_p = 2^{1/p}, \quad \norm{f_1}_p = \norm{f_2}_p = 1
\end{align*}
%
Se vale l'identità del parallelogramma allora
%
$$
\norm{f_1 + f_2}_p^2 + \norm{f_1 - f_2}_p^2 = 2 \norm{f_1}_p^2 + 2 \norm{f_2}_p^2
$$
%
cioè
%
$$
2^{2/p} + 2^{2/p} = 2 \cdot 1 + 2 \cdot 1 \iff p = 2.
$$
%

\textbf{Domanda.} Per quali $X,\mc{A},\mu$ vale la stessa conclusione?

%
% Lezione dell'11 Ottobre 2021
%

\section{Controesempi sulle convergenze}

Vediamo un controesempio che mostra che tutte le implicazioni sui vari tipi di convergenza sono ottimali ovvero
\begin{enumerate}
	\item \label{item:ce_1}
		$f_n \to f$ in misura $\centernot\implies f_n \to f$ q.o.
	\item \label{item:ce_2}
		$f_n \to f$ in $L^p$ con $p < +\infty \centernot\implies f_n \to f$ q.o.
	\item \label{item:ce_3}
		$\mu(E_n) \to 0 \centernot\implies$ per q.o $x$ si ha $x \notin E_n$ definitivamente. 
\end{enumerate}

\textbf{Dimostrazione.}
Consideriamo gli insiemi $I_1 = \left[ 1, 1 + \frac{1}{2} \right], I_2 = \left[1 + \frac{1}{2}, 1 + \frac{1}{2} + \frac{1}{3} \right], \dots$
$$
I_n \coloneqq \left[ \; \sum_{k=1}^n \frac{1}{k}, \; \sum_{k=1}^{n+1} \frac{1}{k} \; \right]
$$
e consideriamo la loro proiezione ``modulo'' $[0, 1]$ usando la funzione $p \colon \R \to [0, 1)$ \textit{parte frazionaria} data da
$$
p(x) \coloneqq x - \lfloor x \rfloor
$$
e chiamiamo $E_n \coloneqq p(I_n)$. Per ogni $n$ abbiamo che $|I_n| = |E_n| = 1 / n$ e $\bigcup_n I_n = [1, +\infty)$ (in quanto $\sum_{k=1}^\infty \frac{1}{k} = +\infty$) e quindi ogni $x \in [0, 1)$ appartiene ad $E_n$ per infiniti $n$ ed in particolare questo mostra la \ref{item:ce_3}. 

[TODO: Disegnino]

Per la \ref{item:ce_1} basta consideare $\One_{E_n} \to 0$ in misura (in quanto $|E_n| \to 0$) ma $\One_{E_n} \centernot\to 0$ q.o., anzi $\forall x \in [0, 1) \; \One_{E_n}(x) \centernot\to 0$ e la \ref{item:ce_2} segue analogamente.
\qed

\subsection{Approssimazioni di funzioni in $L^p$}

% Ricordiamo la nozione di insieme denso in uno spazio metrico.
% Sia (X,d) uno spazio metrico e Y ⊆ X. Allora Y è denso in X se solo se
% per ogni x ∈ X, esiste una successione y_n in Y che tale che x = lim_n y_n.

Vediamo ora alcune classi di funzioni dense in $L^p$ che risulteranno essere un utile strumento da usare nelle dimostrazioni.

\textbf{Nota.} Ricordiamo la nozione di insieme denso in uno spazio metrico.
Sia $(X,d)$ uno spazio metrico e $Y \subset X$. Allora Y è denso in X se solo se
per ogni $x \in X$, esiste una successione $(y_n)_{n \in \N}$ in $Y$ che tale che $x = \lim_n y_n$.

Per ora sia $(X, \mc A, \mu)$ in generale.

\textbf{Esercizio.} 
Le funzioni limitate in $L^p$ sono dense in $L^p$.

\textbf{Dimostrazione.}
Data $f \in L^p(X)$ cerchiamo una successione di funzioni $f_n \in L^p(X)$ limitate tali che $f_n \to f$ in $L^p$, consideriamo
$$
f(x) (\coloneqq f(x) \land n) \lor (-n)
$$
vorremmo mostrare che $f_n \to f$ in $L^p$ ovvero
$$
\norm{f_n - f}_p^p = \int_X |f_n - f|^p \dd \mu \to 0
$$
intanto vediamo che per la \textit{convergenza puntuale} basta osservare che se $n \geq |f(x)|$ abbiamo che $\forall x \; f_n(x) = f(x) \implies f_n(x) \xrightarrow{n} f(x) \implies |f_n(x) - f(x)|^p \to 0$.

Per concludere basta applicare \textit{convergenza dominata} usando come dominazione direttamente $|f(x) - f_n(x)| \leq |f(x)| \implies |f(x) - f_n(x)|^p \leq |f(x)|^p$ e notiamo che $|f|^p \in L^1(X)$.
\qed

\textbf{Proposizione.}
Sia\footnote{Lo span è inteso come combinazioni lineari} $\tilde{\mathscr S} \coloneqq \spn(\{ \One_E \mid E \in \mc A, \mu(E) < +\infty \})$, allora $\tilde{\mathscr S}$ è denso in $L^p(X)$.

\textbf{Dimostrazione.}
Data $f \in L^p(X)$ cerchiamo una successione che approssima $f$ in $\tilde{\mathscr S}$.
\begin{itemize}
	\item 
		\textit{Caso 1}: Se $f \geq 0$ allora fissiamo $\epsilon > 0$ e per ogni $k = 1, 2, \dots$ e poniamo
		$$
		A_k^\epsilon := \{ x \mid k \epsilon \leq f(x) \leq (k+1) \epsilon \}
		$$
		risulta che $A_k^\epsilon$ è misurabile ed ha misura finita. Ora consideriamo la successione di funzioni parametrizzata da $\epsilon$ data da
		$$
		f_\epsilon(x) := \sum_{1 \leq k \leq 1 / \epsilon^2} k \epsilon \cdot \One_{A_\epsilon^k}(x) \in \tilde{\mathscr S}
		$$
		[TODO: Disegnino]

		Osserviamo che vale anche $f_\epsilon(x) = \max\{ k \epsilon \mid k \epsilon \leq f(x) \text{ e } k \leq 1 / \epsilon^2 \}$ e mostriamo la seguente\footnote{Notiamo che qui stiamo applicando il teorema di \textit{convergenza dominata} su una famiglia parametrizzata da $\epsilon$ e non su una successione ma si può verificare facilmente che il teorema (ed anche gli altri risultati di convergenza di successioni di funzioni) si può estendere semplicemente prendendo $\epsilon = 1 / n$ per $n \to \infty$.}
		$$
		\int_X |f(x) - f_\epsilon(x)|^p \dd \mu(x) \xrightarrow{\epsilon \to 0} 0
		$$
		\begin{itemize}
			\item \textit{Convergenza puntuale}: Per l'identità precedente abbiamo che $0 \leq f(x) - f_\epsilon(x) \leq \epsilon$ se $f(x) \leq 1 / \epsilon$.
			% @aziis98: Cioè per me questo passaggio è ancora un po' mistico quindi poi voglio provare a spiegarlo meglio
			% ($f(x) \leq 1 / \epsilon \implies k \epsilon \leq 1 / \epsilon \implies k \leq 1 / \epsilon^2$ [TODO])
			\item \textit{Dominazione}: Possiamo usare nuovamente $|f(x) - f_\epsilon(x)|^p \leq |f(x)|^p < +\infty$ in quanto $f \in L^p(X)$.
		\end{itemize}

		[TODO: Disegnino]

	\item 
		\textit{Caso 2}:
		Sia $f \colon X \to \R$ allora si può rifare la dimostrazione precedente oppure si può semplicemente consideare $f_\epsilon \coloneqq (f^+)_\epsilon - (f^-)_\epsilon$.

	\item 
		\textit{Caso 3}:
		Generalizziamo la proposizione al caso di $f \colon X \to \R^d$ come segue

		\textbf{Proposizione} (Generalizzata).
		Sia $\tilde{\mathscr S} \coloneqq \{ \sum_i \alpha_i \One_{E_i} \mid \alpha_i \in \R^d, E_i \in \mc A, \mu(E_i) < +\infty \} \implies \tilde{\mathscr S}$ è denso in $L^p(X; \R^d)$.

		\textbf{Dimostrazione.} (Idea)
		Basta approssimare componente per componente.
\end{itemize}
\qed

Sia ora $X$ uno \textit{spazio metrico} e $\{ \text{aperti} \} \subset \mc A$.

\textbf{Proposizione.}
Sia $\tilde{\mathscr S}_\ell \coloneqq \{ \sum_i \alpha_i \One_{E_i} \mid \alpha_i \in \R^d, E_i \in \mc A, \mu(E_i) < +\infty, E_i \text{ limitati} \}$ allora $\tilde{\mathscr S}_\ell$ è denso in $L^p(X; \R^d)$ per $p < +\infty$.

\textbf{Osservazione.} 
In generale l'enunciato non vale per $p = +\infty$. Ad esempio preso $L^\infty(\R)$ e $f = 1$ non si può approssimare con funzioni a supporto limitato (come quelle in $\tilde{\mathscr S}_\ell$. In particolare data $g$ con supporto $A$ limitato $|f - g| = 1$ su $\R \setminus A$ e siccome $|\R \setminus A| > 0$ abbiamo $\norm{f - g}_\infty \geq 1$).

\textbf{Dimostrazione.} ($\tilde{\mathscr S}_\ell$ è denso in $L^p$)
Per prima cosa vediamo un lemma che useremo assieme alla proposizione precedente.

% @aziis98: Boh questo lemma non so se metterlo prima o se lasciarlo qua

\textbf{Lemma.}
Dato $E \in \mc A, \mu(E) < +\infty$ esiste $E_n \in \mc A$ con $E_n$ limitati tali che $E_n \subset E$ e $\mu(E \setminus E_n) \to 0$ e quindi $\norm{\One_{E} - \One_{E_n}}_p = \mu(E \setminus E_n)^{1/p} \xrightarrow{n} 0$ (e $\One_{E_n} \in \tilde{\mathscr S}_\ell$).

\textbf{Dimostrazione.}
Dato $E$ con $\mu(E) < +\infty$ prendiamo $x_0 \in X$ e poniamo $E_n \coloneqq E \cap \mc B(x_0, n)$; $E_n \subset E$ e $E \setminus E_n \downarrow \varnothing \implies \mu(E \setminus E_n) \xrightarrow{n} 0$.

Intuitivamente $\tilde{\mathscr S}_\ell$ è denso in $\tilde{\mathscr S}$ che a sua volta è denso in $L^p$ (usando la definizione di densità topologica la tesi è quasi ovvia mentre usando la definizione per successioni bisogna passare per un procedimento diagonale).
\qed

Ora sia $X \subset \R^n, \mu = \mathscr L^n$ e 
$$
C_C(\R^n) \coloneqq \{ \text{funzioni a supporto compatto} \}
$$
notiamo che $C_C(\R^n) \subset L^p$ per ogni $p$.

\textbf{Proposizione.}
Le funzioni in $C_C(\R^n)$ \textit{ristrette a $X$} sono dense in $L^p(X)$ per $p < +\infty$.

Vediamo prima alcuni lemmi.

\textbf{Lemma.}
Dato $E \subset \R^n$ limitato (e quindi di misura finita) esiste $f_\epsilon \in C_C(\R^n)$ tale che $f_\epsilon \xrightarrow{\epsilon \to 0} \One_E$ in $L^p(\R^n)$ e quindi in $L^p(X)$.

\textbf{Dimostrazione.}
Per regolarità della misura di Lebesgue abbiamo che per ogni $\epsilon$ esistono $C_\epsilon \subset E \subset A_\epsilon$ tali che $|A_\epsilon \setminus C_\epsilon| \leq \epsilon$ e prendiamo $f_\epsilon \colon \R^n \to [0, 1]$ continua tale che
$$
f_\epsilon = 1 \text{ su $C_\epsilon$}
\qquad
f_\epsilon = 0 \text{ su $\R^n \setminus A_\epsilon$}
$$
in particolare sappiamo che su $A_\epsilon \setminus C_\epsilon$ vale $|f_\epsilon - \One_E| \leq 1$
$$
\implies \norm{f_\epsilon - \One_E}_p^p = \int_{A_\epsilon \setminus C_\epsilon} |f_\epsilon - \One_E|^p \dd x
$$

\textbf{Lemma.} (di Urysohn)
Dati $C_0, C_1$ chiusi disgiunti in $X$ spazio metrico esiste una funzione $f \colon X \to [0, 1]$ continua tale che $f = 0$ su $C_0$ e $f = 1$ su $C_1$.

\textbf{Dimostrazione.}
Posta $d(x, C) = \inf \{ d(x, y) \mid y \in C \}$ basta consideare
$$
f(x) =
\frac{d(x, C_0)}{d(x, C_0) + d(x, C_1)}
$$

\textbf{Dimostrazione.} ($C_C(\R^n)$ è denso in $L^p(X)$)

Segue dalla proposizione e dal lemma precedente.

% 
% Lezione del 13 Ottobre 2021
% 

\section{Esercitazione del 13 ottobre}

\subsection{Esercizi su spazi $L^p(X)$ al variare di $p$ e dello spazio $X$}

Sia $X \subset \R^n$, $\mu$ la misura di Lebesgue e $ 1 \leq p_1 \leq p_2$.

\textbf{Domanda.} Possiamo confrontare gli spazi $L^{p_1}(X)$ e $L^{p_2}(X)$?
In generale no. 

Vediamo informalmente perché.
Posto $X = (0,+\infty)$, gli integrali 
%
$$
\int_{0}^{+\infty} \frac{1}{(1+x)^{\beta p}} \dd x, \qquad \int_{0}^{+\infty} \frac{1}{x^{\beta p}} \cdot \One_{[0,1]}(x) \dd x = \int_{0}^{1} \frac{1}{x^{\beta p}} \dd x
$$
%
 sono maggiorati dall'integrale di $1 / x^{\alpha}$ dove l'esponente  $\alpha$ è rispettivamente più piccolo e più grande di $\beta \cdot p$.

Vediamo quanto detto finora più formalmente.

Cerchiamo una funzione $f \in L^{p_1}(0,+\infty) \setminus \, L^{p_2}(0,+\infty)$ e una funzione $g \in L^{p_2}(0,+\infty) \setminus \, L^{p_1}(0,+\infty)$.
La funzione $f$ definita come segue
%
$$
f(x) \coloneqq 
\begin{cases}
1 / x^\beta \mquad x \in (0,1) \\
0 \mquad x \geq 1
\end{cases} 
$$
%
ha integrale 
%
$$
\int_{0}^{+\infty} f(x)^{p_1} \dd x = \int_{0}^{1} \frac{1}{x^{\beta p_1}} \dd x < +\infty \longiff \beta \cdot p_1 < 1, \mquad 0 < p_1 < p_2 \longiff \frac{1}{p_2} < \frac{1}{p_1}
$$
e
$$
\int_{0}^{+\infty} f(x)^{p_2} \dd x = \int_{0}^{1} \frac{1}{x^{\beta p_2}} \dd x = +\infty \longiff \beta \cdot p_2 \geq 1
$$
%
basta prendere $\beta \in [1/p_2, 1/p_1)$.

Ora cerco $g \in L^2 (0,+\infty) \setminus \, L^{p_1}(0,+\infty)$.
Definisco $g(x)$ come segue
$$
g(x) \coloneqq \frac{1}{(1+x)^\alpha}
$$
da cui
$$
\int_{0}^{+\infty} g(x)^{p_2} \dd x < +\infty \longiff \alpha \cdot p_2 > 1
\quad
\text{e}
\quad
\int_{0}^{+\infty} g(x)^{p_1} \dd x = +\infty \longiff \alpha \cdot p_1 \leq 1
$$

\textit{Conclusione.} In generale non c'è confrontabilità fra gli spazi $L^p$. La confrontabilità, dipende infatti dall'insieme $X$ su cui sono definiti.

Un caso particolare è dato ponendo $p_1 < p_2$ e $\mu(X) < +\infty$. In tal caso $L^{p_2}(X) \subset L^{p_1}(X) $.

Data $f \in L^{p_2}(X)$, cioè con $\int_X \left| f \right|^{p_2} \dd \mu < +\infty$ vediamo che  $\int_X \left| f \right|^{p_1} \dd \mu < +\infty$.

Usiamo Hölder:
\begin{align*}
\int_X \left| f \right|^{p_1} \dd \mu & \leq \Bigg( \int_X \overbrace{\left| h(x) \right|^p}^{\left| f(x) \right|^{p_1 p}}  \dd \mu  \Bigg)^{1/p} \cdot \left( \int_X 1^q \dd \mu  \right)^{1/q}
\underbrace{\leq}_{p = p_1 / p_2} \left( \int_X \left| f \right)^{p_1} \dd \mu  \right)^{p_1 /p_2} \left( \int_X 1^q \dd \mu  \right)^{1/q} \\
& \underbrace{=}_{q = (1 - \frac{1}{p}^{-1} = \frac{p}{p-1} = \frac{p_2 / p_1}{p_2 - p_1}} \norm{f}_{L^{p_2}(X)}^{p_1} \cdot \mu(X)^{\frac{p_2 - p_1}{p_2}}.
\end{align*}
%
Dunque
%
$$
\norm{f}_{L^{p_1}(X)} \leq \norm{f}_{L^{p_2}(X)}\cdot \mu(X)^{\frac{p_2 - p_1}{p_1 p_2}}.
$$
%
L'inclusione
%
\begin{align*}
i \colon L^{p_2} & \to L^{p_1}(X) \\
f & \mapsto f
\end{align*}

è ben definita per quanto fatto sopra. Per esercizio vedere con quale topologia risulta continua. [TO DO]

\textbf{Esercizio.} [TO DO] Dato $p \geq 1$, stabilire se esistono $X, \mu,f \in L^p(X)$ e $f \notin L^q(X)$ per ogni $q \neq p$, $q \geq 1$. \\
\textit{Suggerimento.} pensare a $X = (0,+\infty)$, $\mu$ misura di Lebesgue.

\textbf{Osservazione.} $L^p(X)$ è uno spazio vettoriale di dimensione infinita, ossia ogni base algebrica ha cardinalità infinita. 
Vediamo il caso $X = (0,1)$.
Per trovare una base infinita, cerchiamo per ogni $N \in \N$, $f_1,\ldots , f_N \in L^p(0,1)$ tali che siano linearmente indipendenti.
Vale a dire, presi $\lambda_1,\ldots ,\lambda_N \in \R$ vale $\lambda_1 f_1 + \ldots +f_N = 0$ se solo se $\lambda_1 = \ldots = \lambda_N = 0$.

Ad esempio, definisco $f_i \coloneqq \One_{i/N, (i+1)/N}$ (questa costruzione si può riprodurre per ogni $N \in \N$).

Ricordiamo che, essendo $L^p(X)$ uno spazio metrico, dato $Y \subset L^p$ vale la seguente caratterizzazione:
\begin{center}
$Y$ è compatto $\longiff$ $Y$ è compatto per successioni $\longiff $ $Y$ chiuso e totalmente limitato.
\end{center}

\textbf{Osservazione.} $Y \subset L^p(X)$ è un sottoinsieme che eredita la norma $\norm{\cdot}_{L^p}$ :
\begin{center}
$Y$ è completo $\longiff$ $Y$ è chiuso.
\end{center}

\textbf{Osservazione.} In $L^p$ i sottoinsiemi chiusi e limitati non sono compatti!
In particolare le palle
%
$$
Y = \left\{ f \in L^p \mymid \norm{f}_{L^p} \leq 1 \right\}
$$
%
non sono compatte.

Ad esempio, mostriamo che in $L^p(0,1)$ le palle 
%
$$
B = \left\{ f \in L^p \mymid \norm{f}_{L^p} \leq 1 \right\}
$$
%
non sono compatte.
Per farlo, esibiamo una successione $\left\{ f_n \right\}_{n \in \N} \subset B$ che non ammette sottosuccessioni convergenti.
La costruiamo in modo che non abbia sottosuccessioni di Cauchy
%
$$
f_n \colon (0,1) \to \R, \quad \norm{f_n - f_m}_{L^p} \geq c_0 > 0 \; \forall n \neq m.
$$
%
Cerco $A_n \subset (0,1)$ tale che $\left| A_n \cap A_m \right| = 0$ per ogni $n \neq m$.
Definiamo $f_n$ come segue
%
$$
f_n(x) \coloneqq 
\begin{cases}
0 \quad  \text{se} \; x \in (0,1) \setminus (1 / (n+1), 1/ n) \\
c_n > 0 \quad \text{altrimenti}
\end{cases} 
$$
%
dove $c_n$ è tale che 
%
$$
\left( \int_{1 / n+1}^{1 / n} c_n^p  \right)^{1/p} = 1 \longiff 
c_n^p \cdot (1/n - 1/(n+1)) = 1 \longiff c_n^p = n \cdot (n+1).
$$
%
Calcoliamo ora $\norm{f_n - f_m}^p_{L^p}$ con $n \neq m$ :
%
$$
\int_0^1 \left| f_n(x) - f_m(x) \right|^p \dd x = \int\limits_{\mathclap{(1/n,1/n+1) \cup (1/ m+1,1/m)}} \left| f_n - f_m \right|^p \dd x = \int_{1 / n+1}^{1 / n} \left| f_n \right|^p \dd x + \int_{0}^{1} \left| f_m \right|^p \dd x = 1 + 1 = 2.
$$
%

Si osserva che quanto detto sopra vale anche per $p = + \infty$.

\textbf{Esercizio.} [TO DO] Sia $E = \left\{ f \in L^1(1,+\infty) \mymid \left| f(x) \right| \leq 1 / x^2 \mquad \text{e} \;x \in [1,+\infty) \right\}$.

\begin{itemize}

\item $E$ è limitato in $L^1$?

\item $E$ è chiuso in $L^1$?

\item $E$ è compatto in $L^1$?

\end{itemize}

\textbf{Esercizio.} [TO DO] 
\begin{itemize}
\item Dire se $f_n(x) = x^n$, $n = 0,\ldots , N$ è un insieme di funzioni linearmente indipendenti in $L^p([0,1])$.

\item Dire se $\left\{ f_n \right\} \subset L^p(0,1)$ è compatta in $L^p(0,1)$.
\end{itemize}
\textit{Suggerimento.} Studiare il limite puntuale.

\subsection{Spazi $\ell^p$}

Prendiamo $X = \N$ e $\mu = \#$ la misura che conta i punti.

\textbf{Osservazione.} Definiamo
%
$$
\ell^p = L^p(\N, \#) = \left\{ \left( x_n \right)_{n \in \N} \mymid \sum_{n=0}^{+\infty} \left| x_n \right|^p < +\infty  \right\}
$$
con $p \geq 1$ e $p \neq +\infty$, e
%
$$
l^{\infty} = \left\{ \text{successioni limitate} \right\} = \left\{ \left( x_n \right) \mymid \sup_{n \in \N}\left| x_n \right| < +\infty \right\}.
$$
%

\textbf{Esempio} (di insieme non compatto in $\ell^1$). Consideriamo la successione $\left( e_i \right)$ definita come
%
$$
(e_i)_n \coloneqq 
\begin{cases}
0 \quad \text{se} \; n \neq i \\
1 \quad \text{se} \; n = i
\end{cases} 
$$
%
si osserva inoltre che le successioni così definite sono linearmente indipendenti e generano se sono infiniti.

\textbf{Esempio} (di insieme compatto in $\ell^1$). Sia $F = \left\{ (x_n)_n \in \ell^1 \mymid \left| x_n \right| \leq 1 / n^2 \quad \forall n \in \N \right\}$.
Noto subito che $F$ è limitato, infatti, presa
%
$$
\underline{x} = (x_n) \in F, \quad  \norm{\underline{x}}_{\ell^1} = \sum_{n=0}^{+\infty} \left| x_n \right| \leq
\sum_{n=0}^{+\infty} 1 / n^2 < +\infty.  
$$
%
$F$ è anche chiuso.

\textbf{Osservazione.} Data una successione $(\underline{x}^k) \subset \ell^1$, se $\underline{x}^k \xrightarrow{\ell^1} \underline{x}^{\infty}$, vuol dire che
%
$$
\norm{\underline{x}^k - \underline{x}^\infty}_{\ell^1} = \sum_{n = 0}^{+\infty}  \left| x_n^k - x_n^\infty \right| \xrightarrow{k} 0. 
$$
%
In particolare, per ogni $n \in \N$ fissato, $\lim_k (x_n^k - x_n^\infty) = 0$.

$F$ è chiuso perché se $(\underline{x}^k) \subset F$ e $\underline{x}^k \xrightarrow{\ell^1} \underline{x}^\infty$, allora per ogni $n \in \N$ vale 
%
$$
\left| x_n^k \right| \leq 1 / n^2 \quad \text{e} \quad \underbrace{\lim_{n \to +\infty} \left| x_n^k  \right|}_{x_n^\infty} \leq 1/n^2.
$$
%

Dimostriamo che è compatto per successioni.
Prendiamo $( \underline{x}^k ) \subset F$, ogni componente $x_n$ è equilimitata a meno di sottosuccessioni $x_n^{x_j}$ converge a $x_n^\infty$.
A meno di diagonalizzare, posso supporre che le successione $k_j$ non dipenda da $n$.
Otteniamo che $x_n^{k_j}$ sono dominate da $y = (1 / n^2)$. Concludiamo usando il teorema di Lebesgue.

% 
% Lezione del 14 Ottobre 2021
% 

\section{Complementi su approssimazioni di funzioni in $L^p$}

Sia $X$ misurabile in $\R^n$ con $\mu = \mathscr L^n$ su $X$, in precedenza abbiamo visto che

\textbf{Proposizione 3.} Le funzioni in $C_C(\R^n)$ \textit{ristrette a $X$} sono dense in $L^p$ se $p < +\infty$.

[TODO: la seguente osservazione è da rilocare probabilmente]

\textbf{Osservazione.} 
Le funzioni $C_C(\R^n)$ sono le funzioni a supporto compatto, dove il supporto è definito come la chiusura dell'insieme dei punti in cui la funzione è non zero
$$
\operatorname{supp}(f) := \overline{\{ x \mid f(x) \neq 0 \}}
$$
in quanto per le funzioni continue l'insieme $\{ x \mid f(x) \neq 0 \}$ è sempre aperto e dunque mai veramente compatto a parte quando è vuoto.

\begin{wrapfigure}{r}{150pt}
	\centering
	\vspace{-2.5\baselineskip}
	\inputfigure{supporto-compatto}
	\vspace{-3.5\baselineskip}
\end{wrapfigure}

\textbf{Osservazione.}
Si vede facilmente che $C_C(\R^n) \subset L^p(\R^n)$.

\textbf{Domanda.} Vale un risultato analogo per le funzioni $C_C(X)$?

Notiamo che dato $X \subset \R^n$ le funzioni continue su $X$ hanno supporto compatto solo se $X$ è aperto in quanto il supporto ha veramente distanza non nulla dal bordo e possiamo estendere la funzione a $0$ fuori da $X$, altrimenti... [TODO: Esempio con un chiuso in cui le cose non fungono?]

\textbf{Proposizione 4.} 
Sia $X$ aperto di $\R^n, \mu = \mathscr L^n$ allora $C_C(X)$ è denso in $L^p$ per ogni $p < +\infty$

\textbf{Dimostrazione.}
\begin{itemize}
	\item
		$\mathscr S_C := \{ \text{funzioni semplici con supporto compatto in $X$} \}$ è denso in $L^p(X)$ per ogni $p < +\infty$.

	\item
		Dato $E$ relativamente compatto in $X$ esiste $f_n \in C_C(X)$ tale che $f_n \to \One_E$ in $L^p$ per ogni $p < +\infty$.
\end{itemize}

La Proposizione 3 non vale per $p = +\infty$, intuitivamente in quanto data $f \in L^\infty(X)$ discontinua, se trovassimo $f_n \to f$ in $L^\infty(X)$ con $f_n$ continue avremmo $f_n \to f$ \textit{uniformemente} e dunque $f$ continua.

\textbf{Fatto.} 
In generale vale che data $f \colon X \to \R$ misurabile, $\norm{f}_\infty \leq \sup_{x \in X} |f(x)|$ (detta anche \textit{norma del sup})

\textbf{Esercizio.} 
Se $X$ è aperto in $\R^n$ e $\mu = \mathscr L^n$ e $f \colon X \to \R$ continua, allora $\norm{f}_\infty = \sup_{x \in X} |f(x)|$.

\textbf{Soluzione.}
Se per assurdo $\exists x \in X$ tale che $\norm{f}_\infty < |f(x)|$ allora la continuità di $f$ implica che esiste un intorno di $x$ in cui $|f| > \norm{f}_\infty$ ma un intorno contiene una palla aperta di misura positiva \absurd

\begin{wrapfigure}{r}{125pt}
	\centering
	\vspace{-2.5\baselineskip}
	\inputfigure{aperto-a-misura-positiva}
	\vspace{-3.5\baselineskip}
\end{wrapfigure}

In particolare possiamo anche estenderci a $X \subseteq \R^n$ tali che ogni $A$ aperto relativamente a $X$ abbia misura positiva.

Per spiegare meglio il perché la Proposizione 3 non si estende al caso $p = +\infty$ consideriamo
$$
f(x) =
\begin{cases}
	1 & x \geq 0 \\
	0 & x < 0
\end{cases}
$$
e vediamo che $\nexists f_n \colon \R \to \R$ tale che $f_n \to f$ in $L^\infty$. 

Se esistesse $(f_n)_n$, allora sarebbe di Cauchy rispetto alla norma $\norm{\curry}_\infty$ allora per continuità $(f_n)_n$ è di Cauchy anche rispetto alla norma del sup $\implies f_n \to \tilde f$ uniformemente con $\tilde f$ continua, quindi $\tilde f = f$ quasi ovunque ma questo non è possibile per la $f$ definita sopra.

(In particolare dato $E = \{ x \mid f(x) = \tilde f(x) \}$, prendiamo $x_n, y_n \in E$ tali che $x_n \uparrow 0$ e $y_n \downarrow 0$ ma i limiti di $f$ sono $0$ e $1$ \absurd)

\textbf{Teorema} (di Lusin).
Dato $X \subset \R^d, \mu = \mathscr L^d$ e data $f \colon X \to \R$ o $\R^m$ misurabile e $\epsilon > 0$, esiste $E$ aperto in $X$ con $|E| \leq \epsilon$ tale che $f$ è continua su $X \setminus E$ (la restrizione di $f$ a $X \setminus E$ è continua)

\textbf{Osservazione.} 
In generale $f$ può essere non continua in tutti i punti di $X$, infatti $E$ può essere denso e $X \setminus E$ avere parte interna vuota.

\textbf{Lemma} (di estensione di Tietze). Dato $X$ spazio metrico e $C \subset X$ chiuso, $f \colon C \to \R$ continua allora $f$ si estende a una funzione continua su $X$.

Usando questo lemma possiamo rienunciare il teorema precedente come segue

\textbf{Teorema} (di Lusin$'$).
Data $f \colon X \to \R$ misurabile e $\epsilon > 0$, $\exists E$ aperto con $|E| \leq \epsilon$ e $g \colon X \to \R$ continua tale che $f = g$ su $X \setminus E$, inoltre se $f \in L^p(X)$ e $p < +\infty$ si può anche chiuedere che $\norm{f - g}_p \leq \epsilon$.

\textbf{Dimostrazione.}
Basta trovare $E$ misurabile (per ottenere $E$ aperto si usa la regolarità della misura)
\begin{itemize}
	\item \textit{Caso 1}:
		$f \in L^1(X)$ e $|X| < +\infty$

		Abbiamo che $f \in L^1 \implies \exists f_n$ continue tali che $f_n \to f$ in $L^1 \implies f_n \to f$ in misura e per Severini-Egorov esiste $E$ tale che $|E| \leq \epsilon$ e $f_n \to f$ uniformemente su $X \setminus E \implies f$ è continua su $X \setminus E$.

	\item \textit{Caso 2}:
		$f$ qualunque misurabile e $|X| < +\infty$

		\textbf{Lemma.}
		Dati $X, \mc A, \mu$ con $\mu(X) < +\infty$ e data $f \colon X \to \R$ misurabile e $\epsilon > 0$ esiste $F$ misurabile con $\mu(F) \leq \epsilon$ tale che $f$ è limitata su $X \setminus F$.
		
		\textbf{Dimostrazione.}
		$\forall m > 0$ sia $F_m := \{ x \mid |f(x)| > m \}$ allora $F_m \downarrow \varnothing \implies \mu(F_m) \downarrow 0$ e quindi esiste $m$ tale che $\mu(F_m) \leq \epsilon$.

		Quindi data $f$ qualunque misurabile e $|X| < +\infty$ esiste $F$ misurabile tale che $|F| \leq \epsilon / 2$ e con $f$ limitata su $X \setminus F \implies f \in L^\infty(X \setminus F) \subset L^1(X \setminus F)$, dunque per il \textit{Caso 1} esiste $E$ misurabile tale che $|E| \leq \epsilon / 2$ e $f$ è continua su $X \setminus (E \cup F)$ e $\mu(E \cup F) \leq \epsilon$

	\item \textit{Caso 3}:
		$f$ qualunque misurabile

		Per ogni $n$ poniamo $X_n \coloneqq X \cap B(0, n)$ per il \textit{Caso 2} esistono $E_n$ misurabili con $|E_n| \leq \epsilon / 2^n$ tali che $f$ è continua su $X_n \setminus E_n$, infine prendo $E \coloneqq \bigcup_{n=1}^\infty E_n$ con $\mu(E) \leq \epsilon \implies f$ è continua su $X_n \setminus E$ per ogni $n \implies f$ è continua su $X \setminus E$. 

\end{itemize}
\qed

%
% Lezione dell'18 Ottobre 2021
%

\section{Appendice}

\textbf{Proposizione.} Siano $V,W$ spazi normati, $T \colon V \to W$ lineare.
Sono fatti equivalenti
\begin{enumerate}
\item $T$ è continua in $0$.

\item $T$ è continua.

\item $T$ è lipschitziana, cioè esiste una costante $c < +\infty$ tale che $\norm{Tv - Tv'}_W \leq \norm{v - v'}_V$.

\item esiste una costante $c$ tale che $\norm{Tv'} \leq c \norm{v}$ per ogni $v \in V$.

\item esiste una costante $c$ tale che $\norm{Tv}_W \leq c$ per ogni $v \in V$, $\norm{v}_V = 1$.
\end{enumerate}

\textbf{Dimostrazione.}
v) $\Rightarrow$ iv). Vale la seguente
%
$$
\norm{Tv}_W \underbrace{=}_{v = \lambda \tilde{v}, \norm{v}_V = 1} \left| \lambda \right| \norm{T \tilde{v}}_W \leq c \lambda = c \norm{v}_V \leq 1.
$$
%
iv) $\Rightarrow$ iii). Vale la seguente
%
$$
\norm{Tv - Tv'}_W = \norm{T(v - v')}_W \leq c \norm{v - v'}_W.
$$
%
iii) $\Rightarrow$ ii). \\
i) $\Rightarrow$ v). $T$ continua in $0$, dunque esiste $\delta > 0$ tale che
%
$$
\norm{Tv - T0}_W \leq 1 \quad \text{se} \quad \norm{v - 0}_V \leq \delta,
$$
%
cioè
%
$$
\norm{Tv} \leq 1 \quad \text{se} \quad \norm{v} \leq \delta,
$$
%
da cui segue che $\norm{Tv} \leq 1/ \delta$ se $\norm{v} \leq 1$.
\qed

\textbf{Osservazione.} Le costanti ottimali iii), iv), v) sono uguali e valgono
%
$$
c = \sup_{\norm{v}_V \leq 1} \norm{Tv}_W.
$$
%

\textbf{Esempi di utilizzo.}
\begin{enumerate}
\item Sia $X, \mc{A}, \mu$ coma al solito, con $\mu(X) < +\infty$.
Allora, dati $1 \leq p_1 < p_2 \leq +\infty$, vale
\begin{equation} \tag{$\star$} \label{eq:star_1}
L^{p_2}(X) \subset L^{p_1}(X).
\end{equation}
Inoltre, l'inclusione $i \colon L^{p_2}(X) \to L^{p_1}(X)$ è continua.

\textbf{Dimostrazione.} La dimostrazione di \eqref{eq:star_1} segue dalla stima
%
$$
\norm{u}_{p_1} \underbrace{\leq}_{\text{Hölder generalizzato}} \norm{\One_X}_q \norm{u}_{p_2} \quad \text{dove} \quad q = \frac{p_1 p_2}{p_2 - p_1}.
$$
%
Dove
%
$$
\norm{\One_X}_{\frac{p_1 p_2}{p_2 - p_1}} \norm{u}_{p_2} = \left( \mu(X) \right)^{\frac{1}{p_1} - \frac{1}{p_2}} \norm{u}_{p_2}.
$$
%
Quanto sopra soddisfa la condizione al punto iv).
\qed

\item L'applicazione $\ds L^1(X) \ni u \mapsto \int u \dd \mu \in \R$ è continua.

\textbf{Dimostrazione.} Infatti, vale
%
$$
\left| \int_{X} u \dd \mu \right| \leq \int_{X} \left| u \right| \dd \mu = \norm{u}_1.
$$
%
Quanto sopra soddisfa la condizione al punto iv).
\qed

\item Cosa possiamo dire invece dell'applicazione $\ds L^p(X) \ni u \mapsto \int u \dd \mu \in \R$?
Se $\mu(X) < +\infty$ la continuità segue dagli esempi i) e ii) sopra.
Se invece $\mu(X) = +\infty$? Per esempio $L^2(\R)$? [TO DO].
\end{enumerate}

\section{Convoluzione}

\textbf{Definizione.} Date $f_1,f_2 \colon  \R^d \to \R$ misurabili, il \textbf{prodotto di convoluzione} $f_1 \ast f_2$ è la funzione (da $\R^d$ a $\R$) data da
%
\begin{equation} \label{eq:star_def_convoluzione}
	f_1 \ast f_2(x) = \int_{\R^d} f_1(x-y) f_2(y) \dd y
	\tag{$\star$}
\end{equation}
%
\textbf{Osservazioni.}
\begin{enumerate}
\item La definizione \eqref{eq:star_def_convoluzione} è ben posta se $f_1,f_2 \geq 0$ ($f_1 \ast f_2(x)$ può essere anche $+\infty$).
In generale non è ben posta per funzioni a valori reali (non è detto che l'integrale esista).

\item Se $f_1 \ast f_2(x)$ esiste, allora $\ds f_1 \ast f_2(x) = f_2 \ast f_1(x)$, infatti
%
$$
f_1 \ast f_2 (x) 
= \int_{\R^d} f_1(x-y) f_2(y) \dd y 
% \underbrace{=}_{} 
= \left( 
{\footnotesize \begin{gathered}
	t \coloneqq x - y \\ 
	\dd t = \dd y
\end{gathered}}
\right) =
\int_{\R^d} f_1(t) f_2(x-t) \dd t 
= f_2 \ast f_1(x).
$$
%

\item È importante che $f_1,f_2$ siano definite su $\R^d$ e che la misura sia quella di Lebesgue.

In realtà, si può generalizzare quanto sopra rimpiazzando $(\R^d, L^d)$ con $(G,\mu)$, dove $G$ è un gruppo commutativo e $\mu$ una misura su $G$ invariante per traslazione. Per esempio, $\Z$ con la misura che conta i punti. Cioè $f_1,f_2 \colon \Z \to \R$, vale
%
$$
f_1 \ast f_2(n) \coloneqq \sum_{n \in \Z} f_1(n - m) f_2(m).
$$
%

\item Data $f$ distribuzione di massa (continua) su $\R^3$, il potenziale gravitazionale generato è
%
$$
v(x) = \int_{y \in \R^d} \frac{1}{\left| x - y \right|} \rho(y) \dd y
$$
%
cioè $v = g \ast \rho$, dove  $g (x) = 1 / \left| x \right|$ è il potenziale di una massa puntuale in $0$.

\item Se $X_1, X_2$ sono variabili aleatorie (reali) con distribuzione di probabilità continua $p_1,p_2$ e $X_1,X_2$ sono indipendenti, allora $X_1 + X_2$ ha distribuzione di probabilità $p_1 \ast p_2$. (Facile per $X_1,X_2$ in $\Z$).

\end{enumerate}

%
% Lezione dell'20 Ottobre 2021
%

% \textbf{Definizione.}
% Date $f_1, f_2 \colon \R^d \to \R$ misurabile allora il \textbf{prodotto di convoluzione} è dato da
% $$
% f_1 \ast f_2 (x) \coloneqq \int_{\R^d} f_1(x - y) f_2(y) \dd y
% $$
% e se $f_1$ e $f_2$ sono positive allora $f_1 \ast f_2(x) \in [0, +\infty]$. Ma ad esempio se prendiamo $f_1 = 1$ e $f_2 = \sin x$ con $d = 1$ allora $f_1 \ast f_2(x)$ non è definito per alcun $x$.

\textbf{Proposizione 1.}
Se $|f_1| \ast |f_2| (x) < +\infty$ allora $f_1 \ast f_2(x)$ è ben definito in quanto
$$
|f_1 \ast f_2(x)| \leq |f_1| \ast |f_2|(x)
$$
\textbf{Dimostrazione.}
Basta osservare che
$$
\int_{\R^d} |f_1(x - y) \ast f_2(y)| \dd y < +\infty 
\implies \int_{\R^d} f_1(x - y) f_2(y) \dd y
$$
e dunque esiste.
\qed

\textbf{Corollario 2.}
Se $|f_1| \ast |f_2| \in L^p(\R^d)$ con $1 \leq p \leq +\infty$ allora $f_1 \ast f_2(x)$ è ben definito per quasi ogni $x \in \R^d$ e $\norm{f_1 \ast f_2}_p \leq \norm{|f_1| \ast |f_2|}_p$.

\textbf{Dimostrazione.}
Segue subito dalla proposizione precedente.
\qed

\textbf{Teorema 3} \textit{(Disuguaglianza di Young per la convoluzione)}.
Se $f_1^{p_1}$ e $f_2 \in L^{p_2}$ e preso $r \geq 1$ tale che
\begin{equation}\label{eqn:conv_th3_cond}
	\frac{1}{r} = \frac{1}{p_1} + \frac{1}{p_2} - 1
	\tag{$\star$}
\end{equation}
allora $f_1 \ast f_2$ è ben definito quasi ovunque e
\begin{equation}\label{eqn:conv_th3_thesis}
	\norm{f_1 \ast f_2}_r \leq \norm{f_1}_{p_1} \cdot \norm{f_2}_{p_2}
	\tag{$\star\star$}
\end{equation}

\textbf{Osservazioni.}
\begin{itemize}
	\item 
		Nel caso di prima $1$ e $\sin x$ sono solo in $L^\infty$ infatti viene $r = -1$ e la disuguaglianza non ha senso.

	\item
		Supponiamo di avere $\norm{f_1 \ast f_2} \leq C \cdot \norm{f_1}_{p_1}^{\alpha_1} \cdot \norm{f_2}_{p_2}^{\alpha_2}$ allora vediamo che per ogni $f_1, f_2$ positiva deve valere necessariamente $\alpha_1 = \alpha_2 = 1$ e la condizione (\ref{eqn:conv_th3_cond}).

		\textbf{Dimostrazione.}
		Per ogni $\lambda > 0$ consideriamo $\lambda f_1$ e $f_2$, allora 
		$$
		\norm{(\lambda f_1) \ast f_2}_r = \norm{\lambda (f_1 \ast f_2)}_r = \lambda \norm{f_1 \ast f_2}_r
		$$
		ma abbiamo anche
		$$
		\norm{(\lambda f_1) \ast f_2}_r \leq C \cdot \norm{f_1}_{p_1}^{\alpha_1} \cdot \norm{f_2}_{p_2}^{\alpha_2} = C \cdot \lambda^{\alpha_1} \norm{f_1}_{p_1} \cdot \norm{f_2}_{p_2}
		$$
		A questo punto richiediamo anche che $f_1$ e $f_2$ siano tali che $\norm{f_1}_{p_1}, \norm{f_2}_{p_2} < +\infty$ e $\norm{f_1 \ast f_2} > 0$ (questo possiamo farlo in quanto basta prendere $f_1 = f_2 = \One_B$ con $B$ una palla, nel caso segue proprio che $f_1 \ast f_2 (x) > 0$ se $|x| < 1$).

		Data $f \colon \R^d \to \R$ e $\lambda > 0$ poniamo $R_{\lambda} f(x) \coloneqq f(\frac{x}{\lambda})$ allora abbiamo
		$$
		\norm{(R_\lambda f_1) \ast (R_\lambda f_2)}_r 
		= \lambda^{d \left( 1 + \frac{1}{r} \right)} \norm{f_1 \ast f_2}_r 
		$$
		ma anche
		$$
		\norm{(R_\lambda f_1) \ast (R_\lambda f_2)}_r 
		\leq C \cdot \norm{R_\lambda f_1}_{p_1} \cdot \norm{R_\lambda f_2}_{p_2}
		= \lambda^{d(\frac{1}{p_1} + \frac{1}{p_2})} \cdot \norm{f_1}_{p_1} \cdot \norm{f_2}_{p_2}
		$$
		dunque sicuramente abbiamo $\lambda^{d \left(1 + {1 / r} \right)} \leq C \cdot \lambda^{d\left( {1 / p_1} + {1 / p_2} \right)}$ per ogni $\lambda > 0$ e quindi $1 + {1 / r} = {1 / p_1} + {1 / p_2} \iff$ (\ref{eqn:conv_th3_cond}).
		\qed

	\item
		$\norm{R_\lambda f}_p = \lambda^{d / p} \norm{f}_p$ ed in realtà possiamo ricavare l'esponente $d / p$ per \textit{analisi dimensionale}\footnote{Ovvero studiando le potenze delle unità di misura delle varie quantità.}\footnote{In particolare ad Istituzioni di Analisi si vedono le disuguglianze di Sobolev ed anche in quel caso tutte le condizioni sugli esponenti si riescono a ricavare per analisi dimensionale...}. Consideriamo l'espressione
		$$
		\norm{f}_p^p = \int_{\R^d} f(x) \dd x
		$$
		se $f(x)$ è una \textit{quantità adimensionale} e $\int_{\R^d} f \dd x$ ha dimensione di una \textit{lunghezza} $L^d$ allora $\norm{f}_p$ ha dimensione di $L^{d / p}$.

		Similmente per ottenere $\norm{R_\lambda(f_1 \ast f_2)}_r = \lambda^{d(1 + 1 / r)} \norm{f_1 \ast f_2}_r$ basta osservare che nell'espressione
		$$
		f_1 \ast f_2 (x) = \int_{\R^d} f_1(x - y) f_2(y) \dd y
		$$
		dunque $f_1 \ast f_2 (x)$ ha dimensione $L^d$ da cui
		$$
		\norm{f_1 \ast f_2}_r = \bigg( \int_{\R^d} \underbrace{|f_1 \ast f_2|^r}_{L^{dr}} \underbrace{\dd x}_{L^d} \bigg)^{1 / r}
		$$
		e quindi $\norm{f_1 \ast f_2}_r$ ha dimensione di $L^{d(1 + 1/r)}$.
\end{itemize}

\textbf{Dimostrazione Teorema 3.}
Per via del Corollario 2. ci basta dimostrare (\ref{eqn:conv_th3_thesis}) se $f_1, f_2 \geq 0$.
\begin{itemize}
	\item
		\textit{Caso facile.} Se $p_1 = p_2 = 1$ e $r = 1$
		$$
		\begin{aligned}
			\norm{f_1 \ast f_2}_1
			&= \int f_1 \ast f_2 (x) \dd x 
			= \iint f_1(x - y) f_2(y) \dd y \dd x 
			= \int f_2(y) \int f_1(x - y) \dd x \dd y = \\
			&= \int \norm{f_1}_1 \cdot f_2(y) \dd y 
			= \norm{f_1}_1 \cdot \norm{f_2}_1
		\end{aligned}
		$$

	\item
		\textit{Caso leggermente meno facile.} Se $p_1 = p, p_2 = 1$ e $r = p$.
		Vogliamo vedere che
		$$
		\norm{f_1 \ast f_2}_p \leq \norm{f_1}_p \cdot \norm{f_2}_1
		$$
		allora
		$$
		\begin{aligned}
			\norm{f_1 \ast f_2}_p
			&= \int_{\R^d} (\underbrace{f_1 \ast f_2}_{h})^p \dd x
			= \int h \cdot h^{p-1} \dd x 
			= \iint f_1(x - y) f_2(y) h^{p-1}(x) \dd y \dd x = \\
			&= \iint f_1(y - x) h^{p-1}(x) \dd x f_2(y) \dd y 
			\overset{\text{H\"older}}{\leq} 
			\int \norm{f_1(y - \curry)}_p {\| h^{p-1} \|}_{p'} f_2(y) \dd y
		\end{aligned}
		$$
		con $p'$ esponente coniugato a $p$. Inoltre notiamo che $\norm{f_1(y - \curry)}_p = \norm{f_1}$ per invarianza di $\mathscr L^d$ per riflessioni e traslazioni, infine otteniamo
		$$
		= \norm{f_1}_p {\| h^{p-1} \|}_{p'} \norm{f_2}_1
		= \norm{f_1}_p \norm{h}_{p'}^{p-1} \norm{f_2}_1
		$$
		$\implies \norm{f_1 \ast f_2}_p^p \leq \norm{f_1 \ast f_2}_p^{p-1} \norm{f_1}_p \norm{f_2}_1 \implies \norm{f_1 \ast f_2}_p \leq \norm{f_1}_p \norm{f_2}_1$. Questo però solo nel caso in cui valga $0 < \norm{f_1 \ast f_2}_p < +\infty$, resterebbero da controllare i due casi in cui la norma è $0$ oppure $+\infty$, il primo è ovvio, il secondo invece si fa per approssimazione e passando al limite.

		Consideriamo $f_1, f_2$ e approssimiamole con $f_{1,n}, f_{2,n}$ limitate a supporto compatto, allora vale $\norm{f_{1,n} \ast f_{1,n}}_p \leq \norm{f_{1,n}}_p \cdot \norm{f_{2,n}}_1$ e passando al limite si ottiene la tesi. In particolare possiamo costruire le $f_n$ come
		$$
		f_n(x) \coloneqq (f(x) \cdot \One_{\mc B(0, n)}(x)) \land n
		$$

		\textbf{Osservazione.}
		Se $f_2 \geq 0$ e $\int f_2 \dd x = 1$ allora $\norm{f_1 \ast f_2}_p \leq \norm{f_1}_p$ è una versione semplificata della proposizione precedente, in particolare la dimostrazione si semplifica in quanto possiamo pensare a $f_2$ come distribuzione di probabilità e quindi $f_1 \ast f_2$ è una ``media pesata'' delle traslazioni di $f_1$ o più precisamente una combinazione convessa ``integrale''.

	\item
		\textit{Caso generale.} Non lo facciamo perché servono mille mila parametri e non è troppo interessante.
\end{itemize}
\qed

\textbf{Teorema 4.}
Se $p_1$ e $p_2$ sono coniugati e $r = +\infty$ abbiamo un risultato più forte ovvero valgono
\begin{enumerate}
	\item \label{item:20ott_th4_1} 
		$f_1 \ast f_2(x)$ è ben definito per ogni $x \in \R^d$

	\item \label{item:20ott_th4_2}
		$|f_1 \ast f_2(x)| \leq \norm{f_1}_{p_1} \norm{f_2}_{p_2}$

	\item \label{item:20ott_th4_3} 
		$f_1 \ast f_2$ è uniformemente continua

	\item \label{item:20ott_th4_4}
		Se $1 < p_1, p_2 < +\infty$ allora $f_1 \ast f_2 \to 0$ per $|x| \to +\infty$
\end{enumerate}

\textbf{Dimostrazione \ref{item:20ott_th4_1} e \ref{item:20ott_th4_2}.}
Seguono subito da (\ref{eqn:conv_th3_cond}) per $f_1, f_2 \geq 0$ (con il Corollario 2.), se $f_1, f_2 \geq 0$ allora
$$
f_1 \ast f_2 (x) 
= \int_{\R^d} f_1(x - y) f_2(y) \dd y 
\leq \norm{f_1(x - \curry)}_{p_1} \norm{f_2}_{p_2} 
= \norm{f_1}_{p_1} \norm{f_2}_{p_2}
$$

\textbf{Proposizione 5.}
Data $f \in L^p(\R^d)$ con $p < +\infty$ la mappa
$$
\begin{array}{cccc}
	\tau_h f : & \R^d & \to & L^p(\R^d) \\
	& h & \mapsto & f(\curry - h)
\end{array}
$$
è continua.

\textbf{Lemma 6.}
Lo spazio $C_0(\R^d) = \{ f \colon \R^d \to \R \text{ continue con } f(x) \to 0 \text{ per } |x| \to 0 \}$ è chiuso rispetto alla convergenza uniforme.

\textbf{Dimostrazione \ref{item:20ott_th4_3}.} 
Supponiamo $p_1 < +\infty$ allora
$$
\begin{aligned}
	|f_1 \ast f_2(x + h) - f_1 \ast f_2(x)|
	&\leq \int |f_1(x + h - y) - f_1(x - y)| \cdot |f_2(y)| \dd y \\
	&\leq \norm{f_1(x + h - \curry) - f(x - \curry)}_{p_1} \norm{f_2}_{p_2} \\
	&= \norm{\tau_h f_1 - f_1}_{p_2} \norm{f_2}_{p_2}
\end{aligned}
$$
\qed

%
% Lezione del 21 Ottobre 2021 
%

\section{Esercitazione del 21 ottobre}

% Piccolo recap di quanto fatto le scorse lezioni.

Data $T \colon X \to Y$ lineare tra $X,Y$ spazi normati, allora $T$ è continua se solo se $T$ è limitata.
In altre parole, $T$ è continua se solo se esiste  $C > 0$ tale che $\norm{T(x)}_Y \leq C \norm{x}_X$ per ogni $x \in X$.

Applichiamo questo risultato.

\begin{enumerate}
\item Sia $X = \R^d$. L'applicazione $\ds L^1(\R^d) \ni u \xmapsto{\; T \;} \int_{\R^d} u \dd x$ è lineare e continua in quanto limitata. Infatti:
%
$$
\left| T(u) \right| = \left| \int_{\R^d} u \dd x  \right| \leq \int_{\R^d} \left| u \right| \dd x = \norm{u}_{L^1(\R^d)}.
$$
%

\item Studiamo ora il caso per $p > 1$. Data $u \in L^p(\R^d)$, l'applicazione
%
$$
u \mapsto \int_{\R^d} u \dd x 
$$
%
potrebbe non essere ben definita.

Ad esempio se restringiamo il dominio a $L^p(\R^d) \cap L^1(\R^d)$ l'applicazione sopra è ben definita, ma in generale non è continua.
Più formalmente, la mappa
%
$$
T \colon \left( L^p \cap L^1(\R^d), \norm{\cdot}_{L^p} \right) \to \R
$$
%
è lineare ma non continua.

\textbf{Osservazione.} Dobbiamo cercare una funzione tale per cui non esista $C$ per cui
%
$$
\left| \int_{\R} u \dd x  \right| \leq C \left( \int_{\R} \left| u \right|^p \dd x  \right)^{1/p}.
$$
%
Studiamo il caso reale, ovvero $d = 1$.

\textbf{Nota.} Le funzioni limitate soddisfano la disuguaglianza sopra (per Hölder), dunque non possono essere utilizzate come controesempio. 

Usiamo la nozione di continuità per successioni per mostrare che la mappa sopra non è continua. Per farlo definiamo una successione di funzioni a supporto compatto (che sappiamo essere in tutti gli spazi $L^p$).

Definiamo la successione come segue (fare disegno):
%
$$
u_n (x) =
\begin{cases}
\frac{1}{n} \quad \text{se} \quad n \leq x \leq 2n \\
0 \quad \text{altrimenti} 
\end{cases} 
$$
%
Dunque, $\ds T(u_n) = \int_{\R} u_n \dd x = \frac{1}{n} \left| E_n \right| = 1$, dove $E_n = [n,2n]$.
Segue che $T(u_n) \equiv 1$ e non è vero che $T(u_\infty = u_n \to 0) = 0$.

Più in generale, quando $u \in L^p(\R^d)$ con $p > 1$, una costruzione come sopra non funziona, infatti
%
$$
\norm{u_n}_{L^p(\R)}^p = \int_{\R} u_n^p(x) \dd x = \frac{1}{n^p} \cdot \left| E_n \right| = \frac{n}{n^p} = \frac{1}{^{p-1}} \xrightarrow{n \to \infty} 0.
$$
%

\end{enumerate}

\textbf{Esercizio.} [TO DO] Fissato $C > 0$, trovare $u \in L^p \cap L^1 (\R)$ tale che
%
$$
\left| \int_{\R} u \dd x\right| \geq C \norm{u}_{L^p(\R)}
$$
%

%%%
\textbf{Esercizio.} Sia $p \geq 1$ e $\ds E = \left\{ u \in L^p(-1,1) \colon \fint_{-1}^1 u \dd x = 0 \right\}$.

\begin{enumerate}
\item Dire se $E$ è limitato in $L^p(-1,1)$.

\item Dire se $E$ è chiuso in $L^p(-1,1)$.
\end{enumerate}

\textbf{Soluzione.}
\begin{enumerate}
\item Dimostrare che $E$ è limitato in $L^p(-1,1)$ equivale a dimostrare che esiste $M > 0$ tale che ogni  $u \in L^p(-1,1)$, $\ds \fint_{-1}^1 u \dd x = 0$ verifica $\norm{u}_{L^p} \leq M$.

Vediamo che $E$ non è limitato.
Preso $M > 0$, riesco sempre a trovare una funzione maggiore di $M$ in norma.
Ad esempio la funzione definita come
%
$$
u(x) \coloneqq
\begin{cases}
M \quad \text{se} \quad x \in (0,1) \\
-M \quad \text{se} \quad x \in (-1,0)
\end{cases} 
$$
%
ha norma $\ds \norm{u}_{L^p}^p = 2 M^p$.

\textbf{Nota.} Aveva senso cercare il controesempio nella classe delle funzioni dispari e limitate, perché hanno media zero, e perché sono in tutti gli $L^p$.

\item Vediamo che $E$ è chiuso.

\textbf{Nota.} Possiamo dimostrarlo usando i teoremi di convergenza, ma seguiremo un'altra strada.

\begin{itemize}
\item \textit{Caso} $p > 1$. Definiamo l'operatore 
\begin{align*}
T \colon L^p(-1,1) & \to \R \\
u & \mapsto \int_{-1}^{1} u \dd x 
\end{align*}
è ben definito.
Infatti, per Hölder vale
%
$$
\left| \int_{-1}^{1} 1 \cdot u \dd x  \right| \leq \left( \int_{-1}^{1} \left| u \right|^p \dd x  \right)^{1/p} \left( 1^q \right)^{1/q}
$$
%
dove $q = \frac{p}{p-1}$.
Allora
 %
$$
\left| T(u) \right| \leq \norm{u}_{L^p(-1,1)} \cdot 2^{\frac{p}{p-1}}.
$$
%
Dunque $T$ è continuo in $L^p$ per ogni $p > 1$.

\item \textit{Caso} $p = 1$. L'operatore sopra è continuo anche per $p = 1$. Grazie alla stima vista prima
%
$$
\left| T(u) \right| = \left| \int_{-1}^{1} u \dd x  \right| \leq \int_{-1}^{1} \left| u \right| \dd x = \norm{u}_{L^1}.
$$
%
Dunque $T$ è continua e $T^{-1}(0) = E$, dunque $E$ è chiuso.

\end{itemize}

\end{enumerate}

\textbf{Esercizio.} [TO DO] Sia $p \geq 1$. Definiamo 
%
$$
F = \left\{ v \in L^p(\R) \mymid \int_{0}^{1} u(x) \dd x - 2 \int_{-1}^{0} u(x) \dd x = 3 \right\}.
$$
%
Dire se $F$ è chiuso in $\left( L^p(\R), \norm{\cdot }_{L^p(\R)} \right)$.


\textbf{Esercizio.} [TO DO] Sia 
%
$$
G = \left\{ v \in L^p(0,2\pi) \mymid \int_{0}^{2\pi} v(x) \sin(x) \dd x = 1  \right\}.
$$
%
Dire se $G$ è chiuso in $L^2(0,2\pi)$.

\textbf{Domanda.} Dato $L^p (X,\mu)$ e $V$ sottospazio di $L^p(X,\mu)$, posso dire che $V$ è chiuso?

In generale no! Infatti esistono sottospazi densi in $L^p(X,\mu)$.

Ad esempio in $\ell^2$ consideriamo l'insieme denso
%
$$
V = \left\{ \left\{ x_n \right\} \mymid x_n = 0 \quad \text{definitivamente}  \right\}.
$$
%
Vediamo che non è chiuso. Sia $\underline{x} \in \ell^2$, definita come $\underline{x} = \{ 1 / n \}_{n \in \N \setminus \{0 \}}$, dico che $\ds \underline{x} = \lim_{n \to +\infty} \underline{x}^n$ dove
%
$$
x_n^k = 
\begin{cases}
\frac{1}{n} \quad 1 \leq n \leq k \\
0 \quad n > k, n = 0
\end{cases} 
$$
%
ho che
%
$$
\norm{\underline{x} - \underline{x}^k}_{\ell^2}^2 = \sum_{n=1}^{\infty} \left| x_n -x_n^k \right|^2 = \sum_{n = k+1}^{+\infty} \left| x_n \right|^2 = \sum_{n = k+1}^{\infty} \frac{1}{n^2} \xrightarrow{k \to +\infty} 0.   
$$
%

Vediamo un altro esempio. Siano $X = \R$, $\mu$ la misura di Lebesgue e $p > 1$.
In tal caso, l'insieme $L^p \cap L^1 (\R)$ è un sottospazio denso in $\left( L^1(\R), \norm{\cdot }_{L^1} \right)$ e $\left( L^p(\R), \norm{\cdot }_{L^p} \right)$.

\textbf{Nota.} L'insieme $L^2(\R) \cap L^1(\R)$ è un sottospazio proprio di $L^1(\R)$. Dico che non è chiuso in $\norm{\cdot }_{L^1(\R)}$ perché è denso.
Infatti, 
%
$$
\mc{C}_C^0(\R) \subset L^2(\R) \cap L^1(\R).
$$
%

\subsection{Convoluzione}

Sia $f \in L^1(\R^d)$ e sia $g$ supporto compatto $K$ e lipschitziana, vale a dire esiste $M > 0$ tale che per ogni $x,y $ vale
%
$$
\left| g(x) - g(y) \right| \leq M \left| x - y \right|_{\R^d}.
$$
%


\textbf{Esercizio.} Dimostrare che $f \ast g$ è ben definita e lipschitziana, dove $f \in L^1(\R^d)$ e $g \in \mc{C}_C^0 (\R^d)$.

Prendo $x_1,x_2 \in \R^d$
%
$$
\left| f \ast g (x_1) - f \ast g(x_2) \right| = \left| \int_{\R^d} f(x_1 - x) g(y) \dd y  - \int_{\R^d} f(x_2 - y) g(y) \dd y  \right|
$$
%
Uso la proprietà che essendo ben definita, $f \ast g$ si ha $ f \ast g(x) = g \ast f(x) $, dai cui
\begin{align*}
\left| f \ast g(x_1) - f \ast g(x_2) \right|  & = \left| \int_{\R^d} g(x_1 - y) f(y) \dd y \int_{\R^d} g(x_2 - y) f(y) \dd y   \right| \\
& = \left| \int_{\R^d} \left( g(x_1 - y) - g(x_2 - y) \right) f(y) \dd y  \right| \\
& \leq \int_{\R^d} \left| g(x_1 - y) - g(x_2 - y) \right| \left| f(y) \right| \dd y \\
& \leq \int_{\R^d} M \left| x_1 - y - (x_2 - y) \right| \left| f(y) \right| \dd y \leq M \left| x_1 - x_2 \right| \cdot \norm{f}_{L^1(\R^d)}.
\end{align*}

\textbf{Esercizio.} [TO DO] Se $f \in L^1(\R^d)$ e $g$ a supporto compatto è $\alpha$-Hölderiana allora anche $f \ast g$ lo è.

\textbf{Esercizio.} [TO DO] Presa $f(x) = \One_{[0,1]}$ in $\R$, calcolare $f \ast f$.

\subsection{Separabilità degli spazi $L^p$}

\textbf{Proposizione.} Si ha che $L^p\left( \R^d, \mu \right)$ con $\mu $ la misura di Lebesgue, è separabile se solo se $p \neq +\infty$. Lo stesso risultato vale per $\ell^p$.

Sia $1 \leq p < +\infty$, $L^p(\R^d, \mu)$ con $\mu$ la misura di Lebesgue.
Le funzioni semplici costituite da somme finite di insiemi di misura finita sono dense in $L^p(\R^d)$.

Prendiamo una base numerabile di $\R^d$ e la indichiamo con $\mc{B}$. L'insieme
%
$$
Y = \left\{ \sum_{i=1}^{n} \alpha_i \One_{B_i} \mymid B_i \in \mc{B}, \alpha_i \in \Q \right\}
$$
%
è numerabile. Vediamo che è denso in $L^p(\R^d)$.

\textit{Idea.} È sufficiente approssimare le funzioni semplici a somma finita $\sum_{i=1}^{N} \alpha_i \One_{E_i} $. In particolare, mi basta approssimare $\alpha \cdot \One_E$. Essendo $\alpha \in \R$ trovo una successione di razionali $\alpha_j$ tali che $\alpha_j \xrightarrow{j \to \infty} \alpha$. Dunque, rimane da approssimare l'insieme $E$.

Fissiamo $E$ e supponiamo dapprima $E$ aperto. Possiamo scrivere $E$ come unione arbitraria di elementi della base $\mc{B}$
%
$$
E = \bigcup_{i = 1}^\infty B_i.
$$
%
Per approssimare $E$ considero gli insiemi $E_N = \bigcup_{i = 1}^N B_i$.
Otteniamo $\ds \left| E \right| = \lim_N \left| E_N \right|$, da cui $\left| E \setminus E_N \right| \xrightarrow{N \to +\infty} 0$.
Concludiamo notando che il caso $E$ arbitrario si fa approssimandolo con una famiglia di aperti.

\vspace{3mm}

Per $\ell^p$ con $p < +\infty$ definisco
%
$$
Y = \left\{ \left\{ x_n \right\} \mymid x_n = 0 \quad \text{definitivamente}, x_n \in \Q \right\}
$$
%
e verifico che è numerabile e separabile.

\textbf{Domanda.} Cosa succede per $p = +\infty$?

Considero $L^\infty ([0,+\infty], \mu)$ con $\mu$ di Lebesgue e $E_n = [n,n+1]$.
Definisco l'insieme
 %
$$
Z = \left\{ \forall J \subset \N \quad u = \sum_{j \in J} \One_{E_j} \right\}.
$$
%
$Z$ ha la cardinalità delle parti di $\N$ cioè è più che numerabile. Osserviamo che per ogni $u,v \in Z$, $u \neq v$ si ha che $\norm{u - v}_{L^\infty(\R)} = 1$.
Se per assurdo esistesse un insieme denso e numerabile $D$ in $\ell^\infty$, per definizione di insieme denso dovremmo trovare per ogni palla di raggio minore di 1 e centro in un qualsiasi elemento di $Z$, un elemento di $D$. Ma questo è impossibile in quanto $D$ ha cardinalità numerabile e $Z$ la cardinalità del continuo.

Vediamo in un altro modo che $l^\infty$ non è separabile. 
Se per assurdo $Y = \left\{ \underline{x}^k \right\}_{k \in \N}$ fosse denso in $L^\infty$, allora potremmo definire un elemento $z \in l^\infty$ tale che $\norm{\underline{x}^k - \underline{z}}_{l^\infty} \geq 1$ per ogni $k$.

Definiamo $z = \left\{ z_n \right\}$ come segue
%
$$
z_n = 
\begin{cases}
0 \quad \text{se} \quad | x_n^n | > 1 \\
2 \quad \text{se} \quad | x_n^n | \leq 1
\end{cases}. 
$$
%
%
% Lezione del 25 Ottobre 2021
%

% @aziis98: Secondo me possiamo rilocarle abbastanza le cose di questa lezione boh
\section{Aggiunte sulle lezioni precedenti}

\textbf{Proposizione.}
Data $f \in L^p(\R^d)$ con $1 \leq p < +\infty$ allora la funzione $\tau_h f \colon \R^d \to L^p(\R^d)$ data da $\tau_h f(x) \coloneqq f(x - h)$ è continua.

\textbf{Dimostrazione.}
Per prima cosa notiamo che basta vedere solo la continuità in $0$ in quanto
$$
\tau_{h'} f - \tau_h f = \tau_{h} (\tau_{h' - h} f - f) 
\implies \norm{\tau_{h'} f - \tau_{h} f}_p = \norm{\tau_{h' - h} f - f}_p
$$
dimostriamo ora la proposizione in due passi
\begin{itemize}
	\item
		\textit{Caso 1:} $f \in C_C(\R^d)$
		$$
		\norm{\tau_h f - f}_p^p 
		= \int_{\R^d} |f(x - h) - f(x)|^p \dd x \xrightarrow{|h| \to 0} 0
		$$
		per convergenza dominata, verifichiamo però che siano rispettate le ipotesi
		\begin{enumerate}
			\item
				La convergenza puntuale, ovvero $|f(x - h) - f(x)|^p \xrightarrow{|h| \to 0} 0$ segue direttamente dalla continuità di $f$.
			\item
				Come dominazione invece usiamo $|f(x - h) - f(x)|^p \leq (2 \norm{f}_\infty)^p \cdot \One_{\mc B(0, R + 1)}$ usando che $f \in C_C \implies \operatorname{supp}(f) \subset \overline{B(0, R)}$ e poi che 
				$$
				\operatorname{supp}(f(\curry - h) - f(\curry)) \subset \overline{\mc B(0, R + |h|)}
				$$
				infine se $|h| < 1$ come raggio ci basta prendere $R + 1$.
		\end{enumerate}
	\item 
		\textit{Caso 2:} $f$ qualunque
		Dato $\epsilon > 0$ prendiamo $g \in C_C(\R^d)$ tale che $\norm{g - f} \leq \epsilon$ allora aggiungiamo a sottraiamo $g + \tau_h g$ e raggruppiamo in modo da ottenere
		$$
		\begin{gathered}
			\tau_h f - f = \tau_h(f - g) + (\tau_h g - g) + (g - f) \\
			\implies \norm{\tau_h f - f}_p 
			\leq \underbrace{\norm{\tau_h(f - g)}_p}_{\leq \epsilon} 
			+ \norm{\tau_h g - g}_p
			+ \underbrace{\norm{g - f}_p}_{\leq \epsilon} 
			\leq 2 \epsilon + \underbrace{\norm{\tau_h g - g}_p}_{\to 0 \text{ per \textit{Caso 1}}}
		\end{gathered}
		$$
		dunque $\limsup_{|h| \to 0} \norm{\tau_h f - f}_p \leq 2\epsilon$ ma per arbitrarietà di $\epsilon$ otteniamo anche che $\norm{\tau_h f - f}_p \to 0$ per $|h| \to 0$.
\end{itemize}
\qed

\textbf{Teorema.}
Siano $f_1 \in L^{p_1}(\R^d)$ e $f_2 \in L^{p_2}(\R^d)$ con $p_1$ e $p_2$ esponenti coniugati, allora $f_1 \ast f_2$ è definita per ogni $x$ e uniformemente continua e
$$
\forall x \quad |f_1 \ast f_2(x)| \leq \norm{f_1}_{p_1} \cdot \norm{f_2}_{p_2}
$$

\textbf{Dimostrazione.}
Prendiamo $f_{1,n}, f_{2, n} \in C_C(\R^d)$ tali che $f_{1, n} \to f_1$ in $L^{p_1}$ e $f_{2, n} \to f_2$ in $L^{p_2}$.
\begin{itemize}
	\item 
		Per prima cosa notiamo che $f_{1,n} \ast f_{2,n}$ ha supporto limitato, infatti se $\supp(f_{i,n}) \subset \overline{\mc B(0, r_{i,n})}$ per $i = 1, 2$ allora
		$$
		\supp(f_{1,n} \ast f_{2,n}) \subset \overline{\mc B(0, r_{1,n} + r_{2,n})}
		$$
		e basta notare che l'espressione
		$$
		f_1 \ast f_2(x) = \int_{\R^d} f_1(x - y) f_2(y) \dd y
		$$
		ha integranda nulla per ogni $y$ se $|x| \geq r_{1,n} + r_{2,n}$.
	
	\item
		Vediamo che $f_{1,n} \ast f_{2,n} \to f_1 \ast f_2$ uniformemente
		$$
		f_{1,n} \ast f_{2,n} - f_1 \ast f_2 
		= (f_{1,n} - f_1) \ast f_{2,n} - f_1 \ast (f_{2,n} - f_2)
		$$
		$$
		\begin{aligned}
			\norm{f_{1,n} \ast f_{2,n} - f_1 \ast f_2}_p
			&\leq \norm{(f_{1,n} - f_1) \ast f_{2,n}}_\infty - \norm{f_1 \ast (f_{2,n} - f_2)}_\infty \\
			&\leq 
			\underbrace{\norm{f_{1,n} - f_1}_{p_1}}_{\to 0}
			\cdot \underbrace{\norm{f_{2,n}}_{p_2}}_{\to \norm{f_2}_{p_2}}
			+ \underbrace{\norm{f_1}_{p_1}}_{\text{cost.}}
			\cdot \underbrace{\norm{f_{2,n} - f_2}_{p_2}}_{\to 0}
			\to 0
		\end{aligned}
		$$

	\item 
		$C_0(\R^d)$ è chiuso per convergenza uniforme [TODO: da fare per esercizio]
\end{itemize}

\section{Derivata e Convoluzione}

\textbf{Osservazione.}
Osserviamo che la convoluzione si comporta bene con l'operatore di traslazione definito precedentemente, infatti $\tau_h (f_1 \ast f_2) = (\tau_h f_1) \ast f_2$ in quanto
$$
f_1 \ast f_2 (x - h) 
= \int f_1(x - h - y) \cdot f_2(y) \dd y = \int \tau_h f(x - y) \cdot f_2(y) \dd y
= (\tau_h f_1) \ast f_2
$$
quindi ``formalmente'' possiamo calcolare il seguente rapporto incrementale
$$
\frac{\tau_h(f_1 \ast f_2) - f_1 \ast f_2}{h}
= \frac{\tau_h f_1 - f_1}{h} \ast f_2
\implies (f_1 \ast f_2)' = (f_1)' \ast f_2
$$

Vediamo ora di formalizzare questo risultato

\textbf{Teorema.}
Dati $p_1$ e $p_2$ esponenti coniugati
\begin{itemize}
	\item se $f_1 \in C^1(\R^d)$ allora $f_1, \Lambda f_1 \in L^{p_1}(\R^d)$

	\item se $f_2 \in L^{p_2}(\R^d)$ allora $f_1 \ast f_2 \in C^1$ con $\Lambda(f_1 \ast f_2) = (\Lambda f_1) \ast f_2$ cioè
		$$
		\frac{\pd}{\pd x}(f_1 \ast f_2) = \left( \frac{\pd f_1}{\pd x_i} \right) \ast f_2 
		\quad
		\text{per } i = 1, \dots, d
		$$

\end{itemize}

\textbf{Dimostrazione.}
\begin{itemize}
	\item $d = 1$:
		Sappiamo che $f_1 \ast f_2$ è continua e $f_1' \ast f_2$ è continua, vediamo che coincidono usando il teorema fondamentale del calcolo integrale, infatti $(f_1 \ast f_2)' = f_1' \ast f_2$ segue da
		$$
		\int_a^b f_1' \ast f_2 \dd x = f_1 \ast f_2(b) - f_1 \ast f_2(a)
		\quad \forall a < b
		$$
		ed in effetti
		$$
		\begin{aligned}
			\int_a^b f_1 \ast f_2 (x) \dd x
			&= \int_a^b \int_{-\infty}^\infty f_1'(x - y) f_2(y) \dd y \dd x \\
			&\overset{\text{($*$)}}{=} \int_{-\infty}^\infty \int_a^b f_1'(x - y) \dd x \cdot f_2(y) \dd y \\
			&= \int_{-\infty}^\infty (f_1(b - y) - f_1(a - y)) \cdot f_2(y) \dd y \\
			&= \int_{-\infty}^\infty f_1(b - y) f_2(y) \dd y - \int_{-\infty}^\infty f_1(a - y) f_2(y) \dd y \\
			&= f_1 \ast f_2(b) - f_1 \ast f_2(a) \\
		\end{aligned}
		$$
		in particolare in ($*$) stiamo usando Fubini-Tonelli in quanto
		$$
		\int_a^b \int_{-\infty}^\infty |f_1'(x-y)| \cdot |f_2(y)| \dd y
		\leq \int_a^b \norm{f_1'(x - \curry)}_{p_1} \cdot \norm{f_2}_{p_2} \dd x 
		= \norm{f_1'}_{p_1} \cdot \norm{f_2}_{p_2} \cdot (b - a)
		$$

	\item
		per $d > 1$ dato $i = 1, \dots, d$ basta semplicemente considerare le proiezioni infatti
		$$
		\int_a^b \frac{\pd f_1}{\pd x_i} \ast f_2 (x_1, \dots, \overset{\text{($i$)}}{t}, \dots, x_d) \dd t
		= f_1 \ast f_2 (x_1, \dots, \overset{\text{($i$)}}{b}, \dots, x_d) - f_1 \ast f_2 (x_1, \dots, \overset{\text{($i$)}}{a}, \dots, x_d)
		$$
\end{itemize}

\textbf{Corollario.}
Data $f_1 \in C_C^\infty(\R^d)$ (da cui segue $\Lambda^k \in L^q(\R^d)$ per ogni $k = 0, 1, \dots$ e $1 \leq q < +\infty$) e $f_2 \in L^p(\R^d)$ allora $f_1 \ast f_2 \in C^\infty(\R^d)$ (anzi $\Lambda^k(f_1 \ast f_2) \in C_0(\R^d)$ per ogni $k$) e vale la formula nota\footnote{Vista in termini di gradienti la formulazione è più compatta ma non poi così intuitiva, bisognerebbe definire la convoluzione tre una funzione a valori vettoriali ed uno scalare etc... Altrimenti basta scrivere le singole identità usando \textit{derivate parziali e multiindici}.}
$$
\Lambda^k (f_1 \ast f_2) = (\Lambda^k f_1) \ast f_2
$$

\textbf{Dimostrazione.}
Dimostriamo il corollario per approssimazione usando il seguente teorema

\begin{wrapfigure}{r}{200pt}
	\centering
	\vspace{-1.5\baselineskip}
	\inputfigure{sigma-delta-transform}
	\vspace{-2.5\baselineskip}
\end{wrapfigure}

\textbf{Definizione.} 
Per prima cosa data una funzione $g \colon \R^d \to \R$ e $\delta \neq 0$ poniamo
$$
\sigma_\delta g(x) \coloneqq \frac{1}{\delta^d} g\left( \frac{x}{\delta} \right)
$$
e notiamo che questa trasformazione preserva la norma $L^1$.

\textbf{Teorema.}
Data $g \in L^p(\R^d)$ e $g \in L^1(\R^d)$ con $1 \leq p < +\infty$ e posto
$$
m \coloneqq \int_{\R^d} g(x) \dd x
$$
allora $f \ast \sigma_\delta g \xrightarrow{\delta \to 0} m f$ in $L^p(\R^d)$.

\textbf{Osservazione.}
Se $g_2 \geq 0$ con $\int g \dd x = 1$ (dunque $g$ distribuzione di probabilità) allora $f \ast g$ possiamo pensarla come media pesata di traslate di $f$, dunque facendo $f \ast \sigma_\delta g$ stiamo pesando sempre di più i valori delle traslate vicino a $0$. 

Inoltre per $p = +\infty$ non vale ed il controesempio è sempre il solito.

\textbf{Dimostrazione.}
Per ora consideriamo $g$ generica e ripercorriamo una dimostrazione simile a quella fatta per la disuguaglianza di Young [TODO: ricontrollare: o Minkowski??]
$$
\begin{aligned}
	\norm{f \ast g - m f}_p^p 
	&= \int_{\R^d} {\underbrace{|f \ast g - m f|}_h}^p \dd x \\
	&= \int |f \ast g - m f| \cdot h^{p-1} \dd x \\
	&= \int \left| \int \left( f(x - y) g(y) - f(x) \int g(y) \right) \dd y \right| \cdot h^{p-1}(x) \dd x \\
	&\leq \int \int |f(x - y) - f(x)| \cdot |g(y)| \dd y \cdot h^{p-1}(x) \dd x \\
	&\overset{\text{($*$)}}{=} \int \left(\int |f(x - y) - f(x)| h^{p-1}(x) \dd x \right) |g(y)| \dd y
\end{aligned}
$$
dove in ($*$) abbiamo usato Fubini-Tonelli, ora prendiamo $q$ tale che $1/p + 1/q = 1$ allora per H\"older abbiamo
$$
\begin{aligned}
	&\leq \int \norm{f(\curry - y) - f(\curry)}_p \| h^{p-1} \|_q \cdot |g(y)| \dd y \\
	&= \norm{h}_p^{p-1} \int_{\R^d} \norm{\tau_y f - f}_p \cdot |g(y)| \dd y \\
\end{aligned}
$$
dunque abbiamo ricavato che
$$
\norm{f \ast g - m f}_p^p 
\leq \norm{f \ast g - m f}_p^{p-1} \int_{\R^d} \norm{\tau_y f - f}_p \cdot |g(y)| \dd y
$$
ed ora applicando questa stima a $\sigma_\delta g$ invece che a $g$ otteniamo
$$
\norm{f \ast \sigma_\delta g - m f}_p
\leq \int_{\R^d} \norm{\tau_y f - f}_p \cdot |\sigma_\delta g(y)| \dd y
$$
infine ponendo $z = y / \delta$ e $\dd z = 1/\delta^d \dd y$ e sostituendo nell'integrale
$$
= \int_{\R^d} \norm{\tau_{\delta z} f - f}_p \cdot |\sigma_\delta g(y)| \dd y \xrightarrow{\delta \to 0} 0
$$
per \textit{convergenza dominata}, verifichiamone le ipotesi
\begin{enumerate}
	\item La convergenza puntuale segue in quanto $\norm{\tau_{\delta z} f - f}_p \xrightarrow{\delta \to 0} 0$ per ogni $z$.
	\item Come dominazione prendiamo $2 \norm{f}_p \cdot |g| \in L^1$.
\end{enumerate}
\qed

\textbf{Corollario.}
Sia $g \in C_C^\infty(\R^d)$ con $\int g \dd x = 1$ e $f \in L^p(\R^d)$ e $1 \leq p < +\infty$ allora $\sigma_\delta g \ast f \xrightarrow{\delta \to 0} f$ in $L^p(\R^d)$ e $\sigma_\delta g \ast f \in C^\infty(\R^d)$.


%
% Lezioni del 27-28 Ottobre 2021
%

\chapter{Spazi di Hilbert}

Sia $H$ spazio vettoriale reale con prodotto scalare $\left<\cdot, \cdot \right>$ definito positivo e norma indotta $\norm{\cdot}$ definita come $\norm{x} = \sqrt{\left<x,x \right>}$.

Si ricorda l'identità di polarizzazione
%
$$
\left<x_1,x_2 \right> = \frac{1}{4} \left( \norm{x_1 + x_2}^2 - \norm{x_1 - x_2}^2 \right).
$$
%

\textbf{Nota.} Siccome $\norm{\cdot }$ è continua, dalla formula di polarizzazione segue che il prodotto scalare è continuo.

\textbf{Definizione.} $H$ si dice \textbf{spazio di Hilbert} se è completo.

\textbf{Esempi.} 
\begin{itemize}
\item Dato $(X, \mc{A}, \mu )$, gli spazi $L^2(X), L^2(X, \R^m)$ sono spazi di Hilbert.

\item Lo spazio $\ds \ell^2 = \left\{ (x_n) \mymid \sum_{n=0}^{\infty} x_n^2 < +\infty  \right\}$ è uno spazio di Hilbert.

\end{itemize}

\textbf{Definizione.} $\mc{F} \subset H$ è un \textbf{sistema ortonormale} se
%
$$
\norm{e} = 1 \mquad \forall e \in \mc{F}, \qquad  \left<e,e' \right> = 0 \mquad \forall e \neq e' \in \mc{F}.
$$
%


\textbf{Definizione.} $\mc{F}$ si dice \textbf{completo} se $\overline{\spn(\mc{F})} = H$\footnote{lo span sono combinazioni lineari finite}. In tal caso $\mc{F}$ si dice \textbf{base di Hilbert}.

\textbf{Osservazione.} Se $H$ ha dimensione infinita non esistono basi ortonormali di Hilbert. \textit{Attenzione.} Le basi algebriche esistono, sono quelle ortonormali a non esistere.

\textbf{Esempi.}
In $\ell^2$ una base ortonormale è $\mc{F} = \left\{ e_n \mymid n \in \N \right\}$ con $e_n = (0,\ldots ,0,\underbrace{1}_{i},0,\ldots )$. \\
Infatti, il fatto che siano ortonormali è banale; verifichiamo che sia una base. 
Studiamo $\spn(\mc{F}) = \left\{ x = (x_0,x_1,\ldots ) \mymid x_n \quad \text{è definitivamente nullo}  \right\}$: dato $x \in \ell^2$ e $m = 0,1,2,\ldots $, definiamo
%
$$
P_mx \coloneqq (x_0,x_1,\ldots , x_m,0,\ldots ).
$$
%
Allora $\spn(\mc{F}) \supset P_m x \xrightarrow{m \to +\infty} x$ in $\ell^2$.
Infatti, 
%
$$
x - P_m x = (0,\ldots ,0, x_{m+1}, x_{m+2},\ldots ).
$$
%
Dunque
%
$$
\norm{x - P_m x} = \sum_{n = m+1}^{\infty} x_n^2 \xrightarrow{m \to +\infty} 0.
$$
%

\textbf{Teorema 1.} (della base di Hilbert.) Dato $H$ spazio di Hilbert, $\mc{F}$ sistema al più numerabile\footnote{il caso interessante è quello numerabile}, ovvero $\mc{F} = \left\{ e_n \mymid n \in \N \right\}$.
Definiamo per ogni $x \in H$, $n \in \N$ l'elemento $x_n = \left<x, e_n \right>$.
Allora
\begin{enumerate}
\item \label{item:27ott_thm1_1}
Vale $\ds \sum_{n} x_n^2 \leq \norm{x}^2$ (\textbf{Disuguaglianza di Bessel}).

\item \label{item:27ott_thm1_2}
La somma $\ds \sum_n x_n e_n$ converge a qualche $\overline{x} \in H$ e $\overline{x}_n = x_n$  per ogni $n$.

\item \label{item:27ott_thm1_3}
Vale $\ds \norm{\overline{x}}^2 = \sum_n x_n^2 \leq \norm{x}^2$.

\item \label{item:27ott_thm1_4}
Se $x - \overline{x} \perp \mc{F}$, allora $x - \overline{x} \perp \overline{\spn(\mc{F})}$, ovvero $\overline{x}$ è la proiezione di $x$ su $\overline{\spn(\mc{F})}$.

\item \label{item:27ott_thm1_5}
Se $\mc{F}$ è completo, allora $x = \overline{x}$ e in particolare
%
$$
x = \sum_{n=0}^{\infty} x_n e_n, \qquad \norm{x}^2 = \sum_{n=0}^{\infty} x_n^2  \qquad \text{(\textbf{Identità di Parceval})}.
$$
%
\end{enumerate}

\textbf{Nota.} Il punto \ref{item:27ott_thm1_2} non segue dal fatto che la serie non è assolutamente convergente. Infatti
%
$$
\sum \norm{x_n e_n} = \sum \left| x_n \right|
$$
%
può essere $+\infty$.


Alla dimostrazione del teorema premettiamo il seguente lemma.

\vs

\textbf{Lemma.} Siano $H$ e $\mc{F}$ come nel teorema.
Data $(a_n) \in \ell^2$, allora
\begin{enumerate}
\item La somma $\ds \sum_n a_n e_n$ converge a qualche $\overline{x} \in H$. 

\item $\overline{x}_n = a_n$.

\item $\ds \norm{\overline{x}}^2 = \sum_n a_n^2$.
\end{enumerate}

\textbf{Dimostrazione lemma.} 
\begin{enumerate}
\item Dimostriamo che $\ds y_n = \sum_{n = 1}^{m} x_n e_n$ è di Cauchy in $H$.
Se $m' > m$, vale
%
$$
y_{m'} - y_m = \sum_{n = m+1}^{m'} x_n e_n
\Longrightarrow  \norm{y_{m'} - y_m}^2 = \norm{\sum_{n = m+1}^{m'} x_n e_n}^2 
= \sum_{n = m+1}^{m'} x_n^2 \leq \sum_{n = m+1}^{\infty} x_n^2 < +\infty.
$$
%
Dunque, per ogni $\epsilon$ esiste $m_\epsilon$ tale che $\ds \sum_{m + 1}^{\infty} x_n^2 \leq \epsilon^2 $, per cui 
%
$$
\norm{y_{m'} - y_m}^2 \leq \sum_{m+1}^{\infty} x_n^2 \leq \sum_{m_\epsilon + 1}^{\infty} x_n^2 \leq \epsilon^2 \quad \forall m,m' \geq m_\epsilon.
$$
%

\item Per ipotesi, $\left<y_m, e_n \right> = x_n$ se $m \geq n$, dunque
%
$$
\left<y_n, e_n \right> \xrightarrow{n \to \infty} \left<\overline{x},e_n \right> = x_n.
$$
%

\item Si ha l'uguaglianza $\ds \norm{y_n}^2 = \sum_{n=1}^{m} x_n^2$, per cui passando al limite per $n \to +\infty$ otteniamo 
%
$$
\norm{y_n}^2 \to \norm{\overline{x}}^2, \qquad \sum_{n=0}^{m} x_n^2 \to \sum_{n=0}^{\infty} x_n^2.
$$
%


\end{enumerate}
\qed


\textbf{Dimostrazione teorema.}

\begin{enumerate}
\item Studiamo la somma
%
$$
x = \sum_{n=0}^{\infty} x_n e_n + \overbrace{y}^{\text{resto}}
$$
%
notiamo che $x$ è somma di vettori ortogonali, infatti $y$ è ortogonale a $\ds \sum_{n=0}^{\infty} x_n e_n$ :
%
$$
\left<y,e_i \right> = \left<x - \sum_{n=0}^{\infty} x_n e_n, e_i \right>
= \left<x,e_i \right> - \sum_{n=0}^{\infty} x_n \underbrace{\left<e_n,e_i \right>}_{\delta_{i,n}} = x_i - x_i = 0.
$$
%
Essendo che $x$ è somma di vettori ortogonali abbiamo
%
$$
\norm{x}^2 = \sum_{n=1}^{\infty} x_n^2 + \norm{y}^2 \geq \sum_{n=1}^{m} x_n^2.
$$
%
Passando al limite per $m \to +\infty$ otteniamo
%
$$
\norm{x}^2 \geq \sum_{n=1}^{\infty} x_n^2. 
$$
%

\item Segue dal punto precedente e dal lemma.

\item Segue dal punto precedente e dal lemma.

\item Notiamo che 
%
$$
\left<x - \overline{x}, e_n \right> = \left<x,e_n \right> - \left<\overline{x} , -e_n \right> = x_n - \overline{x}_n 
\overbrace{=}^{\ref{item:27ott_thm1_2}} x - \overline{x} \perp e_n \mquad \forall n \Longrightarrow x - \overline{x} \perp \spn(\mc{F}).
$$
%
Segue che $x - \overline{x} \perp \overline{\spn(\mc{F})}$. (dato $y \in$ chiusura span.., prendo $y_m \to y \in span$, $\left< x- \overline{x}, y_n \right> = 0 \Rightarrow  \left<x - \overline{x}, y \right> = 0$).

\item $x - \overline{x} \perp \overline{\spn(\mc{F})} \underbrace{=}_{\mathclap{\text{$\mc{F}$ è completo}}} H \Longrightarrow x - \overline{x} = 0$, cioè $x = \overline{x}$.
\end{enumerate}
\qed

\textbf{Corollario.} Siano $H$ spazio di Hilbert, $\mc{F} = \left\{ e_n \mymid n \in \Z \right\}$ base di Hilbert, $x,x' \in H$. Valgono le seguenti.
\begin{enumerate}
\item Se $x_n = x_n'$ per ogni $n \in \N$, allora $x = x'$ ($\Leftarrow$ è ovvia.)

\item $\ds \left<x,x' \right> = \sum_{n=0}^{\infty} x_n  x_n'$ (\textbf{Identità di Parceval}).

\item L'applicazione $H \ni X \mapsto (x_n) \in \ell^2$ è un'isometria surgettiva\footnote{in particolare è bigettiva ma l'iniettività è ovvia}.
\end{enumerate}

\vs 

\textbf{Dimostrazione.}

\begin{enumerate}
\item Per l'enunciato \ref{item:27ott_thm1_5} se due vettori hanno la stessa rappresentazione rispetto a una base di Hilbert coincidono.

\item La tesi segue usando l'identità di polarizzazione conigiuntamente all'enunciato \ref{item:27ott_thm1_5} del teorema:
%
\begin{align*}
\left<x,x' \right> & = \frac{1}{4} \left( \norm{x + x'}^2 + \norm{x - x'}^2 \right)
= \frac{1}{4} \Big( \sum_n \overbrace{(x_n + x_n')^2}^{x_n^2 + x_n'^2 + 2x_n x_n'}  \sum_n \underbrace{(x_n - x_n')^2}_{x_n^2 + x_n'^2 - 2 x_n x_n'}  \Big) \\
& = \frac{1}{4} \left( \cancel{\sum x_n^2} + \cancel{\sum x_n'^2} + 2 \sum x_n x_n' - \cancel{\sum x_n^2} - \cancel{\sum x_n'^2} + 2 \sum x_n x_n' \right).
\end{align*}

\item TO DO.

\end{enumerate}
\qed

\textbf{Osservazioni.}
\begin{itemize}
\item Gli enunciati \ref{item:27ott_thm1_1} e \ref{item:27ott_thm1_5} non richiedono $H$ completo.

\item Se $H$ è uno spazio di Hilbert e $\mc{F}$ sistema ortonormale infinito, allora $\mc{F}$ non è mai una base algebrica\footnote{per base algebrica s'intende un insieme di vettori di uno spazio vettoriale le cui combinazioni lineari generano tutto lo spazio}. Dunque combinazioni lineari finite di $H$ non sono mai uguali ad $H$, ovvero $\spn(\mc{F}) \subsetneq H $) di $H$.

\textbf{Dimostrazione.} 
Notiamo che possiamo scrivere $\overline{x}$ come
%
$$
(e_n) \subset \mc{F}, \quad  \overline{x} = \sum_{n = 0}^\infty \frac{1}{2^n} e_n, \quad  \overline{x} \notin \spn(\mc{F}).
$$
%
\textbf{Nota.} I coefficienti sono univocamente determinati perchè ottenuti tramite prodotto scalare. Notiamo che non si può usare il teorema di albebra lineare sull'unicità della rappesentazione poichè stiamo trattando combinazioni lineari infite.
\qed

\item Siano $H$ uno spazio di Hilbert di dimensione infinita e $\mc{F}$ una base di Hilbert. Allora, $\mc{F}$ è numerabile se solo se $H$ è separabile.

\textbf{Dimostrazione.}

\begin{itemize}

\item[$\boxed{\Rightarrow}$] Vale $ H = \overline{\spn(\mc{F})} = \overline{\spn_\Q (\mc{F})} $ e notando che $\overline{\spn_\Q (\mc{F})}$ è numerabile se  $\mc{F}$ è numerabile.

\item[$\boxed{\Leftarrow}$] Se $\mc{F}$ non è numerabile, siccome $\norm{e - e'} = \sqrt{2}  \quad \forall e,e' \in \mc{F}$ allora $H$ non è separabile.

\end{itemize}
\qed

\textbf{Esempio.} Lo spazio $H = L^2(X)$, con $X = \R^n$, $\mu $ misura di Lebesgue ha base di Hilbert numerabile.

\item Dato $\mc{F}$ sistema ortonormale in $H$, allora $\mc{F}$ è completo se solo se $\mc{F}$ è massimale (nella classe dei sistemi ortonormali rispetto all'inclusione).

\textbf{Dimostrazione.}
\begin{itemize}

\item[$\boxed{\Rightarrow}$] Dato che $\mc{F}$ è completo segue che $\overline{\spn(\mc{F})} = X$, quindi
%
$$
\mc{F}^{\perp} = \left( \spn(\mc{F}) \right)^\perp
\underbrace{=}_{\mathclap{\substack{\text{continuità del} \\ \text{prodotto scalare}}}} \overline{\spn(\mc{F})}^\perp = H^\perp = \{ 0 \}.
$$
%
dunque $\mc{F}$ è massimale.

\item[$\boxed{\Leftarrow}$] Se  $\mc{F}$ non è completo, esiste $c \in H \setminus \spn(\mc{F})$.
Definiamo $\overline{x}$ come nel Teorema 1. Notiamo che $x - \overline{x} \perp \spn(\mc{F})$, dunque $x - \overline{x} \perp \mc{F}$ e $x - \overline{x} \neq \{ 0 \}$, da cui $\ds \mc{F} \; \cup \; \left\{ \frac{x - \overline{x}}{\norm{x - \overline{x}}} \right\}$ è un sistema ortonormale che include strettamente $\mc{F}$. \absurd

\end{itemize}


\textbf{Osservazione.} Nell'implicazione $\boxed{\Rightarrow}$ non abbiamo usato la completezza di $H$.

\end{itemize}

\vs

\textbf{Corollario.} Ogni sistema ortonormale $\mc{F}$ si completa a $\tilde{\mc{F}}$ base di Hilbert di $H$.

\textbf{Dimostrazione.} Sia $X = \left\{ \mc{F} \; \text{sistema ortonormale} H \text{ tale che } \tilde{\mc{F}} \subset \mc{F} \right\}$
Per Zorn, $X$ contiene un elemento massimale. Denotiamolo con $\tilde{\mc{F}}$. Allora $\tilde{\mc{F}}$ è una base di Hilbert.
\qed

\vs

\textbf{Nota.} Aggiungere le note a caso.

\vs

\textbf{Teorema 2.} Dato $V$ sottospazio vettoriale chiuso di $H$. Allora
\begin{enumerate}
\item $H = V + V^\perp$, cioè per ogni $x \in H$ esiste $\overline{x} \in V$ e $\tilde{x} \in V$ tale che $x = \overline{x} + \tilde{x}$.

\item Gli elementi $\overline{x}$ e $\tilde{x}$ sono univocamente determinati (e indicati con $x_V$ e $x_V^\perp$).

\item $\overline{x}$ è caratterizzato come l'elemento di $V$ più vicino a $X$.
\end{enumerate}

\textbf{Dimostrazione.}
\begin{enumerate}
\item Dato che $V$ è chiuso, $V$ è completo, cioè $V$ è un sottospazio di $H$, dunque $V$ ammette base ortonormale $\mc{F} = \left\{ e_n \mymid n \in \N \right\}$.
Definiamo $\overline{x} \in \overline{\spn(\mc{F})}$ come nel Teorema 1 e $\tilde{x} \coloneqq x - \overline{x} \in \overline{\spn(\mc{F})} = V^\perp$ (per \ref{item:27ott_thm1_4}).

\item Se $x = \overline{x} + \tilde{x} = \overline{x}' + \tilde{x}'$, dove $\overline{x}, \overline{x}' \in V$ e $\tilde{x}, \tilde{x}' \in V^\perp$, allora
%
$$
\overline{x} - \overline{x}' = \tilde{x}' - \tilde{x} \underbrace{\Longrightarrow}_{V \cap V^\perp = \{0 \} }
\overline{x} - \overline{x}' = \tilde{x}' - \tilde{x} = 0.
$$
%

\item Per ogni $y \in V$ sia $f(y) = \norm{x - y}^2$. Mostriamo che $\overline{x}$ è l'unico minimo di $f$.
%
$$
f(y) = \norm{x - y}^2 = \lVert{\overbrace{x - \overline{x}}^{\in V^\perp} + \overbrace{\overline{x} - y}^{\in V}}\rVert^2 = \norm{x - \overline{x}}^2 + \norm{\overline{x} - y}^2
= f(\overline{x}) + \norm{\overline{x} - y}^2 \geq f(\overline{x}).
$$
%
\qed
\end{enumerate}

\vs

\textbf{Osservazione.}
Serve $V$ chiuso. Dato $\mc{F}$ base di Hilbert di $H$ ($H$ dimensione infinita), $V \coloneqq \spn(\mc{F})$, so che $V = \spn(\mc{F}) \subset \overline{V} = H$. Allora
%
$$
\overline{V^\perp} = \overline{V}^\perp = H^\perp = \{0\} \Longrightarrow V + V^\perp = V \subsetneq H.
$$
%

\textbf{Teorema 3.} Dato $\Lambda \colon  H \to \R$ lineare e continuo, esiste $x_0 \in H$ tale che 

\begin{equation} \tag{$\ast$}
	\Lambda(x) = \left<x,x_0 \right> \quad \text{per ogni} \; x \in H.
\end{equation}

\textbf{Dimostrazione.}
Supponiamo $\Lambda \not\equiv 0$. Dato che $\Lambda$ è continuo, $\ker \Lambda$ è chiuso in $H$. Definiamo $V \coloneqq \ker \Lambda$.
Per il primo enunciato del teorema precedente, $H = V + V^\perp$ e per quanto supposto $V^\perp \neq \{0\}$.

Notiamo che $\dim V^\perp = 1$. Infatti, se per assurdo $\dim(V^\perp) > 1$, allora esisterebbe $W \subset V^\perp$ con $\dim W = 2$, da cui seguirebbe che $\Lambda \colon  W \to \R$ ha $\ker$ banale. \absurd

Allora $V^\perp = \spn \left\{ x_1 \right\}$ con $\norm{x_1} = 1$. Definiamo $c \coloneqq \Lambda(x_1), x_0 = c x_1$.

Dimostriamo ora l'uguaglianza $\ast$ per passi.

\begin{enumerate}
\item Vale per $x \in V$ tale che $x \in \ker \Lambda$. Infatti $\Lambda(x)=x_0$ e $\left<x,x_0 \right> = 0$ perchè $x_0 \in V^\perp$.

\item Vale per $x = x_1$ (e quindi per $x \in V^\perp$). Infatti, 
%
$$
\Lambda(x_1) = c \quad \left<x_1,x_0 \right> = \left<x_1, c x_1 \right> = c \norm{x_1}^2 = c.
$$
%

\item Vale su $V + V^\perp = H$.
\end{enumerate}

\textbf{Osservazioni.}
\begin{itemize}
\item Esistono funzioni $\Lambda \colon  H \to \R$ lineari ma non continue se $H$ ha dimensine infinita.

\textbf{Dimostrazione.} Prendo $\Lambda \colon H \to \R$ lineare definito come
%
$$
\begin{cases}
\Lambda(e_n) = n \quad \forall n \\
\Lambda(e) = \text{qualsiasi } e \in \mc{G} \setminus \left\{ e_n \right\}.
\end{cases} 
$$
%
Allora
%
$$
+\infty = \sup_n \left| \Lambda(e_n) \right| \leq \sup_{\norm{x} \leq 1} \left| \Lambda(x) \right| 
$$
%
da cui segue che $\Lambda$ non è continuo.

\end{itemize}

%
% Lezione del 3 Novembre 2021
%

\section{Esercitazione del 3 Novembre 2021}

\subsection{Basi Hilbertiane e proiezioni}

\textbf{Esercizio 1.}
Sia $H = L^2(-1, 1)$ e sia $V = \spn\{ 1, x, x^2 \}$, verificare che sia un sottospazio chiudo e calcolare la proiezione di $\sin x$ su $V$.

\textbf{Osservazione.}
Su $L^2(\R)$ e su $L^2(-1, 1)$ esistono di sicuro basi Hilbertiane di cardinalità numerabile in quanto abbiamo già visto che sono spazi separabili.

\textbf{Soluzione.}
Vediamo come trovare le proiezioni su dei sottospazi $V$ di $H$ spazi di Hilbert separabili.

\begin{itemize}
	\item Bisgona controllare che $V$ sia chiuso.

	\item Si calcola una ``base hilbertiana di $V$'', se $\{ e_1, \dots, e_n, \dots \}$ è una base di $V$ allora 
		$$
		p_V(x) = \sum_n \langle x, e_n \rangle e_n
		$$

\end{itemize}

Indichiamo con $\norm{\curry}_{L^2}$ la norma $\norm{\curry}_{L^2(-1, 1)}$ e con $\langle \curry, \curry \rangle$ il prodotto scalare su $L^2$. Notiamo che se $V$ è chiuso in $L^2(-1, 1)$ in quanto ha dimensione finita. 

Abbiamo una base di $V$ data da $1, x, x^2$ in quanto sono linearmente indipendenti (si può verficare mostrando che $\forall x \in [-1, 1] \; \lambda_1 + \lambda_2 x + \lambda_3 x^2 = 0 \implies \lambda_1 = \lambda_2 = \lambda_3 = 0$ usando la teoria sulle equazioni di II grado oppure si può derivare e man mano ottenere più informazioni su $\lambda_3, \lambda_2, \lambda_1$)

Una prima tecnica sarebbe di applicare direttamente il processo di ortonormalizzazione di Gram-Schmidt a questa base ed ottenere
$$
\begin{aligned}
	e_1 &= \frac{1}{\norm{1}_{L^2}} = \frac{1}{\sqrt{2}}
	&\norm{1}_{L^2} = \sqrt{2} \\
	e_2 &= \frac{x - \langle x, \frac{1}{\sqrt 2} \rangle \cdot 1}{\norm{x - \langle x, \frac{1}{\sqrt 2} \rangle \cdot 1}_{L^2}} \\
	e_3 &= \frac{x^2 - \langle x^2, e_1 \rangle \cdot e_1 - \langle x^2, e_2 \rangle \cdot e_2}{\norm{x^2 - \langle x^2, e_1 \rangle \cdot e_1 - \langle x^2, e_2 \rangle \cdot e_2}_{L^2}} \\
\end{aligned}
$$

Alternativamente possiamo direttamente cercare la proiezione su $V$ di $\sin x$. Cerchiamo $a, b, c$ tali che $a + b x + c x^2$ sia $p_V(x) = \sin x$ allora posto $f(x) \coloneqq \sin x - a - b x - c x^2$ abbiam $f(x) \in V^\perp \iff $ si verficano le seguenti condizioni
$$
\langle f(x), 1 \rangle = 0
\qquad
\langle f(x), x \rangle = 0
\qquad
\langle f(x), x^2 \rangle = 0
$$
Ad esempio da $\langle f(x), 1 \rangle = 0$ otteniamo
$$
0 = \int_{-1}^1 (\sin x - a - b x - c x^2) \cdot 1 \dd x 
= \underbrace{\int_{-1}^1 \sin x \dd x}_{=0} - 2a - b \underbrace{\int_{-1}^1 x \dd x}_{=0} - c \int_{-1}^1 x^2
\implies 0 = -2a - \frac{2}{3}c
$$
ed analogamente si procede con $x$ e $x^2$... [TODO: Magari finire questo esercizio veramente]

Un altro modo è considerare la funzione $g(a, b, c) \coloneqq \norm{\sin x - a - bx - cx^2}_{L^2(-1, 1)}$ che è continua, coerciva, etc. e imponendo $\nabla_{a,b,c,} g = 0$ si minimizza e si ottengono $\bar a, \bar b, \bar c$ che verficano $p_V(\sin x)$.

\textbf{Esercizio 2.}
Sia $X = \{ u \in L^2(\R) \mid \int_0^2 u \dd x = 0 \}$, dire se è un sottospazio chiuso, calcolare $X^\perp$ per una generica $u \in L^2(\R)$ e determinare le proiezioni $p_X(u)$ e $p_{X^\perp}(u)$.

\textbf{Soluzione.}
Consideriamo la mappa $T$ lineare data da
$$
u \mapsto \int_0^2 u \dd x
$$
è ben definita, lineare e continua, allora $X$ è proprio $T^{-1}(0)$ dunque è un sottospazio chiuso. 

Osserviamo anche che
$$
T(u) 
= \int_\R u(x) \cdot \One_{[0, 2]}(x) \dd x
= \langle u, g \rangle_{L^2(\R)}
$$
con $g = \One_{[0, 2]}(x) \dd x \in L^2(\R)$. E dunque $X = \{ u \in L^2 \mid \langle u, g \rangle = 0 \}$.

Calcoliamo ora $X^\perp$ e le proiezioni $p_X$, $p_{X^\perp}$. 
$$
L^2(\R) = \spn_\R\left\{\frac{g}{\norm{g}_{L^2}}\right\} \oplus \left\{ \frac{g^\perp}{\norm{g}_{L^2}} \right\}
$$
quindi
$$
\norm{g}_{L^2} = \left( \int_\R \One_{[0, 2]}(x)^2 \dd x \right)^{1/2} = \sqrt 2
$$
e dunque
$$
p_X(u) = u - \frac{1}{2} \int_0^2 u \dd x \cdot \One_{[0, 2]}
$$
[TODO: Ricontrollare i conti]

\textbf{Esercizio.}
Sia $V = \{ \underline x = (x_n)_{n \in \N} \in \ell^2 \mid x_1 + x_3 + x_5 = 0 \}$, dire se $V$ è chiuso in $\ell^2$ e calcolare $p_V$ e $p_{V^\perp}$.

\subsection{Approssimazioni per convoluzione}

Abbiamo visto che data $g \in L^1(\R^d)$ con $\int g \dd x = 1$ allora per ogni $f \in L^p(\R^d)$ abbiamo $f_\delta \coloneqq f \ast \sigma_\delta g \xrightarrow{\delta \to 0} f$ in $L^p(\R^d)$ per $p \neq \infty$.

\textbf{Esercizio.}
Dire se esiste $v \in L^1(\R)$ tale che sia elemento neutro della convoluzione ovvero
$$
\forall f \in L^1(\R) \qquad f \ast v = f
$$
Non esiste tale $v$, per vederlo scegliamo opportunamente $\bar f$ e usiamo l'equazione. Prendiamo $g$ a supporto compatto, allora vorremmo avere $\sigma_\delta g \ast v = \sigma_\delta g$ per ogni $\delta$. Ma questo tende a $0$ in quanto il supporto diventa sempre più piccolo...

[TODO: Aggiustare]

\textbf{Osservazione.} 
Abbiamo già visto in passato che se $f$ è Lebesgue-misurabile tale che $\int_E f \dd x = 0$ per ogni $E$ misurabile di $\R^d$ allora $f = 0$ quasi ovunque su $\R^d$.

\textbf{Esercizio.}
Sia $f$ Lebesgue-misurabile su $\R^d$ tale che $\forall B$ palla su $\R^d$
$$
\int_B f \dd x = 0
$$
è vero allora che $f = 0$ quasi ovunque su $\R^d$?

\textbf{Hint.}
Si usa la convoluzione con un opportuno nucleo. In particolare $f \ast \One_B$...

\section{Esempi di basi Hilbertiane}

\subsection{Polinomi}

La base data da
$$
\{ 1, x, x^2, \dots, x^n, \dots \}
$$
opportunamente ortonormalizzata è una base di $L^2[0, 1]$... si ricollega al teorema di Stone-Weierstrass...

\subsection{Base di Haar}

\begin{wrapfigure}{r}{225pt}
	\centering
	\vspace{-1.5\baselineskip}
	\inputfigure{base-di-haar-1} 
	\vspace{-4.5\baselineskip}
\end{wrapfigure}

Vediamo la base di Haar data da due indici $n, k$ dove $n$ indica l'ampiezza delle ``onde'' (anche dette \textit{wavelet}) e $k$ il posizionamento dell'onda. Sia $n \in \N$ e $k = 1, \dots, 2^n$ e poniamo
$$
g^{0,0} \coloneqq 1
\qquad
g^{n,k} \coloneqq 2^\frac{n-1}{2} \left( \One_{\left[ \frac{2k - 2}{2^n}, \frac{2k - 1}{2^n} \right]} - \One_{\left[ \frac{2k - 1}{2^n}, \frac{2k}{2^n} \right]} \right)
$$

Inoltre $\| g^{n, k} \|_{L^2[0, 1]} = 1$ ed anche $\| g^{0,0} \|_{L^2[0, 1]} = 1$. Vedremo che $\{ g^{n,k} \mid n \geq 1, k = 1, \dots, 2^n \} \cup \{ g^{0,0} \}$ formano un sistema ortonormale.

\begin{itemize}
	\item $\langle g^{n,k}, g^{0,0} \rangle = 0$: È ovvio in quanto le $g^{n,k}$ hanno media nulla.

	\item $\langle g^{n,k}, g^{n',k'} \rangle = 0$: Se $n = n'$ i supporti sono sempre disgiunti altrimenti $n \neq n'$, se supponiamo $n < n'$ allora i supporti o sono disgiunti e si conclude come prima o il supporto di $g^{n',k'}$ è contenuto in quello di $g^{n,k}$. In tal caso però $g^{n,k}$ è costante su $g^{n',k'}$ e dunque l'integrale è sempre nullo.
\end{itemize}

Inoltre è anche una base hilbertiana, per combinazioni algebriche si ottengono tutti gli intervalli della forma
$$
I_k \coloneqq \left[ \frac{k-1}{2^n}, \frac{k}{2^n} \right]
\qquad
\rightsquigarrow
\qquad
\One_{I_k}
$$
ad esempio normalizzando $g^{n,k} + 2^\frac{n-1}{2} g^{0, 0}$ otteniamo uno degli intervalli di sopra di lunghezza $1 / 2^{n+1}$.

Vedremo che possiamo estendere la base di Haar a tutto $\R$ però è più difficile... [TODO: Ehm aggiungere la parte dopo quando verrà fatta]

\textbf{Esercizio.}
Sia $p \geq 1$ allora $\{ u \in L^p(\R) \mid \int u \dd x = 0 \} \subseteq L^p(\R)$ è denso in $L^p(\R)$?

%
% Lezione del 4 Novembre 2021
%

\section{Spazi di Hilbert complessi}

\textbf{Definizione.}
Sia $H$ una spazio vettoriale su $\C$ con prodotto hermitiano $\langle\curry; \curry\rangle$, ovvero tale che
\begin{itemize}
	\item $\langle \curry; \curry \rangle$ è lineare nella prima variabile
	\item $\langle x; x' \rangle = \overline{\langle x', x \rangle}$ ovvero è antilineare nella seconda variabile.
	\item $\langle x; x \rangle \geq 0$ per ogni $x$ e vale $0$ se e solo se $x = 0$.
\end{itemize}

Analogamente si pone $\norm{x} \coloneqq \sqrt{\langle x; x \rangle}$. C'è un'identità di polarizzazione ma è leggermente diversa dalla versione reale.

Allora $H$ si dice di Hilbert se è \textit{completo}.

\textbf{Esempio.}
Su $L^2(X; \C)$ si mette il prodotto scalare dato da
$$
\langle u; v \rangle \coloneqq \int_X u \cdot \overline v \dd \mu
$$

\textbf{Teorema.} (della base di Hilbert per spazi complessi)
Dato $\mathcal F = \{ e_n \}$ sistema ortonormale in $H$ e $x \in H$ allora per ogni $n$ si pone\footnote{E non $\langle e_n; x \rangle$!}
$$
x_n = \langle x; e_n \rangle
$$
Vale anche l'identità di Parceval $\norm{x^2} = \sum |x_n|^2$ dove $|\curry|$ è il modulo di un numero complesso, in particolare nella versione con prodotto scalare diventa
$$
\langle x, x' \rangle = \sum_n x_n \overline{x_n'}
$$

\chapter{Serie di Fourier}

Lo scopo della serie di Fourier (complessa) è di rappresentare una funzione $f \colon [-\pi, \pi] \to \C$ (o più in generale una funzione $f \colon \R \to \C$ $2\pi$-periodica) come
$$
f(x) = \sum_{n=-\infty}^\infty c_n e^{i n x}
$$
In particolare chiamiamo i coefficienti $c_n$ \textit{coefficienti di Fourier} di $f(x)$ e tutta l'espressione a destra \textit{serie di Fourier} di $f(x)$.

\textbf{Motivazione.}
La rappresentazione in serie di Fourier serve ad esempio a risolvere certe equazioni alle derivate parziali ed è anche utilizzata per la ``compressione dati''.

\textbf{Problemi.}
\begin{itemize}
	\item Come si trovano (se esistono) i coefficienti di Fourier?
	\item Ed in che senso la serie converge?
\end{itemize}

\textbf{Osservazione.}
La serie appena vista è indicizzata da $-\infty$ a $+\infty$, più avanti vedremo che la definizione esatta non sarà importante ma per ora usiamo la definizione
$$
\sum_{n=-\infty}^\infty a_n \coloneqq \lim_{N \to +\infty} \sum_{n = -N}^N a_n
$$
ed ogni tanto scriveremo anche $\ds \sum_{n \in \Z} a_n$ per brevità.

\textbf{Teorema 1.}
Sia $\ds\mathcal F = \left\{ e_n(x) \coloneqq \frac{e^{inx}}{\sqrt{2\pi}} \right\}$ allora è una base ortonormale di $L^2([-\pi, \pi]; \C)$.

Da cui \textit{formalmente} segue che
$$
\begin{aligned}
	f(x) 
	&= \sum_{n \in \Z} \langle f; e_n \rangle \cdot e_n
	= \sum_{n \in \Z} \left( \int_{-\pi}^\pi f(t) \overline{\frac{e^{int}}{\sqrt{2\pi}}} \dd t \right) \frac{e^{inx}}{\sqrt{2\pi}} \\
	&= \sum_{n \in \Z} \, \underbrace{\frac{1}{2\pi} \left( \int_{-\pi}^\pi f(t) e^{-int} \dd t \right)}_{c_n} \, e^{inx}
\end{aligned}
$$

\textbf{Definizione.}
Data $f \in L^2([-\pi, \pi]; \C)$ i coefficienti di Fourier di $f$ sono
$$
c_n = c_n(f) \coloneqq \frac{1}{2\pi} \int_{-\pi}^\pi f(x) e^{-inx} \dd x
$$
e notiamo in particolare che è anche ben definito per $f \in L^1$ (anche se per ora non ci dice molto in quanto $L^1$ non è uno spazio di Hilbert).

\textbf{Corollario.}
Per ogni $f \in L^2([-\pi, \pi]; \C)$ abbiamo
\begin{enumerate}
	\item \label{item:4nov2021_cor1_1} 
		La serie $\ds \sum_{n \in \Z} c_n e^{inx}$ converge a $f$ in $L^2$.

	\item Vale l'identità di Parceval
		$$
		\norm{f}_2^2 = 2 \pi \sum_{n \in \Z} |c_n|^2
		\qquad
		\qquad
		\langle f, g \rangle = \sum_{n \in \Z} c_n(f) \overline{c_n(g)}
		$$
\end{enumerate}

\textbf{Osservazione.}
Usando la \ref{item:4nov2021_cor1_1} ed il fatto che la convergenza in $L^2$ implica la convergenza quasi ovunque a meno di sottosuccessioni otteniamo che $\forall f \; \exists N_n \uparrow \infty$ tale che
$$
\sum_{n = -N_k}^{N_k} c_n e^{inx} \xrightarrow{\;\;k\;\;} f(x) \qquad \foralmostall x \in [-\pi, \pi]
$$

In particolare nel 1966 Carleson ha dimostrato che in realtà vale proprio
$$
\sum_{n = -N}^N c_n e^{inx} \xrightarrow{\;\;N\;\;} f(x) \qquad \foralmostall x
$$

\textbf{Dimostrazione Teorema 1.}
Vogliamo vedere che
\begin{enumerate}
	\item $\mathcal F$ è un sistema ortonormale.

		\textbf{Dimostrazione.}
		Basta calcolare $\langle e_n; e_m \rangle$ per ogni $n, m \in \Z$
		$$
		\langle e_n; e_m \rangle
		= \int_{-\pi}^\pi \frac{e^{inx}}{\sqrt{2\pi}} \cdot \overline{\frac{e^{inx}}{\sqrt{2\pi}}} \dd x
		=
		\begin{cases}
			\ds \frac{1}{2\pi} \int_{-\pi}^\pi 1 \dd x = 1 & \text{se } n = m \\[15pt]
			\ds \frac{1}{2\pi} \left[ \frac{e^{i(n - m)x}}{i(n - m)} \right]_{-\pi}^\pi = 0& \text{se } n \neq m \\
		\end{cases}
		$$

	\item $\mathcal F$ è completo

		Questo punto richiede il teorema di Stone-Weierstrass che enunciamo

		\textbf{Teorema di Stone-Weierstrass.}
		Sia $K$ uno spazio compatto e $T_2$ (essenzialmente è uno spazio metrico compatto) e siano $C(K)$ le funzioni continue reali su $K$, mentre $C(K; \C)$ le funzioni continue complesse su $K$ (con la norma del $\sup$).

		Dato $\mathcal A \subset C(K)$ diciamo che è una \textbf{sottoalgebra} se è uno spazio vettoriale e chiuso rispetto al prodotto e diciamo che \textbf{separa i punti} se $\forall x_1, x_2 \in K$ con $x_1 \neq x_2$ allora $\exists f \in \mathcal A$ tale che $f(x_1) \neq f(x_2)$.
		\begin{itemize}
			\item \textit{Caso reale:}
			se $\mathcal A$ è una sottoalgebra di $C(K)$ che separa i punti e contiene le costanti allora $\overline{\mathcal A} = C(K)$.
			
			\item \textit{Caso complesso:}
			se $\mathcal A$ è una sottoalgebra di $C(K; \C)$ che separa i punti, contiene le costanti e \textit{chiusa per coniugio} allora $\overline{\mathcal A} = C(K; \C)$.
			
		\end{itemize}

		\textbf{Osservazioni.}
		\begin{itemize}
			\item Se $K = [0, 1]$, $\mathcal A = \text{``polinomi reali''} \implies \overline{\mathcal A} = C(K; \C)$.
			
			\item L'ipotesi di separare i punti è necessaria, se ad esempio $\exists x_1, x_2$ tali che $x_1 \neq x_2$ e per ogni $f$ abbiamo $f(x_1) = f(x_2)$ allora varrà analogamente anche per ogni funzione nella chiusura ma le funzioni continue separano i punti.

			\item È anche necessario che $\mathcal A \supset \text{``costanti''}$, ad esempio dato $x_0 \in K$ ed $\mathcal A \coloneqq \{ f \in C(K) \mid f(x_0) = 0 \}$ abbiamo che $\overline{\mathcal A} = \mathcal A \subsetneq C(K)$.

			\item Anche la chiusura per coniugio è necessaria, infatti ad esempio preso $K = \{ z \in \C \mid |z| \leq 1 \}$, $\mathcal A = \text{``polinomi complessi''}$, $\mathcal A$ separa i punti e contiene le costanti però $\overline{\mathcal A}$ sono solo le funzioni olomorfe su $K$.
		\end{itemize}

		In particolare vorremmo applicare questo teorema alle funzioni $2\pi$-periodiche ristrette a $[-\pi, \pi]$ che però non verificano la separazione dei punti in quanto per la periodicità $f(-\pi) = f(\pi)$. Nel seguente corollario vediamo come possiamo estendere leggermente il teorema passando ai quozienti topologici.

		\textbf{Corollario.}
		Sia $\mathcal A$ una sottoalgebra di $C(K)$ (o analogamente per $C(K; \C)$) che contiene le costanti (e nel caso complesso anche chiusa per coniugio) e definiamo la seguente relazione di equivalenza $x_1 \sim x_2$ se $f(x_1) = f(x_2)$ per ogni $f \in \mathcal A$ allora 
		$$
		\overline{\mathcal A} = \{ f \in C(K) \mid x_1 \sim x_2 \Rightarrow f(x_1) = f(x_2) \}
		$$
		\begin{minipage}{\textwidth}
		\parskip 1ex
		\setlength{\parindent}{0pt}

		\begin{wrapfigure}{r}{100pt}
			\centering
			\vspace{-1.5\baselineskip}
			\begin{tikzcd}
				K \ar[r, "g"] \ar[d, "\pi"] & \C \\
				\sfrac{K}{\sim} \ar[ru, dashed, swap, "\tilde g"]
			\end{tikzcd}
			\vspace{-1.5\baselineskip}
		\end{wrapfigure}
		
		\textbf{Dimostrazione del corollario.}
		Diciamo $X \coloneqq \{ f \in C(K) \mid x_1 \sim x_2 \Rightarrow f(x_1) = f(x_2) \}$ allora applichiamo	il teorema di Stone-Weierstrass a $\sfrac{K}{\sim}$, è chiaro che $\overline{\mathcal A} \subset X$, vediamo che $X \subset \overline{\mathcal A}$. 

		Data $g \in X$ troviamo $g_n \in \mathcal A$ tale che $g_n \to g$ uniformemente allora $\exists \tilde g \colon \sfrac{K}{\sim} \to \C$ tale che $g = \tilde g \compose \pi$, consideriamo $\mathcal A = \{ \tilde f \mid f \in \mathcal A \}$ che è una sottoalgebra di $C(\overline{\sfrac{K}{\sim}}; \C)$ che separa i punti, etc. 
		\qed
		\end{minipage}

		Torniamo alla dimostrazione della completezza di $\mathcal F$, $K = [-\pi, \pi]$ e consideriamo
		$$
		\mathcal A = \spn_\C(\mathcal F) = \left\{ \sum_{n \in \Z} c_n e^{inx} \right\} = \{ p(e^{inx}) \mid p \text{ polinomio a esponenti interi} \}
		$$
		segue che $\mathcal A$ è una sottoalgebra, separa i punti di $K$ tranne $-\pi$ e $\pi$ ed è chiuso per coniugio.

		Per il corollario\footnote{Notiamo che la topologia su $\mathcal A$ è quella data dalla norma del $\sup$ delle funzioni continue quindi la chiusura è rispetto a tale norma e la indichiamo con $\overline{\mathcal A}^{\,C}$.} $\overline{\mathcal A}^{\,C} = \{ f \in C([-\pi, \pi]; \C) \mid f(-\pi) = f(\pi) \}$. Se invece facciamo la chiusura rispetto ad $L^2$ abbiamo che 
		$$
		\overline{\mathcal A}^{\,L^2} \supseteq \{ f \in C([-\pi, \pi]; \C) \mid f(-\pi) = f(\pi) \}
		$$
		in quanto la convergenza uniforme implica la convergenza in $L^2$ per spazi di misura finita.

		Inoltre $\overline{\mathcal A}^{\,L^2} \supseteq \{ f \in C([-\pi, \pi]; \C) \}$, data $f \in C([-\pi, \pi]; \C)$ la approssimiamo in $L^2$ con $f_n = f \cdot \varphi_n$, dove le $\varphi_n$ sono tali che $\varphi_n(-\pi) = \varphi_n(\pi) = 0$, $\varphi_n = 1$ su $[1/n - \pi, \pi - 1/n]$ e interpolata linearmente nell'intervallo rimanete.

		[TODO: Disegnino delle $\varphi_n$]

		Infine poiché le funzioni continue sono dense in $L^2$ rispetto alla sua norma segue che $\overline{\mathcal A}^{L^2} = L^2$.

\end{enumerate}

%
% Lezione del 10 Novembre 2021
%

\section{Convergenza puntuale della serie di Fourier}

\textbf{Teorema.} (di convergenza puntuale della serie di Fourier).
Data $f \in L^1([-\pi, \pi])$ estesa a $\R$ per periodicità e dato $\bar x \in \R$ tale che $f$ è $\alpha$-H\"olderiana in $\bar x$ con $\alpha > 0$ (cioè $\exists M < +\infty, \delta > 0$ tali che $|f(\bar x + t) - f(\bar x)| \leq M |t|^\alpha$ se $|t| \leq \delta$) allora
$$
S_n f(\bar x) \xrightarrow{N \to \infty}  f(\bar x)
$$
dove $S_n f(\bar x) = \ds \sum_{n=-N}^N c_n e^{inx}$.

\textbf{Lemma.} (di rappresentazione di $S_n f$ come convoluzione)
Data $f$ come sopra abbiamo visto che
$$
S_n f(x) = \frac{1}{2\pi} \int_{-\pi}^\pi f(x - t) D_n(t) \dd t
\qquad
\text{con }
D_N(t) \coloneqq \sum_{n=-N}^N e^{int} = \frac{\sin\left(\left(N + \frac{1}{2}\right)t\right)}{\sin \left(\frac{t}{2}\right)}
$$
\textbf{Osservazione.}
In particolare vale $\ds \frac{1}{2\pi} \int_{-\pi}^\pi D_N(t) \dd t = 1$.

\textbf{Lemma.} (di Riemann-Lebesgue (generalizzato)).
Data $g \in L^1(\R)$ e $h \in L^\infty(\R)$ con $h$ $T$-periodica, allora
$$
\int_\R g(x) h(yx) \dd x \xrightarrow{y \to \pm \infty}
\underbrace{\left(\int_\R g(x) \dd x \right)}_a
\underbrace{\left(\avint_0^T h(x) \dd x \right)}_m
$$

Se supponiamo $\supp g \subseteq [0, 1]$ allora $\int_0^1 g(x) h(yx) \dd x \to \int_0^1 g(x) \dd x \cdot \avint_0^T h(x) \dd x \approx \int_0^1 g(x) \dd x \cdot \avint_0^1 h(yx) \dd y$.

In particolare è abbastanza intuitivo il risultato per $g$ costante a tratti infatti su un intervallo otterremmo
$$
\int_0^{x_1} g(x) h(yx) \dd x = c \int_0^{x_1} h(yx) \dd x = (c x_1) m
$$
Però ci sarebbero delle correzzioni da fare per dimostrare le cose in questo modo in generale. Vediamo invece un'altra dimostrazione un po' più elegante.

[TODO: Disegnino nel caso $g$ costante a tratti]

\textbf{Dimostrazione.}
Per ogni $s, y$ poniamo $\Phi(y, s) \coloneqq \int_\R g(x) h(yx + s) \dd x$ con $s, y \in \R$ allora la tesi è che $\Phi(y, 0) \xrightarrow{y \to \pm\infty} a m$.
Vedremo che valgono le seguenti
\begin{enumerate}
	\item $\forall y \; \ds \avint_0^T \Phi(y, s) \dd s = am$.
	\item $\forall s \; \Phi(y, s) - \Phi(y, 0) \xrightarrow{y \to \pm \infty} 0$.
\end{enumerate}
da cui segue subito che
$$
\Phi(y, 0) - ma = \avint_0^T \Phi(y, 0) - \Phi(y, s) \dd s \xrightarrow{y \to \pm \infty} 0
$$
per convergenza dominata dove dalla ii). segue la convergenza puntuale e come dominazione usiamo
$$
|\Phi(y, 0) - \Phi(y, s)| \leq 2 \norm{g}_1 \norm{h}_\infty
$$
da cui segue la tesi. Mostriamo ora i due punti.
\begin{enumerate}
	\item Esplicitiamo e applichiamo Fubini-Tonelli
		$$
		\begin{aligned}
			\int_0^T \Phi(y, s) \dd s
			&= \int_0^T \int_\R g(x) h(yx + s) \dd x \dd s \\
			&= \int_\R \underbrace{\avint_0^T h(yx + s) \dd s}_m \cdot g(x) \dd x \\
			&= m \int_\R g(x) \dd x = m a
		\end{aligned}
		$$
		e possiamo usare Fubini-Tonelli in quanto 
		$$
		\ds \int_\R \avint_0^T |h(yx - s)| \dd s \cdot |g(x)| \dd x \leq \int_\R \norm{f}_\infty |g(x)| \dd x = \norm{h}_\infty \cdot \norm{g}_1
		$$

	\item {} [TODO: inventare delle parole a caso]
		$$
		\Phi(y, s) 
		= \int_\R g(x) h\left(y \left( x + \frac{s}{y} \right)\right) \dd x 
		$$
		ora applichiamo la sostituzione $\ds t = x + \frac{s}{y}$ da cui $\dd t = \dd x$
		$$
		= \int_\R g \left( t - \frac{s}{y} \right) h(yt) \dd t
		$$
		ed a questo punto otteniamo
		$$
		\Phi(y, s) - \Phi(y, 0) = \int_\R \left(g\left( t - \frac{s}{y}\right) - g(t) \right) h(yt) \dd t 
		$$
		$$
		\implies
		|\Phi(y, s) - \Phi(y, 0)| = \int_\R |\tau_{\frac{s}{y}} g - g| \cdot |h(yt)| \dd t
		\leq \norm{\tau_{\frac{s}{y}} g - g}_1 \cdot \norm{h}_\infty \xrightarrow{y \to \pm \infty} 0
		$$
\end{enumerate}
\qed

\textbf{Dimostrazione del Teorema.}
$$
\begin{aligned}
	S_N f(\bar x) - f(\bar x) 
	&= \frac{1}{2\pi} \int_{-\pi}^\pi f(\bar x - t) D_N(t) \dd t - \frac{1}{2\pi} \int_{-\pi}^\pi f(\bar x) D_N(t) \dd t \\
	&= \frac{1}{2\pi} \int_{-\pi}^\pi (f(\bar x - t) - f(\bar x)) D_N(t) \dd t \\
	&= \frac{1}{2\pi} \int_{-\pi}^\pi \frac{f(\bar x - t) - f(\bar x)}{\sin \frac{t}{2}} \sin \left(\left(N + \frac{1}{2}\right) t\right) \dd t \\
	&= \int_{-\pi}^\pi g(t) \cdot \sin \left(\left(N + \frac{1}{2}\right) t\right)
	\xrightarrow{\text{RL}} \left(\int g(x) \dd x\right) \cdot \avint_0^\pi \sin x \dd x
\end{aligned}
$$
in particolare per applicare Riemann-Lebesgue serve $g \in L^1([-\pi, \pi])$ ma infatti per $|t| \leq \delta$
$$
|g(t)| \leq \frac{|f(\bar x - t) - f(\bar x)|}{|\sin \frac{t}{2}|} \leq \frac{M |t|^\alpha}{|t| / \pi} = \frac{M \pi}{|t|^{1 - \alpha}} \in L^1([-\delta, \delta])
$$
invece per $\delta \leq |t| \leq \pi$ basta
$$
|g(t)| \leq \frac{|f(\bar x - t)| + |f(\bar x)|}{\sin \frac{\delta}{2}} \in L^1([-\pi, \pi])
$$
\qed

Data $f \in L^1([-\pi, \pi])$ estesa per periodicità e dato $\bar x$ tale che esistano i limiti a destra e sinistra di $f$ in $\bar x$ detti $L^+$ e $L^-$ ed $f$ $\alpha$-H\"olderiana a sinistra e destra si può vedere che vale
$$
S_N f(\bar x) \xrightarrow{N} \frac{L^+ + L^-}{2}
$$

\chapter{Applicazioni della serie di Fourier}

\section{Equazione del calore}

Sia $\Omega$ un aperto di $\R^d$ e $u(t, x) \colon [0, T) \times \Omega \to \R$ e chiamiamo $x$ la \textit{variabile spaziale} e $t$ la \textit{variabile temporale}. In dimensione $3$ l'insieme $\Omega$ rappresenta un solito di materiale conduttore omogeneo  e $u(t, x) = $ temperatura in $x$ all'istante $t \implies u$ risolve l'equazione del calore
$$
u_t = c \cdot \Delta u
$$
dove con $u_t$ indichiamo la derivata parziale di $u$ rispetto al tempo, $c$ è una costante fisica che porremo uguale ad $1$ e $\Delta u$ è il laplaciano rispetto alle dimensioni spaziali ovvero
$$
\Delta u = \sum_{i=1}^d \frac{\pd^2 u}{\pd x_i^2} = \operatorname{div}(\nabla_x u)
$$

Vedremo che la soluzione di $u_t = \Delta u$ esiste ed è unica specificando $u(0, \curry) = u_0$ condizione iniziale con $u_0 \colon \Omega \to \R$ data e delle condizioni al bordo come ad esempio
\begin{itemize}
	\item \textit{Condizioni di Dirichlet}: $u = v_0$ su $[0, T) \times \pd \Omega$ con $v_0$ funzione fissata. Possiamo pensare come fissare delle sorgenti di calore costanti sul bordo.
	\item \textit{Condizioni di Neumann:} $\ds \frac{\pd u}{\pd \nu}$ con $\nu$ direzione normale al bordo. Essenzialmente ci sta dicendo che non c'è scambio di calore con l'esterno.
\end{itemize}
In particolare scriveremo
$$
\left\{
\begin{aligned}
	& u_t = \Delta u \quad \text{su $\Omega$} \\
	& u(0, \curry) = u_0 \\
	& \text{\footnotesize Una delle condizioni al bordo su $\pd \Omega$...}
\end{aligned}
\right.
$$

\subsection{Derivazione dell'equazione del calore}

Partiamo da due leggi fisiche
\begin{itemize}
	\item \textit{Trasmissione del calore attraverso pareti sottili:}

		Siano $u^-$ e $u^+$ le temperature a sinistra e destra di una parete di spessore $\delta$ ed area $a$. Allora ``la quantità di calore che attraversa la parete per unità di tempo è proporzionale a $u^- - u^+$, all'area della parete e inversamente proporzionale allo spessore.
		$$
		\Delta E = c_1 \frac{\Delta u}{\delta} a \Delta t
		$$
		In particolare per $\delta \to 0$ otteniamo che su una superficie $\Sigma$ vale
		$$
		\Delta E = c_1 \frac{\pd u}{\pd \nu} |\Sigma| \Delta t
		$$
		Passando ulteriormente al caso continuo otteniamo
		$$
		\frac{\Delta E}{\Delta t} = c_1 \frac{\pd u}{\pd \nu} |\Sigma| 
		\implies \frac{\pd E}{\pd t} = \int_{\pd A} \frac{\pd u}{\pd \nu}
		$$

	\item \textit{Legge fisica 2:}

		L'aumento di temperatura in un solito è proporzionale alla quantità di calore immessa e inversamente proporzionale al volume.
		$$
		\Delta u = \frac{1}{c_2} \frac{\Delta E}{V}
		$$
		passando al continuo otteniamo $\ds \frac{\pd E}{\pd t} = \int_A c_2 \frac{\pd u}{\pd t}$.
\end{itemize}
Dunque infine otteniamo che
$$
\forall A \subseteq \Omega \, \forall t
\qquad
\int_A c_2 \frac{\pd u}{\pd t} = \int_{\pd A} \frac{\pd u}{\pd \nu} = \int_A \operatorname{div}(\nabla u) = \int_A \Delta u
$$
dove abbiamo usato il teorema della divergenza. Ed infine
$$
\implies \int_A c_2 \frac{\pd u}{\pd t} = \int_A c_1 \Delta u 
\implies c_2 \frac{\pd u}{\pd t} = c_1 \Delta u 
\implies \frac{\pd u}{\pd t} = \frac{c_1}{c_2} \cdot \Delta u
$$





\chapter{Trasformata di Fourier}

% TODO

\chapter{Funzioni armoniche}

% TODO

\chapter{Integrazione di superfici}

% TODO

\newpage

\section{Indice Analitico}

Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod
tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam,
quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo
consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse
cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non
proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

\begin{multicols*}{2}

\makebox[3cm][l]{\absurd} Assurdo

\makebox[3cm][l]{\absurd} Assurdo

\makebox[3cm][l]{\absurd} Assurdo

\makebox[3cm][l]{\absurd} Assurdo

\vfill\null\columnbreak

\makebox[3cm][l]{\absurd} Assurdo

\makebox[3cm][l]{\absurd} Assurdo

\makebox[3cm][l]{\absurd} Assurdo

\makebox[3cm][l]{\absurd} Assurdo

\end{multicols*}

\section*{Esempi di figure}

\subsection*{Semplici}

Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod
tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam,
quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.

% Moralmente "example" corrisponde ad un file "src/figures/example.svg", in realtà la magia è che "example" diventa "example.pdf_tex" attraverso "\inputfigure" e poi quello il latex lo va a cercare dentro ".cache/figures/.pdf_tex/" come impostato in "prelude.tex".
\begin{figure}[h]
	\centering
	\inputfigure{example} 
\end{figure}

Duis aute irure dolor in reprehenderit in voluptate velit esse
cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non
proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

\subsection*{Wrappate}

Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod
tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam,
quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.

% La pagina del file "example.svg" è larga 300pt e qui sotto va lo stesso valore, per motivi estetici i due vspace negativi riducono un po' il margine di default che sta sopra e sotto l'ambiente "wrapfigure".
\begin{wrapfigure}{r}{300pt}
	\centering
	\vspace{-1.5\baselineskip}
	\inputfigure{example}
	\vspace{-2.5\baselineskip}
\end{wrapfigure}

Duis aute irure dolor in reprehenderit in voluptate velit esse
cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non
proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod
tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam,
quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo
consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse
cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non
proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

\subsection*{Con caption o descrizione}

Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod
tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam,
quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.

\begin{figure}[h]
	\centering
	\inputfigure{example}
	\caption{
		Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod
		tempor incididunt ut labore et dolore magna aliqua.
	}
\end{figure}

Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod
tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam,
quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.

\begin{wrapfigure}{r}{300pt}
	\centering
	\vspace{-1.5\baselineskip}
	\inputfigure{example}
	{\footnotesize
		Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod
		tempor incididunt ut labore et dolore magna aliqua.
	}
	\vspace{-1\baselineskip}
\end{wrapfigure}

Duis aute irure dolor in reprehenderit in voluptate velit esse
cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non
proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod
tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam,
quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo
consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse
cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non
proident, sunt in culpa qui officia deserunt mollit anim id est laborum.


\end{document}
