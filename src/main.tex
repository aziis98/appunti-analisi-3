\documentclass[a4paper, 12pt]{report}

\input{prelude.tex}

\title{{\Huge Analisi 3}\\{\small Appunti di Analisi 3 del corso di Giovanni Alberti e Maria Stella Gelli}}
\author{Arianna Carelli e Antonio De Lucreziis}
\date{I Semestre 2021/2021}

\begin{document}

%
% Removes initial indentation from paragraphs.
%
\parskip 1ex
\setlength{\parindent}{0pt}

% Initial page
\maketitle

% Table of contents
\tableofcontents
\newpage

\chapter{Teoria della misura}

\section{Misure astratte}

\textbf{Definizione.} 
Uno spazio misurabile è una terna $(X, \mathcal A, \mu)$ tale che
\begin{itemize}
	
	\item $X$ è un insieme qualunque.

	\item $\mathcal{A}$ è una $\sigma$-algebra di sottoinsiemi di $X$, ovvero una famiglia di sottoinsiemi di $X$ che rispetta le seguenti proprietà:
		\begin{itemize}
			\item $\emptyset, X \in \mathcal{A}$.
			\item $\mathcal{A}$ è chiusa per complementare, unione e intersezione numerabile.
		\end{itemize}
	
	\item $\mu$ è una misura su $X$, ossia una funzione $\mu \colon \mathcal A \to [0, +\infty]$ $\sigma$-addittiva, cioè tale che data una famiglia numerabile $\left\{ E_k \right\} \subset \mathcal A$ disgiunta e posto $E \coloneqq \bigcup E_n $, allora
		$$
		\mu(E) = \sum_{n} \mu (E_n).
		$$

\end{itemize}

\textbf{Notazione.}
Data una crescente di insiemi $E_1 \subset E_2 \subset \cdots E_n \subset \cdots$ con $\bigcup E_n = E$, scriviamo $E_n \uparrow E$.

\textbf{Proprietà.}
\begin{itemize}
	\item $\mu(\emptyset) = 0$
	\item \textit{Monotonia}: Dati $E,E' \in \mathcal{A}$ e $E \subset E'$, allora $\mu(E) \leq \mu(E')$.
	\item Data una successione crescente di insiemi $E_n \uparrow E$, allora $\mu(E) = \lim_{n \to \infty} \mu(E_n) = \sup_{n} \mu(E_n)$.
	\item Se $E_n \uparrow E$ e $\mu (E_{\bar{n}}) < +\infty$ per qualche $\bar{n}$, allora $\mu(E) = \lim_{n \to + \infty} \mu(E_n) = \inf_{n} \mu(E_n)$.
	\item \textit{Subadditività}: Se $\bigcup E_n \supset E$, allora $\mu(E) \leq \sum_{n} \mu(E_n)$.
\end{itemize}

\textbf{Osservazione.} 
Dato $X' \in \mathcal A$ si possono restringere $\mathcal A$ e $\mu$ a $X'$ nel modo ovvio.

\textbf{Definizioni}.
\begin{itemize}
	\item $\mu$ si dice \textbf{completa} se $F \subset E, E \in \mathcal{A}$ e $\mu(E) = 0$, allora $F \in \mathcal{A}$ (e di conseguenza $\mu(F) = 0$).
	\item $\mu$ si dice \textbf{finita} se $\mu(X) < + \infty$.
	\item $\mu$ si dice \textbf{$\sigma$-finita} se esiste una successione $\{ E_n \}$ con $E_n \subset E_{n+1}$ tale che $\bigcup E_n = X$ con $\mu(E_n) < +\infty$ per ogni $n$.
\end{itemize}

\textbf{Notazione.}
Sia $P(X)$ un predicato che dipende da $x \in X$ allora si dice che \textbf{$P(X)$ vale $\mu$-quasi ogni $x \in X$} se l'insieme $\left\{ x \mid P(x) \text{ è falso}  \right\}$ è (contenuto in) un insieme di misura $\mu$ nulla.

D'ora in poi consideriamo solo misure complete.

\section{Esempi di misure}

\begin{itemize}
	
	\item \textbf{Misura che conta i punti.}
		$$
		X \text{ insieme}
		\qquad
		\mathcal A \coloneqq \mathcal P(X)
		\qquad
		\mu(E) \coloneqq \# E \in \N \cup \left\{ +\infty \right\}
		$$

	\item \textbf{Delta di Dirac in $x_0$.}
		$$
		X \text{ insieme, } x_0 \in X \text{ fissato}
		\qquad
		\mathcal A \coloneqq \mathcal P(X)
		\qquad
		\mu(E) \coloneqq \delta_{x_0}(E) = \One_E (x_0)
		$$

	\item \textbf{Misura di Lebesgue.}
		$$
		X = \R^n
		\qquad
		\mathcal{M}^n \text{ $\sigma$-algebra dei misurabili secondo Lebesgue}
		\qquad
		\mathscr L^n \text{ misura di Lebesgue}
		$$
		Dato $R$ parallelepipedo in $\R^n$, cioè $R = \prod_{k=1}^{n} I_k $ con $I_k$ intervalli in $\R$.
		Si pone
		$$
		\mathrm{vol}_n (R) \coloneqq \prod_{k=1}^{n}  \mathrm{lungh} (I_k)
		$$ 
		per ogni $E \subset \R^n$ (assumendo $\mathrm{lungh}([a, b]) = b - a$). Infine poniamo
		$$
		\mathscr L^n(E) \coloneqq \inf \left\{ \sum_{i} \mathrm{vol}_n (R_i) \mymid \left\{ R_i \right\} \text{tale che } E \subset \bigcup_i R_i  \right\}.
		$$
\end{itemize}
 
\textbf{Osservazioni.}
\begin{itemize}
	\item $\mathscr L^n(R) = \mathrm{vol}_n (R)$.
	\item $\mathscr L^n$ è così definita se $\mathcal{P}(\R^n)$ ma non è $\sigma$-addittiva.
	\item $\mathscr L^n$ è $\sigma$-addittiva su $\mathcal{M}^n$ (è per questo che bisogna introdurre $\mathcal{M}^n$).
\end{itemize}

Il terzo punto giustifica l'introduzione dei \textbf{misurabili secondo Lebesgue}. Dunque definiamo $\mathcal{M}^n$, dato $E \subset \R^n$ si dice che $E$ è misurabile (secondo Lebesgue) se
$$
\forall \epsilon > 0 \; \exists A \text{ aperto e } C \text{ chiuso con }
C \subset E \subset A 
\text{tali che}
\mathscr L^n (A \smallsetminus C) \leq \epsilon
$$

\textbf{Osservazioni.}
\begin{itemize}
	\item Per ogni $E$ misurabile vale
	\[
	\mathscr L^n(E) = \inf \left\{ \mathscr L^n \colon A \ \text{aperto}, A \supset E \right\} = \sup \left\{ \mathscr L^n \colon K \ \text{compatto}, K \subset E \right\}.
	\] 
	\item Notiamo che se $F \subset E$ con $E \subset \mathcal{M}^n$ e $\mathscr L^n(E) = 0$, allora $F \in \mathcal{M}^n$. Ovvero la misura di Lebesgue è completa!
\end{itemize}

\textbf{Notazione.} $\left| E \right| \coloneqq \mathscr L^n (E)$

\section{Funzioni misurabili}

\textbf{Definizione.}
Dato $(X, \mathcal{A}, \mu)$ e $f \colon X \to \R$ (o al posto di $\R$ in $Y$ spazio topologico), diciamo che $f$ è \textbf{misurabile} (più precisamente $\mathcal{A}$-misurabile), se
$$
\forall A \text{ aperto} \; f^{-1} (A) \in \mathcal{A}
$$ 


\textbf{Osservazioni.}
\nopagebreak
\begin{itemize}
	\item Dato $E \subset X$, vale $E \in \mathcal{A}$ se solo se $\One_E$ è misurabile.
	\item La classe delle funzioni misurabili è chiusa rispetto a molte operazioni
	\begin{itemize}
		\item \textit{somma}, \textit{prodotto} (se hanno senso nello spazio immagine della funzione).
		\item \textit{Composizione con funzione continua}: Se $f \colon X \to Y$ continua e $g \colon  Y \to Y'$ continua, allora $g \circ f$ è misurabile.
		\item \textit{Convergenza puntuale}: data una successione di $f_n$ misurabili e $f_n \to f$ puntualmente, allora $f$ è misurabile.
		\item $\liminf$ e $\limsup$ (almeno nel caso $Y = \R$).
	\end{itemize}
\end{itemize}


\subsection{Funzioni semplici}

% Indico con $\mathcal{S}$ la classe delle funzioni $f \colon  X \to \R$ \textit{semplici}, cioè della forma $f = \sum_{i}^{n} \alpha_i \One_{E_i}$ con $\{E_i \}_{1 \leq i \leq n}$ misurabili e $\alpha_i \in \R$.
\textbf{Definizione.}
Definiamo la classe delle \textbf{funzione semplici} come
$$
\mathcal S := \left\{ f \colon X \to \R \mymid f = \sum_i \alpha_i \One_{E_i} \text{ con $E_i$ misurabili e $\{\alpha_i\}$ finito} \right\}
$$

\textbf{Osservazione.} La rappresentazione di una funzione semplice come combinazione lineare di indicatrici di insiemi \textit{non è unica}, però se necessario possiamo prendere gli $E_i$ disgiunti.

\section{Integrale}

\textbf{Definizione.}
Diamo la definizione di $\ds\int_X f \dd \mu$ per passi
\begin{enumerate}
	\item \label{item:def_int_1} 
		Se $f \in \mathcal{S}$ e $f \geq 0$ cioè $f = \sum_i \alpha_i \One_{E_i}$ con $\alpha_i \geq 0$ allora poniamo
		\[
			\int\limits_{\mathclap{X}} f \dd \mu \coloneqq \sum_{i} \alpha_i \mu(E_i),
		\] 
		convenendo che $0 \cdot +\infty = 0$ in quanto la misura di un insieme non è necessariamente finita.
	
	\item \label{item:def_int_2} 
		Se $f \colon  X \to [0,+\infty]$ misurabile si pone
		\[
			\int\limits_{\mathclap{X}} f \dd \mu \coloneqq \sup_{\substack{g \in \mathcal{S} \\ 0 \leq g \leq f}} \int\limits_{\mathclap{X}} g \dd \mu.
		\] 
		
	\item 
		$f \colon X \to \overline{\R}$ misurabile si dice \textbf{integrabile} se 
		\[
			\int\limits_{\mathclap{X}} f^+ \dd \mu < + \infty \quad \text{oppure} \quad \int\limits_{\mathclap{X}} f^- \dd \mu < +\infty.
		\] 
		e per tali $f$ si pone
		\[
			\int\limits_{\mathclap{X}} f \dd \mu \coloneqq  \int\limits_{\mathclap{X}} f^+ \dd \mu - \int\limits_{\mathclap{X}} f^- \dd \mu.
		\] 
	
	\item 
		$f \colon X \to \R^n$ si dice \textbf{sommabile} (o di \textbf{classe} $\mathscr L^1$) se $\int_X \left| f \right| \dd \mu < +\infty$. In tal caso, se $\int_X f_i^{\pm} \dd \mu < +\infty$ per ogni $f_i$ componente di $f$, allora $\int_X f \dd \mu$ esiste ed è finito.
\end{enumerate}

Per tali $f$ si pone
\[
	\int\limits_{\mathclap{X}} f \dd \mu \coloneqq  \left( \int_X f_1 \dd \mu, \ldots , \int_X f_n \dd \mu \right).
\] 

\textbf{Notazione.}
Scriveremo spesso $\int_E f(x) \dd x$ invece di $\int_E f \dd \mathscr L^n$ .

\textbf{Osservazioni.}
\begin{itemize}
	\item L'integrale è lineare (sulle funzioni sommabili).
	
	\item I passaggi \ref{item:def_int_1} e \ref{item:def_int_2} danno lo stesso risultato per $f$ semplice $\geq 0$.
	
	\item La definizione in \ref{item:def_int_2} ha senso per ogni $f \colon X \to [0,+\infty]$ anche non misurabile. Ma in generale vale solo che
		$$
		\int\limits_{\mathclap{X}} f_1 + f_2 \dd \mu \geq \int_X f_1 \dd \mu + \int_X f_2 \dd \mu.
		$$
	
	\item Dato $E \in \mathcal{A}$, $f$ misurabile su $E$, notiamo che vale l'uguaglianza
		$$
		\int_E f \dd \mu \coloneqq \int_X f \cdot \One_E \dd \mu.
		$$ 
	
	\item Si può definire l'integrale anche per $f \colon X \to Y$ con $Y$ \textit{spazio vettoriale normato finito dimensionale}\footnote{È necessario avere uno spazio vettoriale, perchè serve la linearità e la moltiplicazione per scalare} ed $f$ sommabile.
	
	\item Se $f_1 = f_2$ $\mu$-q.o. allora $\ds \int_X f_1 \dd \mu = \int_X f_2 \dd \mu$.
	
	\item Si definisce $\ds \int_X f \dd \mu$ anche se  $f$ è misurabile e definita su $X \setminus N$ con $\mu(N) = 0$.
	
	\item Se $f \colon [a,b] \to \R$ è integrabile secondo Riemann allora è misurabile secondo Lebesgue e le due nozioni di integrale coincidono. 
		
		\textbf{Nota.} Lo stesso vale per integrali impropri di funzioni positive. Ma nel caso più generale non vale: se consideriamo la funzione
		$$
		f \colon (0,+\infty) \to \R 
		\qquad
		f(x) \coloneqq \dfrac{\sin x}{x}
		$$
		allora l'integrale di $f$ definito su $(0,+\infty)$ esiste come integrale improprio ma non secondo Lebesgue, infatti
		$$
		\int_0^{+\infty} f^+ \dd x = \int_0^{+\infty} f^- \dd x = +\infty
		$$
	
	\item $\ds \int_X f \dd \delta_{x_0} = f(x_0)$
	
	\item Se $X = \N$ e $\mu$ è la misura che conta i punti l'integrale è 
		$$
		\int_X f \dd \mu = \sum_{n = 0}^{\infty} f(n) 
		$$ 
		per le $f$ positive o tali che $\sum f^+(n) < +\infty $ oppure $\sum f^-(n) < +\infty $.
		
		\textbf{Nota.} Come prima nel caso di funzioni non sempre positive ci sono casi in cui la serie solita non è definita come integrale di una misura, ad esempio
		$$
		\sum_{n=1}^{\infty} \frac{(-1)^n}{n}
		$$
		esiste come serie ma non come integrale.
		
	\item Dato $X$ qualunque, $\mu$ misura che conta i punti e $f \colon  X \to [0,+\infty] $ possiamo definire la somma di tutti i valori di $f$ 
		$$
		\sum_{x \in X} f(x) \coloneqq \int\limits_{\mathclap{X}} f \dd \mu.  
		$$ 
\end{itemize}

\section{Teoremi di convergenza}

Sia $(X, \mathcal{A}, \mu)$ come in precedenza.

\textbf{Teorema.}
\textit{di convergenza monotona o Beppo-Levi.}
Date $f_n \colon  X \to [0,+\infty]$ misurabili, tali che $f_n \uparrow f$ ovunque in $X$, allora
$$
\lim_{n \to +\infty} \int\limits_{\mathclap{X}} f_n \dd \mu = \int\limits_X f \dd \mu,
$$
dove
$$
\lim_{n \to +\infty} \int\limits_{\mathclap{X}} f_n \dd \mu = \sup_n \int f_n \dd \mu.
$$


\textbf{Teorema.}
\textit{detto lemma di Fatou.}
Date $f_n \colon X \to [0,+\infty]$ misurabili, allora
$$
\liminf_{n \to +\infty} \int\limits_X f \dd \mu \geq \int\limits_{\mathclap{X}} \left( \liminf_{n \to +\infty} f_n \right) \dd \mu.
$$ 

\textbf{Teorema.}
\textit{di convergenza dominata o di Lebesgue.}
Date $f_n \colon  X \to \R$ (o anche $\R^n$) con le seguenti proprietà
\begin{itemize}
	\item \textit{Convergenza puntuale:} $f_n (x) \to f(x)$ per ogni $x \in X$.
	\item \textit{Dominazione:} Esiste $g \colon X \to [0,+\infty]$ sommabile tale che $\left| f_n (x) \right| \leq g(x)$ per ogni $x \in X$ e per ogni $n \in \N$.
\end{itemize}
allora
$$
\lim_{n \to \infty} \int\limits_{\mathclap{X}} f_n \dd \mu = \int\limits_X f \dd \mu. 
$$ 

\textbf{Nota.}
La seconda proprietà è essenziale; sostituirla con $\ds \int_X \left| f_n \right| \dd \mu \leq C < + \infty$ non basta!

\textbf{Definizione.}
Data una ``densità'' $\rho \colon  \R^n \to [0,+\infty]$ misurabile, la \textbf{misura $\mu$ con densità $\rho$} è data da
$$
\forall E \in \mathcal A \quad \mu(E) \coloneqq \int\limits_{\mathclap{E}} \rho \dd x
$$ 

\textbf{Osservazioni.}
\begin{itemize}
	\item $\R^n$ e $\mathscr L^n$ possono essere sostituiti da $X$ e $\widetilde{\mu}$.
	\item il fatto che $\mu$ è una misura segue da Beppo Levi, in particolare serve per mostrare la subadditività.
\end{itemize}


\textbf{Teorema.}
\textit{di cambio di variabile.}
Siano $\Omega$ e $\Omega'$ aperti di $\R^n$, $\Phi \colon \Omega \to \Omega' $ un diffeomorfismo di classe $C^1$ e $f \colon \Omega' \to [0,+\infty]$ misurabile. Allora
$$
\int\limits_{\mathclap{\Omega'}} f(x') \dd x' = \int\limits_{\mathclap{\Omega}} f(\Phi(x)) \left| \det(\nabla \Phi(x)) \right| \dd x.
$$

La stessa formula vale per $f$ a valori in $\overline{\R}$ integrabile e per $f$ a valori in $\R^n$ sommabile.

\textbf{Osservazioni.}
\begin{itemize}
	\item Se $n = 1$, $\left| \det(\nabla \Phi(x)) \right| = \left| \Phi'(x) \right|$ e non $\Phi'(x)$ come nella formula vista ad Analisi 1 (l'informazione del segno viene data dall'inversione degli estremi).
	
	\item Indebolire le ipotesi su $\Phi$ è delicato. Basta $\Phi$ di classe $C^1$ e $\foralmostall x' \in \Omega' \; \# \Phi^{-1}(x') = 1$ (supponendo $\Phi$ iniettiva la proprietà precedente segue immediatamente).
	Se $\Phi$ non è "quasi" iniettiva bisogna correggere la formula per tenere conto della molteplicità.

	\item Quest'ultima osservazione serve giusto per far funzionare il cambio in coordinate polari che non è iniettivo solo nell'origine.
\end{itemize}

\subsection{Fubini-Tonelli}

Di seguito riportiamo il teorema di Fubini-Tonelli per la misura di Lebesgue.

\textbf{Teorema.}
\textit{Fubini-Tonelli.}
Sia $\R^{n_1} \times \R^{n_2} \simeq \R^n$ con $n = n_1 + n_2$, $ E \coloneqq E_1 \times E_2 $ dove $E_1, E_2$ sono misurabili e $f$ è una funzione misurabile definita su $E$.
Se $f$ ha valori in $[0,+\infty]$ allora
$$
\int\limits_X f \dd \mu 
= \int\limits_{\mathclap{E_2}} \int\limits_{\mathclap{E_1}} f(x_1,x_2) \dd x_1 \dd x_2 
= \int\limits_{\mathclap{E_1}} \int\limits_{\mathclap{E_2}} f(x_1,x_2) \dd x_2 \dd x_1
$$ 

Vale lo stesso per $f$ a valori in $\R$ o in $\R^n$ sommabile.

\textbf{Osservazioni.}
Possiamo generalizzare il teorema di Fubini-Tonelli a misure generiche ed ottenere alcuni risultati utili che useremo ogni tanto.
\begin{itemize}
	\item Se $X_1, X_2$ sono spazi con misure $\mu_1,\mu_2$ (con opportune ipotesi) vale:
		$$
		\int\limits_{\mathclap{E_2}} \int\limits_{\mathclap{E_1}} f(x_1,x_2) \dd \mu_1(x_1)  \dd \mu_2(x_2) 
		= \int\limits_{\mathclap{E_1}} \int\limits_{\mathclap{E_2}} f(x_1,x_2) \dd \mu_2(x_2)  \dd \mu_1(x_1).
		$$ 
		se $f\geq 0$ oppure $\ds \int\limits_{\mathclap{X_1}} \int\limits_{\mathclap{x_2}} \left| f \right| \dd \mu_2(x_2)  \dd \mu_1(x_1) < + \infty $.
	
	\item \textit{Teorema di scambio serie-integrale:} Se $X_1 \subset \R$ (oppure $X_1 \subset \R^n$), $\mu_1 = \mathscr L^n$ e $X_2 = \N$, $\mu_2$ è la misura che conta i punti, allora la formula sopra diventa
		$$
		\sum_{n=0}^{\infty} \, \int\limits_{\mathclap{X_1}} f_n(x) \dd x  
		= \int\limits_{\mathclap{X_1}} \sum_{n=0}^{\infty} f_n(x)  \dd x.
		$$ 
		se $f_i \geq 0$ oppure $\ds \sum_{i} \int\limits_{\mathclap{X_1}} \left| f_i(x) \right| \dd x  < + \infty $.
	
	\item \textit{Teorema di scambio di serie:} Se $X_1 = X_2 = \N$ e $\mu_1 = \mu_2$ è la misura che conta i punti la formula sopra diventa
		$$
		\sum_{j=0}^{\infty} \sum_{i=0}^{\infty} a_{i,j}  
		= \sum_{i=0}^{\infty} \sum_{j=0}^{\infty} a_{i,j} 
		$$ 
		se $a_{i,j} \geq 0$ oppure $\ds \sum_{i} \sum_{j} \left| a_{i,j} \right| < +\infty $.
\end{itemize}

\chapter{Spazi $L^p$ e convoluzione}

\section{Disuguaglianze}

\subsection{Disuguaglianza di Jensen}

Ricordiamo che una funzione $f \colon \R^d \to [-\infty, +\infty]$ è \textbf{convessa} se e solo se dati $x_1, \dots, x_n \in \R^d$ e $\lambda_1, \dots, \lambda_n \in [0, 1]$ con $\sum_i \lambda_i = 1$ abbiamo che
$$
f \left(\sum_i \lambda_i x_i \right) \leq \sum_i \lambda_i f(x_i)
$$

\textbf{Teorema} (Jensen),
Dato $(X, \mathcal A, \mu)$ con $\mu(X) = 1$ e $f \colon \R^d \to [-\infty, +\infty]$ convessa e semi-continua inferiormente (S.C.I.) e $u \colon X \to \R^d$ sommabile allora vale
$$
\int_X f \compose u \dd \mu \geq f \left( \int_X u \dd \mu \right)
$$
e $f \compose u$ è integrabile.

\textbf{Osservazioni.}
\begin{itemize}
	\item $(f \compose u)^-$ ha integrale finito.

	\item Interpretando $\mu$ come probabilità si riscrive come $\mathbb E[f \compose \mu] \geq f(\mathbb[u])$.

	\item Se $u$ è una funzione semplice, cioè $u = \sum_i y_i \cdot \One_{E_i}$ con $E_i$ disgiunti e $\bigcup E_i = X$ allora posti $\lambda_i = \mu(E_i)$ abbiamo
		$$
		\int_X f \compose u \dd \mu = \int_X \sum_i f(y_i) \cdot \One_{E_i} \dd \mu = \sum_i \lambda_i f(y_i) \geq f \left( \sum_i \lambda_i y_i \right) = f \left( \int_X u \dd \mu \right)
		$$

		Questo ci darebbe una strada per dimostrare in generale per passi il teorema di Jensen ma in realtà si presentano vari problemi tecnici.

	\item Ogni funzione convessa e S.C.I su $\Omega$ convesso in $\R^d$ si estende a $\tilde f \colon \R \to (-\infty, +\infty]$ convessa e S.C.I., ad esempio se $\Omega = (0, +\infty)$
		$$
		f(y) = \frac{1}{y}
		\quad\rightsquigarrow\quad
		\tilde f(y) = 
		\begin{cases}
			+\infty & y \leq 0 \\[3pt]
			\dfrac{1}{y} & y > 0
		\end{cases}
		$$

	\item La semi-continuità inferiore serve perché le funzioni convesse sono continue solo se a valori in $\R$, ad esempio per $k$ costante la funzione
		$$
		f(y) := 
		\begin{cases}
			k & y < 0 \\
			+\infty & y \geq 0
		\end{cases}
		$$
		è convessa ma non semi-continua inferiormente (e neanche continua).
\end{itemize}

\textbf{Dimostrazione.}
Poniamo $y_0 \coloneqq \int_X u \dd \mu$, allora la tesi diventa
$$
\int_X f \compose u \dd \mu \geq f(y_0)
$$
Prendiamo $\phi \colon \R^d \to \R$ affine (ovvero $\phi(y) = a \cdot y + b$ con $a \in \R^d$ e $b \in \R$) tale che $\phi \leq f$, allora
$$
\int_X f \compose u \dd \mu \geq \int_X \phi \compose u \dd \mu = \int_X a \cdot u + b \dd \mu = a y_0 + b = \phi(y_0)
$$

Infine concludiamo usando il seguente lemma di caratterizzazione delle funzioni convesse ed S.C.I.

\textbf{Lemma.}
Ogni $f \colon \R^d \to (-\infty, +\infty]$ convessa e S.C.I è tale che
$$
\forall y_0 \in \R^d \quad \sup_{\substack{\phi \text{ affine} \\ \phi \leq f}} \phi(y_0) = f(y_0)
$$

Nel caso $d = 1$ e $f \colon \R \to \R$ possiamo appoggiarci al fatto che le funzioni convesse sono ammettono sempre derivata destra o sinistra, il $\sup$ diventa un massimo e ci basta prendere come $\phi$ la retta tangente in $(y_0, f(y_0))$ o una con pendenza compresa tra $f'(y_0^-)$ e $f'(y_0^+)$.

Rileggendo meglio la dimostrazione segue che $(f \compose u)^- < (\phi \compose u)^- \implies (f \compose u)^-$. 

\qed

\section{Costruzione spazi $L^p$}

\textbf{Definizione.} Dati $p_1, p_2 \in [1, +\infty]$ diciamo che sono \textbf{coniugati} se
$$
\frac{1}{p_1} + \frac{1}{p_2} = 1
$$
convenendo che $\sfrac{1}{\infty} = 0$.

Fissiamo $p \in [1, +\infty]$ detto ``esponente di sommabilità'' e sia $(X, \mathcal A, \mu)$ come sempre.

\textbf{Definizione.} $f \colon X \to \overline \R$ o $\R^d$ misurabile, allora la \textbf{norma $p$ di $f$} è per $p \in [1, +\infty)$
$$
\norm{f}_p \coloneqq \left( \int_X |f|^p \dd \mu \right)^p
$$
mentre per $p = +\infty$ poniamo
$$
\norm{f}_\infty \coloneqq \inf \{ m \in [0, +\infty] \mid |f(x)| \leq m \text{ per $\mu$-q.o. } x \}
$$
in realtà queste sono solo delle semi-norme\footnote{Vedremo meglio più avanti questo dettaglio}.

\begin{itemize}
	\item $\ds \norm{f}_\infty \leq \sup_{x \in X} |f(x)|$

	\item $\norm{f}_p = 0 \iff f = 0$ quasi ovunque

		\textbf{Dimostrazione.}
		\begin{itemize}
			\item[$\boxed{\Rightarrow}$] [TODO: Facile ma non ovvia]
			\item[$\boxed{\Leftarrow}$] Ovvio.
		\end{itemize}
		\qed

	\item Se $f_1 = f_2$ quasi ovunque $\implies \norm{f_1}_p = \norm{f_2}_p$.

		\textbf{Dimostrazione.} 
		$f_1 = f_2$ quasi ovunque $\implies \exists D \subset X$ con $\mu(D) = 0$ tale che $f_1(x) = f_2(x)$ su $X \setminus D$, usiamo il fatto che l'integrale non cambia se modifichiamo la funzione su un insieme di misura nulla
		$$
		\norm{f_1}_p^p
		= \int_X |f_1|^p \dd \mu 
		= \int_{X \setminus D} |f_1|^p \dd \mu 
		= \int_{X \setminus D} |f_2|^p \dd \mu 
		= \int_{X} |f_2|^p \dd \mu 
		= \norm{f_2}_p^p
		$$ 
		\qed
\end{itemize}

\subsection{Disuguaglianza di Young}

\textbf{Proposizione.}
Per ogni $a_1, a_2 \geq 0$ e $\lambda_1, \lambda_2 > 0$ con $\lambda_1 + \lambda_2 > 0$ abbiamo che
$$
a_1^{\lambda_1} a_2^{\lambda_2} \leq \lambda_1 a_1 + \lambda_2 a_2
$$
inoltre vale l'uguale se e solo se $a_1 = a_2$.

\textbf{Dimostrazione.}
Se $a_1 = a_2 = 0$ allora è ovvia. Supponiamo dunque $a_1, a_2 > 0$, ma sappiamo che 
% e passiamo $a_1^{\lambda_1} a_2^{\lambda_2}$ al logaritmo
$$
\lambda_1 \log a_1 + \lambda_2 \log a_2 \leq \log(\lambda_1 a_2 + \lambda_2 a_2)
$$
per concavità del logaritmo e quindi segue la tesi.

Il se e solo se per l'uguale segue dal fatto che il logaritmo è \textit{strettamente concavo}. 
\qed

\subsection{Disuguaglianza di H\"older}

\textbf{Proposizione.}
Date $f_1, f_2 \colon X \to \overline\R$ o $\R^d$ e $p_1, p_2$ esponenti coniugati allora
$$
\int_X |f_1| \cdot |f_2| \dd \mu \leq \norm{f_1}_{p_1} \cdot \norm{f_2}_{p_2}
$$ 
vale anche per $p = +\infty$ convenendo che $+\infty \cdot 0 = 0$ a destra dell'uguale.

\textbf{Dimostrazione.}
Se $\norm{f_1}_{p_1} = 0$ o $+\infty$ e anche $\norm{f_2}_{p_2} = 0$ o $+\infty$ la dimostrazione è immediata, supponiamo dunque $\norm{f_1}_{p_1}, \norm{f_2}_{p_2} > 0$ e finiti.

\begin{itemize}
	\item \textit{Caso 1:} se $p_1 = 1, p_2 = +\infty$ allora
		$$
		\int_X |f_1| \cdot |f_2| \dd \mu 
		\leq \int_X |f_1| \cdot \norm{f_2}_{\infty} \dd \mu
		= \norm{f_2}_{\infty} \cdot \int_X |f_1| \dd \mu
		= \norm{f_2}_{\infty} \cdot \norm{f_1}_{1} 
		$$

	\item \textit{Caso 2:} se $1 < p_1, p_2 < +\infty$, introduciamo un parametro $\gamma > 0$ allora
		$$
		\int_X |f_1| \cdot |f_2| \dd \mu 
		= \int_X \left( \gamma^{p_1} \cdot |f_1|^{p_1} \right)^{1/p_1} \cdot \left( \gamma^{-p_2} \cdot |f_1|^{p_2} \right)^{1/p_2} \dd \mu
		$$
		a questo punto chiamiamo per comodità $g_1 := \gamma^{p_1} \cdot |f_1|^{p_1}$, $\lambda_1 := 1 / p_1$ e $g_2 := \gamma^{-p_2} \cdot |f_1|^{p_2}$, $\lambda_2 := 1 / p_2$ da cui
		$$
		= \int_X g_1^{\lambda_1} \cdot g_2^{\lambda_2} 
		\overset{\text{Young}}{\leq} \int_X \lambda_1 g_1 + \lambda_2 g_2 \dd \mu
		= \lambda_1 \gamma^{p_1} \int_X |f_1|^{p_1} + \lambda_2 \gamma^{-p_2} \int_X |f_1|^{p_2} \dd \mu
		$$
		$$
		= \lambda_1 \gamma^{p_1} \cdot \norm{f_1}_{p_1}^{p_1} + \lambda_2 \gamma^{-p_2} \cdot \norm{f_1}_{p_2}^{p_2}
		$$
		posti ora $a_1 := \gamma^{p_1} \norm{f_1}_{p_1}^{p_1}$ e $a_2 := \gamma^{-p_2} \norm{f_1}_{p_2}^{p_2}$, per $\gamma \to 0$ abbiamo che $a_1 \to 0, a_2 \to +\infty$ mentre per $\gamma \to +\infty$ abbiamo che $a_1 \to +\infty, a_2 \to 0$ dunque per il teorema del valor medio esisterà $\gamma$ tale che $a_1 = a_2$, ma allora siamo nel caso dell'uguaglianza per la disuguaglianza di Young dunque
		$$
		\lambda_1 \gamma^{p_1} \norm{f_1}_{p_1}^{p_1} + \lambda_2 \gamma^{-p_2} \norm{f_1}_{p_2}^{p_2} 
		= \lambda_1 a_1 + \lambda_2 a_2 = a_1^{\lambda_1} \cdot a_2^{\lambda_2} 
		= \norm{f_1}_{p_1} \cdot \norm{f_2}_{p_2}
		$$
\end{itemize}
In particolare l'uguaglianza vale se [TODO]
\qed

\textbf{Osservazione.}
La disuguaglianza di H\"older può essere generalizzata a $n$ funzioni, date $f_1, \dots, f_n$ e $p_1, \dots, p_n$ con $\frac{1}{p_1} + \dots + \frac{1}{p_2} = 1$ allora
$$
\int_X \prod_i |f_i| \dd \mu \leq \prod_i \norm{f_i}_{p_i} 
$$

\subsection{Disuguaglianza di Minkowski}

\textbf{Proposizione.} 
Consideriamo sempre $(X, \mathcal A, \mu)$ e sia $p \in [1, +\infty]$ un esponente di sommabilità ed $f_1, f_2 \colon X \to \R$ oppure $\R^d$ allora vale la disuguaglianza triangolare
$$
\norm{f_1 + f_2}_p \leq \norm{f_1}_p + \norm{f_2}_p
$$

\textbf{Dimostrazione.}
\begin{itemize}
	\item \textit{Caso 1:} se $p = 1$ o $p = +\infty$, allora basta fare il calcolo diretto
		
		\begin{itemize}
			\item Se $p = 1$
				$$
				\norm{f_1 + f_2}_1 
				= \int_X |f_1 + f_2| \dd \mu 
				\leq \int_X |f_1| + |f_2| \dd \mu 
				= \int_X |f_1| \dd \mu + \int_X |f_2| \dd \mu
				= \norm{f_1}_1 + \norm{f_2}_1
				$$
			\item Se $p = +\infty$
				$$
				\norm{f_1 + f_2}_\infty
				= \mathrm{supess}_X |f_1 + f_2| 
				= \mathrm{supess}_{X \setminus D} 
				\leq \mathrm{supess}_{X \setminus D} (|f_1| + |f_2|)
				$$
				$$
				= \mathrm{supess}_{X \setminus D} |f_1| + \mathrm{supess}_{X \setminus D} |f_2|
				= \mathrm{supess}_X |f_1| + \mathrm{supess}_X |f_2|
				= \norm{f_1}_\infty + \norm{f_2}_\infty
				$$
		\end{itemize}

	\item \textit{Caso 2:} se $1 < p < +\infty$ e $0 < \norm{f_1 + f_2}_p < +\infty$
		$$
		\begin{aligned}
			\norm{f_1 + f_2}_p^p 
			&= \int_X |f_1 + f_2|^p 
			\leq \int_X (|f_1| + |f_2|) \cdot |f_1 + f_2|^{p-1} \dd \mu = \\
			&= \int_X |f_1| \cdot |f_1 + f_2|^{p-1} \dd \mu + \int_X |f_2| \cdot |f_1 + f_2|^{p-1} \dd \mu = \\
			&\overset{\text{H\"older}}{\leq} \norm{f_1}_p \cdot \norm{|f_1 + f_2|^{p-1}}_q + \norm{f_2}_p \cdot \norm{|f_1 + f_2|^{p-1}}_q = \\
			& = (\norm{f_1}_p + \norm{f_2}_p) \cdot \norm{|f_1 + f_2|^{p-1}}_q 
			= (\norm{f_1}_p + \norm{f_2}_p) \cdot \norm{f_1 + f_2}_p^{p-1}  \\
		\end{aligned}
		$$
		e poiché $\norm{f_1 + f_2}_p > 0$ possiamo portare l'ultimo fattore dall'altra parte
		$$
		\implies \frac{\norm{f_1 + f_2}_p^p }{\norm{f_1 + f_2}_p^{p-1}} \leq \norm{f_1}_p + \norm{f_2}_p
		\implies \norm{f_1 + f_2}_p \leq \norm{f_1}_p + \norm{f_2}_p
		$$

	\item \textit{Caso 3:} se $1 < p < +\infty$ ma $\norm{f_1 + f_2} = 0$ o $+\infty$ allora se $\norm{f_1 + f_2} = 0$ la disuguaglianza è banale mentre se $\norm{f_1 + f_2} = +\infty$ si usa la seguente disuguaglianza
		$$
		\norm{f_1 + f_2}_p^p \leq 2^{p-1} (\norm{f_1}_p^p + \norm{f_2}_p^p)
		$$
		che si ottiene usando la convessità della funzione $y \mapsto y^p$
		$$
		\norm{f_1 + f_2}_p^p 
		= \int_X |f_1 + f_2|^p \dd \mu 
		= 2^p \int_X \left| \frac{f_1 + f_2}{2} \right|^p \dd \mu 
		$$
		$$
		\leq 2^p \int_X \frac{1}{2} |f_1|^p + \frac{1}{2}|f_2|^p \dd \mu 
		= 2^{p-1} (\norm{f_1}_p^p + \norm{f_2}_p^p)
		$$
		da cui possiamo ricavare subito che almeno uno dei due termini deve essere $+\infty$.

\end{itemize}

% lezione del 4 ottobre 2021
\section*{Esercitazione del 4 ottobre}

\subsection*{Teoria della misura}

Di seguito riportiamo alcune proprietà di base di teoria della misura.

\textbf{Proprietà.}

\begin{enumerate}
\item Se $A \subset B$, allora $\mu(A) \leq \mu(B)$.

\textbf{Dimostrazione.}
Scomponiamo $B = (B \setminus A) \cup (A \cap B)$. Per ipotesi $A \cap B = A$ ed essendo la misura positiva segue che
\[
	\mu(B) = \underbrace{\mu(B \setminus A)}_{\geq 0} + \mu(A) \geq \mu(A).
\] 

\item \label{item:misura_unione_finita} Dati due insiemi $A,B$ misurabili, vale
\[
	\mu(A \cup B) \leq \mu(A) + \mu(B).
\] 

\textbf{Dimostrazione.}
La disuguaglianza segue dalle seguenti uguaglianze.

\begin{align*}
	\mu(A) & = \mu(A \setminus B) + \mu(A \cap B) \\
	\mu(B) & = \mu(B \setminus A) + \mu(A \cap B) \\
	\mu(A \cup B) & = \mu(A \setminus B ) + \mu(B \setminus A) + \mu(A \cap B).
\end{align*}

\item Data una successione di insiemi $E_1 \subset E_2 \subset \cdots \subset \cdots$, si ha
\[
	\mu \left( \bigcup_{i} E_i \right) = \sup_i \mu(E_i) = \lim_i \mu (E_i).
\] 

\item Data una successione di insiemi $E_1 \supset E_2 \supset \cdots \supset \cdots$ e $\mu(E_1) < +\infty$, si ha
\[
	\mu \left( \bigcap_{i} E_i \right) = \lim_i \mu (E_i).
\] 

\end{enumerate}

\textbf{Esercizio} (Numberabile subaddittività).
Dato $\ds E \in \mathcal{A}, E \subset \bigcup_i E_i$ dove $E_i \in \mathcal{A}$. Allora
\[
	\mu(E) \leq \sum_{i}^{} \mu(E_i).
\] 

\textbf{Dimostrazione} (\textit{Idea}).
Basta dimostrare che $\ds \mu \left( \bigcup_i E_i \right) \leq \sum_{i}^{} \mu(E_i)$. Infatti per quanto visto prima $\ds \mu(E) \leq \mu \left( \bigcup_i E_i \right)$. Prima dimostriamo per induzione $\ds \mu \left( \bigcup_{i = 1}^N E_i \right) \leq \sum_{i=1}^{N} \mu(E_i)$. 

Il passo base $n = 2$ è stato visto al punto \ref{item:misura_unione_finita}. Una volta dimostrata la proprietà sopra, si nota che $\ds \sum_{i=1}^{N} \mu(E_i) $ è limitata per ogni $N$, e dunque è limitato anche il suo limite, da cui la tesi.

\subsection*{Funzioni misurabili rispetto alla misura di Lebesgue}

Si ricorda che le funzioni \textit{continue}, \textit{semplici} e \textit{semicontinue} sono classi di funzioni misurabili.
Due osservazioni sulle funzioni semicontinue.
\begin{itemize}
\item Le funzioni semicontinue sono \textit{boreliane}.

\item La proprietà di misurabilità delle funzioni semicontinue è necessaria per l'enunciato della disuguaglianza di Jensen.
\end{itemize}

\textbf{Controesempio} (\textit{Disuguaglianza di Jensen.})
Notiamo che l'ipotesi di semicontinuità inferiore della funzione $f$ è necessaria per la validità della disuguaglianza di Jensen.
Infatti, definiamo $f$ come segue

\[
f(x) = 
\begin{cases}
0 \qquad \; x \in (0,1) \\
+ \infty \quad \text{altrimenti} 
\end{cases}.
\] 

Osserviamo che la funzione $f$ così definita è convessa ma non semicontinua inferiormente.

Ora definiamo la funzione $u : X \to \R$ con $X = (0,2)$, come la funzione costante di valore $1/2$.
Calcoliamo l'integrale di $u(x)$ su $X$.

\[
	\int\limits_{\mathclap{X}} u(x) \dd x = 1. 
\] 

In tal caso vale $\ds f \left( \int_X u(x) \dd x \right) = + \infty$.
D'altra parte $\ds \int_X f \compose u \dd x = 0$, dunque l'ipotesi di semicontinuità inferiore è necessaria.

\textbf{Fatto.}
Date $\myphi_1, \myphi_2$ funzioni semplici su $\R$ con misura di Lebesgue.
Allora $\myphi_1 \vee \myphi_2$ e $\myphi_1 \wedge \myphi_2$ sono ancora funzioni semplici.

\textbf{Lemma.}
Data $f \colon X \to [0, +\infty]$ misurabile
\[
\int_X f \dd \mu = 0 \quad \longiff \quad f = 0 \; \text{q.o. su } X.
\] 

\textbf{Dimostrazione.}
\begin{itemize}

\item[$\boxed{\Rightarrow}$] Dato che $f$ è non negativa, il dominio $X$ può essere riscritto come
\[
	X = \left\{ x \in X \mymid f(x) \geq 0 \right\} = \left\{ x \in X \mymid f(x) > 0 \right\} \cup \left\{ x \in X \mymid f(x) = 0 \right\}
\] 
ricordiamo che $(0, +\infty) = \bigcup_{n \geq 1} (\frac{1}{n}, +\infty)$ da cui segue
\[
	\left\{ x \in X \mymid f(x) > 0 \right\} =  \bigcup_{n \in \N \setminus \left\{ 0 \right\}} \left\{ x \in X \mymid f(x) \geq \frac{1}{n} \right\},
\] 
e passiamo alle misure
\[
	\mu \left( \left\{ x \in X \mymid f(x) > 0 \right\} \right) 
	= \lim_{n \to +\infty} \mu\left(\left\{ x \in X \mymid f(x) \geq \frac{1}{n} \right\}\right),
\] 
in questo modo otteniamo la seguente caratterizzazione dell'insieme su cui $f$ è positiva
\[
	\mu \left( \left\{ x \in X \mymid f(x) > 0 \right\} \right) >0 
	\longiff
	\exists \bar{n} \mid \mu \left( \left\{ x \in X \mymid f(x) \geq 1 / \bar{n} \right\} \right) > 0.
\] 

% @aziis98: Boh magari potremmo definire tipo L_n := { blob sotto l'integrale } per rendere un po' più leggibile quel dominio di integrazione.
% @aziis98: Oppure anche in notazione "probabilistica" $\{ f \geq \frac{1}{n} \}$ che è più corto
Allora possiamo maggiorare come segue
\[
	0 = \int_X f \dd \mu 
	\geq \;\;\int\limits_{\mathclap{\left\{ x \mymid f(x) \geq \frac{1}{n} \right\}}}^{} \;\; f \dd \mu \geq	\frac{1}{n} \mu \left(  \left\{ x \mymid f(x) \geq \frac{1}{n} \right\} \right). 
\] 
Dunque abbiamo
\[
	\mu \left(  \left\{ x \mymid f(x) \geq \frac{1}{n} \right\} \right) = 0 \qquad \forall n.
\] 
Si conclude osservando che
\[
	\mu \left(  \left\{ x \mymid f(x) > 0 \right\} \right) = \lim_n \mu \left( \left\{ x \mymid f(x) \geq \frac{1}{n} \right\} \right) = 0.
\] 

\item[$\boxed{\Leftarrow}$]
Dal fatto che $f$ è positiva possiamo scrivere
\[
	\int_X f \dd \mu = \sup_{\substack{g \leq f \\ g \; \text{semplice}}} \int_X g \dd \mu = \sup \sum_{i}^{} \alpha_i \mu(E_i) = 0. 
\] 

\end{itemize}

\textbf{Osservazione.} (sup essenziale di funzioni misurabili).
Data $f$ misurabile, definiamo
 \[
	\norm{ f }_{\infty, X} \coloneqq \inf \left\{ m \in [0,+\infty] \mymid \left| f(x) \right| \leq m \quad \text{quasi ovunque}  \right\}.
\] 

Se $\norm{ f }_{\infty} < + \infty$, allora diciamo che esiste una costante $L > 0$ con $L = \norm{ f }_{\infty, X}$, tale che 
\[
	\left| f(x) \right| \leq L
\] 
quasi ovunque. 
Infatti, per definizione di $\inf$, $L = \lim_n m_n$, dove $m_n$ verificano
\[
	\left| f(x) \right| \leq m_n \quad \forall x \in X \setminus N_m, \quad \mu(N_m) = 0.
\] 
Definiamo $N = \bigcup_{m} N_m$, da cui si ottiene
\[
	\mu(N) \leq \sum_{n=1}^{\infty} \mu (N_m) = 0. 
\] 
Ovvero $N$ è trascurabile.
Preso $x \in X \setminus N$, vale
\[
	\left| f(x) \right| \leq m_n \quad \forall n \in \N.
\] 


\subsection*{Formula di cambio di variabile applicata a funzioni radiali}

Sia $f \colon [0,+\infty) \to \R$ misurabile (di solito si richiede misurabile e positiva oppure sommabile).
Vala la seguente
\[
	\int\limits_{\mathclap{0}}^{+\infty} f\left( \left| x \right| \right) \dd x = c_n \cdot \int\limits_{\mathclap{0}}^{+\infty} f(\rho) \rho^{n-1} \dd \rho,
\] 
dove $\ds c_n = n \mathscr L^n \left( \mathcal{B}(0,1) \right)$.

Applichiamo questa formula alla stima di integrali di funzioni positive.

\textbf{Esercizio.}
Sia
\[
	\psi (x) = \frac{1}{\norm{ x }^{\alpha}}
\] 
% @aziis98: Boh secondo me possiamo usare anche solo B(0, 1) invece di \mathcal B(0, 1), sempre sul tema di fare con \mathcal solo l'insieme delle parti e le sigma-algebre?
su $\mathcal{B}(0,1) \in \R^n$. Notiamo che $\psi(x) = f(\norm{ x })$ con $f = 1 / t^\alpha$.
Usiamo la formula appena introdotta per determinare gli $\alpha \in \R$ per i quali $\psi$ è sommabile su $\mathcal{B}(0,1)$.

\[
\int\limits_{\mathclap{\mathcal{B}(0,1)}}^{} \psi(x) \dd x = c_n \int\limits_{\mathclap{0}}^{1} \frac{1}{\rho} \rho^{n -1} \dd \rho = c_n \int\limits_{\mathclap{0}}^{1} \rho^{n-1-\alpha} \dd \rho =
\begin{cases}
	\log (\rho) \quad n = \alpha \\
	\dfrac{\rho^{n-\alpha}}{n - \alpha} \quad \text{altrimenti} 
\end{cases} 
\] 

Concludendo,
\[
	\int\limits_{\mathcal{B}(0,1)}^{} \frac{1}{\norm{ x }^\alpha} \dd x < + \infty \longiff n > \alpha.
\] 

\textbf{Esercizio.}
Con passaggi analoghi al precedente otteniamo
\[
	\int\limits_{\R^n \setminus \; \mathcal{B}(0,1)}^{} \frac{1}{\norm{ x }^\alpha} \dd x < + \infty \longiff n < \alpha.
\] 

\textbf{Esercizio.}
Vediamo per quali valori di $\beta$ l'integrale
\[
	\int\limits_{\mathcal{B}(0,1)}^{} \frac{1}{\left( \norm{ x } + \norm{ x }^2 \right)^\beta} \dd x
\] 
converge.

Vale la seguente catena di uguaglianze.

\[
\int\limits_{\mathclap{\R^n}}^{} \frac{1}{\left( \norm{ x } + \norm{ x }^2 \right)^\beta} \dd x 
= \int\limits_{\mathcal{B}(0,1)}^{} \frac{1}{\left( \norm{ x } + \norm{ x }^2 \right)^\beta} \dd x 
+ \int\limits_{\R^n \setminus \; \mathcal{B}(0,1)}^{} \frac{1}{\left( \norm{ x } + \norm{ x }^2 \right)^\beta} \dd x.
\] 

Studiamo separatamente i due pezzi dell'integrale.

\begin{align*}
	\int\limits_{\mathcal{B}(0,1)}^{} \frac{1}{\left( \norm{ x } + \norm{ x }^2 \right)^\beta} \dd x 
	& = c_n \int\limits_{\mathclap{\mathcal{B}(0,1)}}^{} \frac{1}{\rho + \rho^2}^\beta \rho^{n-1} \dd \rho
	= c_n \int\limits_{\mathclap{0}}^{1} \frac{1}{\rho^\beta} \cdot \frac{\rho^{n-1}}{(1 + \rho)^\beta} \dd \rho \\
	& \approx \int\limits_{\mathclap{0}}^{1} \rho^{n-1-\beta} \dd \rho < + \infty \longiff  \beta < n.
\end{align*}

Inoltre,

\[
	\int\limits_{\mathcal{B}(0,1)}^{} \frac{1}{\left( \norm{ x } + \norm{ x }^2 \right)^\beta} \dd x 
	= \int\limits_{\mathclap{\R^n \setminus \; \mathcal{B}(0,1)}}^{} \frac{1}{\rho^{2\beta}} \cdot \frac{\rho^{n-1}}{\left( \frac{1}{\rho} + 1 \right)^\beta} \dd \rho 
	\approx \int\limits_{\mathclap{1}}^{+\infty} \frac{\rho^{n-1}}{\rho^{2\beta}} \dd rho < + \infty \longiff 2\beta > \alpha.  
\] 

In conclusione, l'integrale è finito se $n > \beta > n / 2$.

% @aziis98: Molto probabilmente metterò un disegnino con assi $n$ e $\beta$ per far vedere "meglio" l'insieme dei valori buoni

\textbf{Esercizio.}
Studiare l'insieme di finitezza al variare del parametro $\alpha$ dell'integrale
\[
	\int\limits_{\mathclap{[0,1]^n}}^{} \frac{1}{\norm{ x }_1^\alpha} \dd x 
\] 
Osserviamo che la norma 1 e 2 sono legate dalle seguenti disuguglianze
\[
	\frac{\norm{ x }_1}{n} \leq \norm{ x }_2 \leq \norm{ x }_1.
\] 

Studiamo una maggiorazione per l'integrale

\[
	\int\limits_{\mathclap{[0,1]^n}}^{} \, \frac{1}{\norm{ x }_1^\alpha} \dd x 
	\leq \;\int\limits_{\mathclap{[0,1]^n}}^{} \, \frac{1}{\norm{ x }^\alpha} \dd x 
	\leq \;\;\int\limits_{\mathclap{\mathcal{B}(0,\sqrt{n})}}^{}\;\; \frac{1}{\norm{ x }^\alpha} \dd x < + \infty \quad \text{se} \; \alpha < n.
\] 

Vediamo ora una minorazione.

\[
	\int\limits_{\mathclap{[0,1]^n}}^{} \frac{1}{\norm{ x }_1^\alpha} \dd x 
= \frac{1}{2^n}	\int\limits_{[-1,1]^n}^{} \frac{1}{\norm{ x }_1^\alpha} \dd x 
\geq \int\limits_{\mathclap{\mathcal{B}(0,1)}}^{} \frac{1}{\norm{ x }_1^\alpha} \dd x 
\approx \int\limits_{\mathclap{\mathcal{B}(0,1)}}^{} \frac{1}{\norm{ x }_1^\alpha} \dd x < + \infty 
\longiff \alpha < n.
\] 

\textbf{Esercizi per casa.}
\begin{enumerate}[label=(\arabic*)]

\item Dimostrare che date $f,g$ misurabili ed $r,p_1,p_2 > 0$ tali che  $1 / r = 1 / p_1 + 1 / p_2$.
Allora vale
\[
	\norm{ f \cdot g }_r \leq \norm{ f }_{p_1} + \norm{ g }_{p_2}.
\] 
\textit{Suggerimento.} Usare Holder osservando che $\ds 1 = \frac{r}{p_1} + \frac{r}{p_2} = \frac{1}{\left( p_1/r \right)} + \frac{1}{\left( p_2/r \right)}$.

\item Dimostrare che date $f_1,\ldots, f_n$ misurabili e $p_i > 0$ tali che $1/p_1 + \ldots + 1/p_n = 1$ si ha
\[
	\norm{ f_1 \cdots f_n }_1 \leq \norm{ f_1 }_{p_1} \cdots \norm{ f_n }_{p_n}.
\] 
\textit{Suggerimento.} Fare il primo passo dell'induzione e usare la formula precedente scegliendo $r$ in modo corretto.

\end{enumerate}


\chapter{Spazi di Hilbert}

% TODO

\chapter{Serie di Fourier}

% TODO

\chapter{Applicazioni della serie di Fourier}

% TODO

\chapter{Trasformata di Fourier}

% TODO

\chapter{Funzioni armoniche}

% TODO

\chapter{Integrazione di superfici}

% TODO

\newpage

\section{Indice Analitico}

Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod
tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam,
quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo
consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse
cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non
proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

\begin{multicols*}{2}

\makebox[3cm][l]{\absurd} Assurdo

\makebox[3cm][l]{\absurd} Assurdo

\makebox[3cm][l]{\absurd} Assurdo

\makebox[3cm][l]{\absurd} Assurdo

\vfill\null\columnbreak

\makebox[3cm][l]{\absurd} Assurdo

\makebox[3cm][l]{\absurd} Assurdo

\makebox[3cm][l]{\absurd} Assurdo

\makebox[3cm][l]{\absurd} Assurdo

\end{multicols*}

\end{document}
