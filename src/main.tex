\documentclass[a4paper, 12pt]{report}

\input{prelude.tex}

\title{{\Huge Analisi 3}\\{\small Appunti di Analisi 3 del corso di Giovanni Alberti e Maria Stella Gelli}}
\author{Arianna Carelli e Antonio De Lucreziis}
\date{I Semestre 2021/2021}

\begin{document}

%
% Removes initial indentation from paragraphs.
%
\parskip 1ex
\setlength{\parindent}{0pt}

% Initial page
\maketitle

% Table of contents
\tableofcontents
\newpage

\chapter{Teoria della misura}

\section{Misure astratte}

\textbf{Definizione.} 
Uno spazio misurabile è una terna $(X, \mathcal A, \mu)$ tale che
\begin{itemize}
	
	\item $X$ è un insieme qualunque.

	\item $\mathcal{A}$ è una $\sigma$-algebra di sottoinsiemi di $X$, ovvero una famiglia di sottoinsiemi di $X$ che rispetta le seguenti proprietà:
		\begin{itemize}
			\item $\emptyset, X \in \mathcal{A}$.
			\item $\mathcal{A}$ è chiusa per complementare, unione e intersezione numerabile.
		\end{itemize}
	
	\item $\mu$ è una misura su $X$, ossia una funzione $\mu \colon \mathcal A \to [0, +\infty]$ $\sigma$-addittiva, cioè tale che data una famiglia numerabile $\left\{ E_k \right\} \subset \mathcal A$ disgiunta e posto $E \coloneqq \bigcup E_n $, allora
		$$
		\mu(E) = \sum_{n} \mu (E_n).
		$$

\end{itemize}


\textbf{Notazione.}
Data una crescente di insiemi $E_1 \subset E_2 \subset \cdots E_n \subset \cdots$ con $\bigcup E_n = E$, scriviamo $E_n \uparrow E$.

\textbf{Proprietà.}
\begin{itemize}
	\item $\mu(\emptyset) = 0$
	\item \textit{Monotonia}: Dati $E,E' \in \mathcal{A}$ e $E \subset E'$, allora $\mu(E) \leq \mu(E')$.
	\item Data una successione crescente di insiemi $E_n \uparrow E$, allora $\mu(E) = \lim_{n \to \infty} \mu(E_n) = \sup_{n} \mu(E_n)$.
	\item Se $E_n \uparrow E$ e $\mu (E_{\bar{n}}) < +\infty$ per qualche $\bar{n}$, allora $\mu(E) = \lim_{n \to + \infty} \mu(E_n) = \inf_{n} \mu(E_n)$.
	\item \textit{Subadditività}: Se $\bigcup E_n \supset E$, allora $\mu(E) \leq \sum_{n} \mu(E_n)$.
\end{itemize}

\textbf{Osservazione.} 
Dato $X' \in \mathcal A$ si possono restringere $\mathcal A$ e $\mu$ a $X'$ nel modo ovvio.

\textbf{Definizioni}.
\begin{itemize}
	\item $\mu$ si dice \textbf{completa} se $F \subset E, E \in \mathcal{A}$ e $\mu(E) = 0$, allora $F \in \mathcal{A}$ (e di conseguenza $\mu(F) = 0$).
	\item $\mu$ si dice \textbf{finita} se $\mu(X) < + \infty$.
	\item $\mu$ si dice \textbf{$\sigma$-finita} se esiste una successione $\{ E_n \}$ con $E_n \subset E_{n+1}$ tale che $\bigcup E_n = X$ con $\mu(E_n) < +\infty$ per ogni $n$.
\end{itemize}

\textbf{Notazione.}
Sia $P(X)$ un predicato che dipende da $x \in X$ allora si dice che \textbf{$P(X)$ vale $\mu$-quasi ogni $x \in X$} se l'insieme $\left\{ x \mid P(x) \text{ è falso}  \right\}$ è (contenuto in) un insieme di misura $\mu$ nulla.

D'ora in poi consideriamo solo misure complete.

\section{Esempi di misure}

\begin{itemize}
	
	\item \textbf{Misura che conta i punti.}
		$$
		X \text{ insieme}
		\qquad
		\mathcal A \coloneqq \mathcal P(X)
		\qquad
		\mu(E) \coloneqq \# E \in \N \cup \left\{ +\infty \right\}
		$$

	\item \textbf{Delta di Dirac in $x_0$.}
		$$
		X \text{ insieme, } x_0 \in X \text{ fissato}
		\qquad
		\mathcal A \coloneqq \mathcal P(X)
		\qquad
		\mu(E) \coloneqq \delta_{x_0}(E) = \One_E (x_0)
		$$

	\item \textbf{Misura di Lebesgue.}
		$$
		X = \R^n
		\qquad
		\mathcal{M}^n \text{ $\sigma$-algebra dei misurabili secondo Lebesgue}
		\qquad
		\mathscr L^n \text{ misura di Lebesgue}
		$$
		Dato $R$ parallelepipedo in $\R^n$, cioè $R = \prod_{k=1}^{n} I_k $ con $I_k$ intervalli in $\R$.
		Si pone
		$$
		\mathrm{vol}_n (R) \coloneqq \prod_{k=1}^{n}  \mathrm{lungh} (I_k)
		$$ 
		per ogni $E \subset \R^n$ (assumendo $\mathrm{lungh}([a, b]) = b - a$). Infine poniamo
		$$
		\mathscr L^n(E) \coloneqq \inf \left\{ \sum_{i} \mathrm{vol}_n (R_i) \mymid \left\{ R_i \right\} \text{tale che } E \subset \bigcup_i R_i  \right\}.
		$$
\end{itemize}
 
\textbf{Osservazioni.}
\begin{itemize}
	\item $\mathscr L^n(R) = \mathrm{vol}_n (R)$.
	\item $\mathscr L^n$ è così definita se $\mathcal{P}(\R^n)$ ma non è $\sigma$-addittiva.
	\item $\mathscr L^n$ è $\sigma$-addittiva su $\mathcal{M}^n$ (è per questo che bisogna introdurre $\mathcal{M}^n$).
\end{itemize}

Il terzo punto giustifica l'introduzione dei \textbf{misurabili secondo Lebesgue}. Dunque definiamo $\mathcal{M}^n$, dato $E \subset \R^n$ si dice che $E$ è misurabile (secondo Lebesgue) se
$$
\forall \epsilon > 0 \; \exists A \text{ aperto e } C \text{ chiuso con }
C \subset E \subset A 
\text{tali che}
\mathscr L^n (A \smallsetminus C) \leq \epsilon
$$

\textbf{Osservazioni.}
\begin{itemize}
	\item Per ogni $E$ misurabile vale
$$
	\mathscr L^n(E) = \inf \left\{ \mathscr L^n \colon A \ \text{aperto}, A \supset E \right\} = \sup \left\{ \mathscr L^n \colon K \ \text{compatto}, K \subset E \right\}.
$$
	\item Notiamo che se $F \subset E$ con $E \subset \mathcal{M}^n$ e $\mathscr L^n(E) = 0$, allora $F \in \mathcal{M}^n$. Ovvero la misura di Lebesgue è completa!
\end{itemize}

\textbf{Notazione.} $\left| E \right| \coloneqq \mathscr L^n (E)$

\section{Funzioni misurabili}

\textbf{Definizione.}
Dato $(X, \mathcal{A}, \mu)$ e $f \colon X \to \R$ (o al posto di $\R$ in $Y$ spazio topologico), diciamo che $f$ è \textbf{misurabile} (più precisamente $\mathcal{A}$-misurabile), se
$$
\forall A \text{ aperto} \; f^{-1} (A) \in \mathcal{A}
$$ 


\textbf{Osservazioni.}
\nopagebreak
\begin{itemize}
	\item Dato $E \subset X$, vale $E \in \mathcal{A}$ se solo se $\One_E$ è misurabile.
	\item La classe delle funzioni misurabili è chiusa rispetto a molte operazioni
	\begin{itemize}
		\item \textit{somma}, \textit{prodotto} (se hanno senso nello spazio immagine della funzione).
		\item \textit{Composizione con funzione continua}: Se $f \colon X \to Y$ continua e $g \colon  Y \to Y'$ continua, allora $g \circ f$ è misurabile.
		\item \textit{Convergenza puntuale}: data una successione di $f_n$ misurabili e $f_n \to f$ puntualmente, allora $f$ è misurabile.
		\item $\liminf$ e $\limsup$ (almeno nel caso $Y = \R$).
	\end{itemize}
\end{itemize}


\subsection{Funzioni semplici}

% Indico con $\mathcal{S}$ la classe delle funzioni $f \colon  X \to \R$ \textit{semplici}, cioè della forma $f = \sum_{i}^{n} \alpha_i \One_{E_i}$ con $\{E_i \}_{1 \leq i \leq n}$ misurabili e $\alpha_i \in \R$.
\textbf{Definizione.}
Definiamo la classe delle \textbf{funzione semplici} come
$$
\mathcal S := \left\{ f \colon X \to \R \mymid f = \sum_i \alpha_i \One_{E_i} \text{ con $E_i$ misurabili e $\{\alpha_i\}$ finito} \right\}
$$

\textbf{Osservazione.} La rappresentazione di una funzione semp/alice come combinazione lineare di indicatrici di insiemi \textit{non è unica}, però se necessario possiamo prendere gli $E_i$ disgiunti.

\section{Integrale}

\textbf{Definizione.}
Diamo la definizione di $\ds\int_X f \dd \mu$ per passi
\begin{enumerate}
	\item \label{item:def_int_1} 
		Se $f \in \mathcal{S}$ e $f \geq 0$ cioè $f = \sum_i \alpha_i \One_{E_i}$ con $\alpha_i \geq 0$ allora poniamo
$$
			\int\limits_{\mathclap{X}} f \dd \mu \coloneqq \sum_{i} \alpha_i \mu(E_i),
$$
		convenendo che $0 \cdot +\infty = 0$ in quanto la misura di un insieme non è necessariamente finita.
	
	\item \label{item:def_int_2} 
		Se $f \colon  X \to [0,+\infty]$ misurabile si pone
$$
			\int\limits_{\mathclap{X}} f \dd \mu \coloneqq \sup_{\substack{g \in \mathcal{S} \\ 0 \leq g \leq f}} \int\limits_{\mathclap{X}} g \dd \mu.
$$
		
	\item 
		$f \colon X \to \overline{\R}$ misurabile si dice \textbf{integrabile} se 
$$
			\int\limits_{\mathclap{X}} f^+ \dd \mu < + \infty \quad \text{oppure} \quad \int\limits_{\mathclap{X}} f^- \dd \mu < +\infty.
$$
		e per tali $f$ si pone
$$
			\int\limits_{\mathclap{X}} f \dd \mu \coloneqq  \int\limits_{\mathclap{X}} f^+ \dd \mu - \int\limits_{\mathclap{X}} f^- \dd \mu.
$$
	
	\item 
		$f \colon X \to \R^n$ si dice \textbf{sommabile} (o di \textbf{classe} $\mathscr L^1$) se $\int_X \left| f \right| \dd \mu < +\infty$. In tal caso, se $\int_X f_i^{\pm} \dd \mu < +\infty$ per ogni $f_i$ componente di $f$, allora $\int_X f \dd \mu$ esiste ed è finito.
\end{enumerate}

Per tali $f$ si pone
$$
	\int\limits_{\mathclap{X}} f \dd \mu \coloneqq  \left( \int_X f_1 \dd \mu, \ldots , \int_X f_n \dd \mu \right).
$$

\textbf{Notazione.}
Scriveremo spesso $\int_E f(x) \dd x$ invece di $\int_E f \dd \mathscr L^n$ .

\textbf{Osservazioni.}
\begin{itemize}
	\item L'integrale è lineare (sulle funzioni sommabili).
	
	\item I passaggi \ref{item:def_int_1} e \ref{item:def_int_2} danno lo stesso risultato per $f$ semplice $\geq 0$.
	
	\item La definizione in \ref{item:def_int_2} ha senso per ogni $f \colon X \to [0,+\infty]$ anche non misurabile. Ma in generale vale solo che
		$$
		\int\limits_{\mathclap{X}} f_1 + f_2 \dd \mu \geq \int_X f_1 \dd \mu + \int_X f_2 \dd \mu.
		$$
	
	\item Dato $E \in \mathcal{A}$, $f$ misurabile su $E$, notiamo che vale l'uguaglianza
		$$
		\int_E f \dd \mu \coloneqq \int_X f \cdot \One_E \dd \mu.
		$$ 
	
	\item Si può definire l'integrale anche per $f \colon X \to Y$ con $Y$ \textit{spazio vettoriale normato finito dimensionale}\footnote{È necessario avere uno spazio vettoriale, perché serve la linearità e la moltiplicazione per scalare} ed $f$ sommabile.
	
	\item Se $f_1 = f_2$ $\mu$-q.o. allora $\ds \int_X f_1 \dd \mu = \int_X f_2 \dd \mu$.
	
	\item Si definisce $\ds \int_X f \dd \mu$ anche se  $f$ è misurabile e definita su $X \setminus N$ con $\mu(N) = 0$.
	
	\item Se $f \colon [a,b] \to \R$ è integrabile secondo Riemann allora è misurabile secondo Lebesgue e le due nozioni di integrale coincidono. 
		
		\textbf{Nota.} Lo stesso vale per integrali impropri di funzioni positive. Ma nel caso più generale non vale: se consideriamo la funzione
		$$
		f \colon (0,+\infty) \to \R 
		\qquad
		f(x) \coloneqq \dfrac{\sin x}{x}
		$$
		allora l'integrale di $f$ definito su $(0,+\infty)$ esiste come integrale improprio ma non secondo Lebesgue, infatti
		$$
		\int_0^{+\infty} f^+ \dd x = \int_0^{+\infty} f^- \dd x = +\infty
		$$
	
	\item $\ds \int_X f \dd \delta_{x_0} = f(x_0)$
	
	\item Se $X = \N$ e $\mu$ è la misura che conta i punti l'integrale è 
		$$
		\int_X f \dd \mu = \sum_{n = 0}^{\infty} f(n) 
		$$ 
		per le $f$ positive o tali che $\sum f^+(n) < +\infty $ oppure $\sum f^-(n) < +\infty $.
		
		\textbf{Nota.} Come prima nel caso di funzioni non sempre positive ci sono casi in cui la serie solita non è definita come integrale di una misura, ad esempio
		$$
		\sum_{n=1}^{\infty} \frac{(-1)^n}{n}
		$$
		esiste come serie ma non come integrale.
		
	\item Dato $X$ qualunque, $\mu$ misura che conta i punti e $f \colon  X \to [0,+\infty] $ possiamo definire la somma di tutti i valori di $f$ 
		$$
		\sum_{x \in X} f(x) \coloneqq \int\limits_{\mathclap{X}} f \dd \mu.  
		$$ 
\end{itemize}

\section{Teoremi di convergenza}

Sia $(X, \mathcal{A}, \mu)$ come in precedenza.

\textbf{Teorema.}
\textit{di convergenza monotona o Beppo-Levi.}
Date $f_n \colon  X \to [0,+\infty]$ misurabili, tali che $f_n \uparrow f$ ovunque in $X$, allora
$$
\lim_{n \to +\infty} \int\limits_{\mathclap{X}} f_n \dd \mu = \int\limits_X f \dd \mu,
$$
dove
$$
\lim_{n \to +\infty} \int\limits_{\mathclap{X}} f_n \dd \mu = \sup_n \int f_n \dd \mu.
$$


\textbf{Teorema.}
\textit{detto lemma di Fatou.}
Date $f_n \colon X \to [0,+\infty]$ misurabili, allora
$$
\liminf_{n \to +\infty} \int\limits_X f \dd \mu \geq \int\limits_{\mathclap{X}} \left( \liminf_{n \to +\infty} f_n \right) \dd \mu.
$$ 

\textbf{Teorema.}
\textit{di convergenza dominata o di Lebesgue.}
Date $f_n \colon  X \to \R$ (o anche $\R^n$) con le seguenti proprietà
\begin{itemize}
	\item \textit{Convergenza puntuale:} $f_n (x) \to f(x)$ per ogni $x \in X$.
	\item \textit{Dominazione:} Esiste $g \colon X \to [0,+\infty]$ sommabile tale che $\left| f_n (x) \right| \leq g(x)$ per ogni $x \in X$ e per ogni $n \in \N$.
\end{itemize}
allora
$$
\lim_{n \to \infty} \int\limits_{\mathclap{X}} f_n \dd \mu = \int\limits_X f \dd \mu. 
$$ 

\textbf{Nota.}
La seconda proprietà è essenziale; sostituirla con $\ds \int_X \left| f_n \right| \dd \mu \leq C < + \infty$ non basta!

\textbf{Definizione.}
Data una ``densità'' $\rho \colon  \R^n \to [0,+\infty]$ misurabile, la \textbf{misura $\mu$ con densità $\rho$} è data da
$$
\forall E \in \mathcal A \quad \mu(E) \coloneqq \int\limits_{\mathclap{E}} \rho \dd x
$$ 

\textbf{Osservazioni.}
\begin{itemize}
	\item $\R^n$ e $\mathscr L^n$ possono essere sostituiti da $X$ e $\widetilde{\mu}$.
	\item il fatto che $\mu$ è una misura segue da Beppo Levi, in particolare serve per mostrare la subadditività.
\end{itemize}


\textbf{Teorema.}
\textit{di cambio di variabile.}
Siano $\Omega$ e $\Omega'$ aperti di $\R^n$, $\Phi \colon \Omega \to \Omega' $ un diffeomorfismo di classe $C^1$ e $f \colon \Omega' \to [0,+\infty]$ misurabile. Allora
$$
\int\limits_{\mathclap{\Omega'}} f(x') \dd x' = \int\limits_{\mathclap{\Omega}} f(\Phi(x)) \left| \det(\nabla \Phi(x)) \right| \dd x.
$$

La stessa formula vale per $f$ a valori in $\overline{\R}$ integrabile e per $f$ a valori in $\R^n$ sommabile.

\textbf{Osservazioni.}
\begin{itemize}
	\item Se $n = 1$, $\left| \det(\nabla \Phi(x)) \right| = \left| \Phi'(x) \right|$ e non $\Phi'(x)$ come nella formula vista ad Analisi 1 (l'informazione del segno viene data dall'inversione degli estremi).
	
	\item Indebolire le ipotesi su $\Phi$ è delicato. Basta $\Phi$ di classe $C^1$ e $\foralmostall x' \in \Omega' \; \# \Phi^{-1}(x') = 1$ (supponendo $\Phi$ iniettiva la proprietà precedente segue immediatamente).
	Se $\Phi$ non è "quasi" iniettiva bisogna correggere la formula per tenere conto della molteplicità.

	\item Quest'ultima osservazione serve giusto per far funzionare il cambio in coordinate polari che non è iniettivo solo nell'origine.
\end{itemize}

\subsection{Fubini-Tonelli}

Di seguito riportiamo il teorema di Fubini-Tonelli per la misura di Lebesgue.

\textbf{Teorema.}
\textit{Fubini-Tonelli.}
Sia $\R^{n_1} \times \R^{n_2} \simeq \R^n$ con $n = n_1 + n_2$, $ E \coloneqq E_1 \times E_2 $ dove $E_1, E_2$ sono misurabili e $f$ è una funzione misurabile definita su $E$.
Se $f$ ha valori in $[0,+\infty]$ allora
$$
\int\limits_X f \dd \mu 
= \int\limits_{\mathclap{E_2}} \int\limits_{\mathclap{E_1}} f(x_1,x_2) \dd x_1 \dd x_2 
= \int\limits_{\mathclap{E_1}} \int\limits_{\mathclap{E_2}} f(x_1,x_2) \dd x_2 \dd x_1
$$ 

Vale lo stesso per $f$ a valori in $\R$ o in $\R^n$ sommabile.

\textbf{Osservazioni.}
Possiamo generalizzare il teorema di Fubini-Tonelli a misure generiche ed ottenere alcuni risultati utili che useremo ogni tanto.
\begin{itemize}
	\item Se $X_1, X_2$ sono spazi con misure $\mu_1,\mu_2$ (con opportune ipotesi) vale:
		$$
		\int\limits_{\mathclap{E_2}} \int\limits_{\mathclap{E_1}} f(x_1,x_2) \dd \mu_1(x_1)  \dd \mu_2(x_2) 
		= \int\limits_{\mathclap{E_1}} \int\limits_{\mathclap{E_2}} f(x_1,x_2) \dd \mu_2(x_2)  \dd \mu_1(x_1).
		$$ 
		se $f\geq 0$ oppure $\ds \int\limits_{\mathclap{X_1}} \int\limits_{\mathclap{x_2}} \left| f \right| \dd \mu_2(x_2)  \dd \mu_1(x_1) < + \infty $.
	
	\item \textit{Teorema di scambio serie-integrale:} Se $X_1 \subset \R$ (oppure $X_1 \subset \R^n$), $\mu_1 = \mathscr L^n$ e $X_2 = \N$, $\mu_2$ è la misura che conta i punti, allora la formula sopra diventa
		$$
		\sum_{n=0}^{\infty} \, \int\limits_{\mathclap{X_1}} f_n(x) \dd x  
		= \int\limits_{\mathclap{X_1}} \sum_{n=0}^{\infty} f_n(x)  \dd x.
		$$ 
		se $f_i \geq 0$ oppure $\ds \sum_{i} \int\limits_{\mathclap{X_1}} \left| f_i(x) \right| \dd x  < + \infty $.
	
	\item \textit{Teorema di scambio di serie:} Se $X_1 = X_2 = \N$ e $\mu_1 = \mu_2$ è la misura che conta i punti la formula sopra diventa
		$$
		\sum_{j=0}^{\infty} \sum_{i=0}^{\infty} a_{i,j}  
		= \sum_{i=0}^{\infty} \sum_{j=0}^{\infty} a_{i,j} 
		$$ 
		se $a_{i,j} \geq 0$ oppure $\ds \sum_{i} \sum_{j} \left| a_{i,j} \right| < +\infty $.
\end{itemize}

\chapter{Spazi $L^p$ e convoluzione}

\section{Disuguaglianze}

\subsection{Disuguaglianza di Jensen}

Ricordiamo che una funzione $f \colon \R^d \to [-\infty, +\infty]$ è \textbf{convessa} se e solo se dati $x_1, \dots, x_n \in \R^d$ e $\lambda_1, \dots, \lambda_n \in [0, 1]$ con $\sum_i \lambda_i = 1$ abbiamo che
$$
f \left(\sum_i \lambda_i x_i \right) \leq \sum_i \lambda_i f(x_i)
$$

\textbf{Teorema} (Jensen),
Dato $(X, \mathcal A, \mu)$ con $\mu(X) = 1$ e $f \colon \R^d \to [-\infty, +\infty]$ convessa e semi-continua inferiormente (S.C.I.) e $u \colon X \to \R^d$ sommabile allora vale
$$
\int_X f \compose u \dd \mu \geq f \left( \int_X u \dd \mu \right)
$$
e $f \compose u$ è integrabile.

\textbf{Osservazioni.}
\begin{itemize}
	\item $(f \compose u)^-$ ha integrale finito.

	\item Interpretando $\mu$ come probabilità si riscrive come $\mathbb E[f \compose \mu] \geq f(\mathbb[u])$.

	\item Se $u$ è una funzione semplice, cioè $u = \sum_i y_i \cdot \One_{E_i}$ con $E_i$ disgiunti e $\bigcup E_i = X$ allora posti $\lambda_i = \mu(E_i)$ abbiamo
		$$
		\int_X f \compose u \dd \mu = \int_X \sum_i f(y_i) \cdot \One_{E_i} \dd \mu = \sum_i \lambda_i f(y_i) \geq f \left( \sum_i \lambda_i y_i \right) = f \left( \int_X u \dd \mu \right)
		$$

		Questo ci darebbe una strada per dimostrare in generale per passi il teorema di Jensen ma in realtà si presentano vari problemi tecnici.

	\item Ogni funzione convessa e S.C.I su $\Omega$ convesso in $\R^d$ si estende a $\tilde f \colon \R \to (-\infty, +\infty]$ convessa e S.C.I., ad esempio se $\Omega = (0, +\infty)$
		$$
		f(y) = \frac{1}{y}
		\quad\rightsquigarrow\quad
		\tilde f(y) = 
		\begin{cases}
$$
			\dfrac{1}{y} & y > 0
		\end{cases}
		$$

	\item La semi-continuità inferiore serve perché le funzioni convesse sono continue solo se a valori in $\R$, ad esempio per $k$ costante la funzione
		$$
		f(y) := 
		\begin{cases}
			k & y < 0 \\
			+\infty & y \geq 0
		\end{cases}
		$$
		è convessa ma non semi-continua inferiormente (e neanche continua).
\end{itemize}

\textbf{Dimostrazione.}
Poniamo $y_0 \coloneqq \int_X u \dd \mu$, allora la tesi diventa
$$
\int_X f \compose u \dd \mu \geq f(y_0)
$$
Prendiamo $\phi \colon \R^d \to \R$ affine (ovvero $\phi(y) = a \cdot y + b$ con $a \in \R^d$ e $b \in \R$) tale che $\phi \leq f$, allora
$$
\int_X f \compose u \dd \mu \geq \int_X \phi \compose u \dd \mu = \int_X a \cdot u + b \dd \mu = a y_0 + b = \phi(y_0)
$$

Infine concludiamo usando il seguente lemma di caratterizzazione delle funzioni convesse ed S.C.I.

\textbf{Lemma.}
Ogni $f \colon \R^d \to (-\infty, +\infty]$ convessa e S.C.I è tale che
$$
\forall y_0 \in \R^d \quad \sup_{\substack{\phi \text{ affine} \\ \phi \leq f}} \phi(y_0) = f(y_0)
$$

Nel caso $d = 1$ e $f \colon \R \to \R$ possiamo appoggiarci al fatto che le funzioni convesse sono ammettono sempre derivata destra o sinistra, il $\sup$ diventa un massimo e ci basta prendere come $\phi$ la retta tangente in $(y_0, f(y_0))$ o una con pendenza compresa tra $f'(y_0^-)$ e $f'(y_0^+)$.

Rileggendo meglio la dimostrazione segue che $(f \compose u)^- < (\phi \compose u)^- \implies (f \compose u)^-$. 

\qed

\textbf{Definizione.} Dati $p_1, p_2 \in [1, +\infty]$ diciamo che sono \textbf{coniugati} se
$$
\frac{1}{p_1} + \frac{1}{p_2} = 1
$$
convenendo che $\sfrac{1}{\infty} = 0$.

Fissiamo $p \in [1, +\infty]$ detto ``esponente di sommabilità'' e sia $(X, \mathcal A, \mu)$ come sempre.

\textbf{Definizione.} $f \colon X \to \overline \R$ o $\R^d$ misurabile, allora la \textbf{norma $p$ di $f$} è per $p \in [1, +\infty)$
$$
\norm{f}_p \coloneqq \left( \int_X |f|^p \dd \mu \right)^p
$$
mentre per $p = +\infty$ poniamo
$$
\norm{f}_\infty \coloneqq \inf \{ m \in [0, +\infty] \mid |f(x)| \leq m \text{ per $\mu$-q.o. } x \}
$$
in realtà queste sono solo delle semi-norme\footnote{Vedremo meglio più avanti questo dettaglio}.

\begin{itemize}
	\item $\ds \norm{f}_\infty \leq \sup_{x \in X} |f(x)|$

	\item $\norm{f}_p = 0 \iff f = 0$ quasi ovunque

		\textbf{Dimostrazione.}
		\begin{itemize}
			\item[$\boxed{\Rightarrow}$] [TODO: Facile ma non ovvia]
			\item[$\boxed{\Leftarrow}$] Ovvio.
		\end{itemize}
		\qed

	\item Se $f_1 = f_2$ quasi ovunque $\implies \norm{f_1}_p = \norm{f_2}_p$.

		\textbf{Dimostrazione.} 
		$f_1 = f_2$ quasi ovunque $\implies \exists D \subset X$ con $\mu(D) = 0$ tale che $f_1(x) = f_2(x)$ su $X \setminus D$, usiamo il fatto che l'integrale non cambia se modifichiamo la funzione su un insieme di misura nulla
		$$
		\norm{f_1}_p^p
		= \int_X |f_1|^p \dd \mu 
		= \int_{X \setminus D} |f_1|^p \dd \mu 
		= \int_{X \setminus D} |f_2|^p \dd \mu 
		= \int_{X} |f_2|^p \dd \mu 
		= \norm{f_2}_p^p
		$$ 
		\qed
\end{itemize}

\subsection{Disuguaglianza di Young}

\textbf{Proposizione.}
Per ogni $a_1, a_2 \geq 0$ e $\lambda_1, \lambda_2 > 0$ con $\lambda_1 + \lambda_2 > 0$ abbiamo che
$$
a_1^{\lambda_1} a_2^{\lambda_2} \leq \lambda_1 a_1 + \lambda_2 a_2
$$
inoltre vale l'uguale se e solo se $a_1 = a_2$.

\textbf{Dimostrazione.}
Se $a_1 = a_2 = 0$ allora è ovvia. Supponiamo dunque $a_1, a_2 > 0$, ma sappiamo che 
% e passiamo $a_1^{\lambda_1} a_2^{\lambda_2}$ al logaritmo
$$
\lambda_1 \log a_1 + \lambda_2 \log a_2 \leq \log(\lambda_1 a_2 + \lambda_2 a_2)
$$
per concavità del logaritmo e quindi segue la tesi.

Il se e solo se per l'uguale segue dal fatto che il logaritmo è \textit{strettamente concavo}. 
\qed

\subsection{Disuguaglianza di H\"older}

\textbf{Proposizione.}
Date $f_1, f_2 \colon X \to \overline\R$ o $\R^d$ e $p_1, p_2$ esponenti coniugati allora
$$
\int_X |f_1| \cdot |f_2| \dd \mu \leq \norm{f_1}_{p_1} \cdot \norm{f_2}_{p_2}
$$ 
vale anche per $p = +\infty$ convenendo che $+\infty \cdot 0 = 0$ a destra dell'uguale.

\textbf{Dimostrazione.}
Se $\norm{f_1}_{p_1} = 0$ o $+\infty$ e anche $\norm{f_2}_{p_2} = 0$ o $+\infty$ la dimostrazione è immediata, supponiamo dunque $\norm{f_1}_{p_1}, \norm{f_2}_{p_2} > 0$ e finiti.

\begin{itemize}
	\item \textit{Caso 1:} se $p_1 = 1, p_2 = +\infty$ allora
		$$
		\int_X |f_1| \cdot |f_2| \dd \mu 
		\leq \int_X |f_1| \cdot \norm{f_2}_{\infty} \dd \mu
		= \norm{f_2}_{\infty} \cdot \int_X |f_1| \dd \mu
		= \norm{f_2}_{\infty} \cdot \norm{f_1}_{1} 
		$$

	\item \textit{Caso 2:} se $1 < p_1, p_2 < +\infty$, introduciamo un parametro $\gamma > 0$ allora
		$$
		\int_X |f_1| \cdot |f_2| \dd \mu 
		= \int_X \left( \gamma^{p_1} \cdot |f_1|^{p_1} \right)^{1/p_1} \cdot \left( \gamma^{-p_2} \cdot |f_1|^{p_2} \right)^{1/p_2} \dd \mu
		$$
		a questo punto chiamiamo per comodità $g_1 := \gamma^{p_1} \cdot |f_1|^{p_1}$, $\lambda_1 := 1 / p_1$ e $g_2 := \gamma^{-p_2} \cdot |f_1|^{p_2}$, $\lambda_2 := 1 / p_2$ da cui
		$$
		= \int_X g_1^{\lambda_1} \cdot g_2^{\lambda_2} 
		\overset{\text{Young}}{\leq} \int_X \lambda_1 g_1 + \lambda_2 g_2 \dd \mu
		= \lambda_1 \gamma^{p_1} \int_X |f_1|^{p_1} + \lambda_2 \gamma^{-p_2} \int_X |f_1|^{p_2} \dd \mu
		$$
		$$
		= \lambda_1 \gamma^{p_1} \cdot \norm{f_1}_{p_1}^{p_1} + \lambda_2 \gamma^{-p_2} \cdot \norm{f_1}_{p_2}^{p_2}
		$$
		posti ora $a_1 := \gamma^{p_1} \norm{f_1}_{p_1}^{p_1}$ e $a_2 := \gamma^{-p_2} \norm{f_1}_{p_2}^{p_2}$, per $\gamma \to 0$ abbiamo che $a_1 \to 0, a_2 \to +\infty$ mentre per $\gamma \to +\infty$ abbiamo che $a_1 \to +\infty, a_2 \to 0$ dunque per il teorema del valor medio esisterà $\gamma$ tale che $a_1 = a_2$, ma allora siamo nel caso dell'uguaglianza per la disuguaglianza di Young dunque
		$$
		\lambda_1 \gamma^{p_1} \norm{f_1}_{p_1}^{p_1} + \lambda_2 \gamma^{-p_2} \norm{f_1}_{p_2}^{p_2} 
		= \lambda_1 a_1 + \lambda_2 a_2 = a_1^{\lambda_1} \cdot a_2^{\lambda_2} 
		= \norm{f_1}_{p_1} \cdot \norm{f_2}_{p_2}
		$$
\end{itemize}
In particolare, vale l'uguaglianza se prendiamo un valore di $\gamma$ tale che $a_1 = a_2$. Resta da verificare che tale valore di $\gamma$ esista [TODO].
\qed

\textbf{Osservazione.}
La disuguaglianza di H\"older può essere generalizzata a $n$ funzioni, date $f_1, \dots, f_n$ e $p_1, \dots, p_n$ con $\frac{1}{p_1} + \dots + \frac{1}{p_2} = 1$ allora
$$
\int_X \prod_i |f_i| \dd \mu \leq \prod_i \norm{f_i}_{p_i} 
$$

\subsection{Disuguaglianza di Minkowski}

\textbf{Proposizione.} 
Consideriamo sempre $(X, \mathcal A, \mu)$ e sia $p \in [1, +\infty]$ un esponente di sommabilità ed $f_1, f_2 \colon X \to \R$ oppure $\R^d$ allora vale la disuguaglianza triangolare
$$
\norm{f_1 + f_2}_p \leq \norm{f_1}_p + \norm{f_2}_p
$$
%
\textbf{Dimostrazione.}
\begin{itemize}
	\item \textit{Caso 1:} se $p = 1$ o $p = +\infty$, allora basta fare il calcolo diretto
		
		\begin{itemize}
			\item Se $p = 1$
				$$
				\norm{f_1 + f_2}_1 
				= \int_X |f_1 + f_2| \dd \mu 
				\leq \int_X |f_1| + |f_2| \dd \mu 
				= \int_X |f_1| \dd \mu + \int_X |f_2| \dd \mu
				= \norm{f_1}_1 + \norm{f_2}_1
				$$
			\item Se $p = +\infty$
				$$
				\norm{f_1 + f_2}_\infty
				= \mathrm{supess}_X |f_1 + f_2| 
				= \mathrm{supess}_{X \setminus D} 
				\leq \mathrm{supess}_{X \setminus D} (|f_1| + |f_2|)
				$$
				$$
				= \mathrm{supess}_{X \setminus D} |f_1| + \mathrm{supess}_{X \setminus D} |f_2|
				= \mathrm{supess}_X |f_1| + \mathrm{supess}_X |f_2|
				= \norm{f_1}_\infty + \norm{f_2}_\infty
				$$
		\end{itemize}

	\item \textit{Caso 2:} se $1 < p < +\infty$ e $0 < \norm{f_1 + f_2}_p < +\infty$
		$$
		\begin{aligned}
			\norm{f_1 + f_2}_p^p 
			&= \int_X |f_1 + f_2|^p 
			\leq \int_X (|f_1| + |f_2|) \cdot |f_1 + f_2|^{p-1} \dd \mu = \\
			&= \int_X |f_1| \cdot |f_1 + f_2|^{p-1} \dd \mu + \int_X |f_2| \cdot |f_1 + f_2|^{p-1} \dd \mu = \\
			&\overset{\text{H\"older}}{\leq} \norm{f_1}_p \cdot \norm{|f_1 + f_2|^{p-1}}_q + \norm{f_2}_p \cdot \norm{|f_1 + f_2|^{p-1}}_q = \\
			& = (\norm{f_1}_p + \norm{f_2}_p) \cdot \norm{|f_1 + f_2|^{p-1}}_q 
			= (\norm{f_1}_p + \norm{f_2}_p) \cdot \norm{f_1 + f_2}_p^{p-1}  \\
		\end{aligned}
		$$
		e poiché $\norm{f_1 + f_2}_p > 0$ possiamo portare l'ultimo fattore dall'altra parte
		$$
		\implies \frac{\norm{f_1 + f_2}_p^p }{\norm{f_1 + f_2}_p^{p-1}} \leq \norm{f_1}_p + \norm{f_2}_p
		\implies \norm{f_1 + f_2}_p \leq \norm{f_1}_p + \norm{f_2}_p
		$$

	\item \textit{Caso 3:} se $1 < p < +\infty$ ma $\norm{f_1 + f_2} = 0$ o $+\infty$ allora se $\norm{f_1 + f_2} = 0$ la disuguaglianza è banale mentre se $\norm{f_1 + f_2} = +\infty$ si usa la seguente disuguaglianza
		$$
		\norm{f_1 + f_2}_p^p \leq 2^{p-1} (\norm{f_1}_p^p + \norm{f_2}_p^p)
		$$
		che si ottiene usando la convessità della funzione $y \mapsto y^p$
		$$
		\norm{f_1 + f_2}_p^p 
		= \int_X |f_1 + f_2|^p \dd \mu 
		= 2^p \int_X \left| \frac{f_1 + f_2}{2} \right|^p \dd \mu 
		$$
		$$
		\leq 2^p \int_X \frac{1}{2} |f_1|^p + \frac{1}{2}|f_2|^p \dd \mu 
		= 2^{p-1} (\norm{f_1}_p^p + \norm{f_2}_p^p)
		$$
		da cui possiamo ricavare subito che almeno uno dei due termini deve essere $+\infty$.

\end{itemize}

% lezione del 4 ottobre 2021
\section{Esercitazione del 4 ottobre}

\subsection*{Teoria della misura}

Di seguito riportiamo alcune proprietà di base di teoria della misura.

\textbf{Proprietà.}

\begin{enumerate}
\item Se $A \subset B$, allora $\mu(A) \leq \mu(B)$.

\textbf{Dimostrazione.}
Scomponiamo $B = (B \setminus A) \cup (A \cap B)$. Per ipotesi $A \cap B = A$ ed essendo la misura positiva segue che
$$
	\mu(B) = \underbrace{\mu(B \setminus A)}_{\geq 0} + \mu(A) \geq \mu(A).
$$

\item \label{item:misura_unione_finita} Dati due insiemi $A,B$ misurabili, vale
$$
	\mu(A \cup B) \leq \mu(A) + \mu(B).
$$

\textbf{Dimostrazione.}
La disuguaglianza segue dalle seguenti uguaglianze.

\begin{align*}
	\mu(A) & = \mu(A \setminus B) + \mu(A \cap B) \\
	\mu(B) & = \mu(B \setminus A) + \mu(A \cap B) \\
	\mu(A \cup B) & = \mu(A \setminus B ) + \mu(B \setminus A) + \mu(A \cap B).
\end{align*}

\item Data una successione di insiemi $E_1 \subset E_2 \subset \cdots \subset \cdots$, si ha
$$
	\mu \left( \bigcup_{i} E_i \right) = \sup_i \mu(E_i) = \lim_i \mu (E_i).
$$

\item Data una successione di insiemi $E_1 \supset E_2 \supset \cdots \supset \cdots$ e $\mu(E_1) < +\infty$, si ha
$$
	\mu \left( \bigcap_{i} E_i \right) = \lim_i \mu (E_i).
$$
\end{enumerate}

\textbf{Esercizio} (Numerabile subaddittività).
Dato $\ds E \in \mathcal{A}, E \subset \bigcup_i E_i$ dove $E_i \in \mathcal{A}$. Allora
$$
	\mu(E) \leq \sum_{i}^{} \mu(E_i).
$$

\textbf{Dimostrazione} (\textit{Idea}).
Basta dimostrare che $\ds \mu \left( \bigcup_i E_i \right) \leq \sum_{i}^{} \mu(E_i)$. Infatti per quanto visto prima $\ds \mu(E) \leq \mu \left( \bigcup_i E_i \right)$. Prima dimostriamo per induzione $\ds \mu \left( \bigcup_{i = 1}^N E_i \right) \leq \sum_{i=1}^{N} \mu(E_i)$. 

Il passo base $n = 2$ è stato visto al punto \ref{item:misura_unione_finita}. Una volta dimostrata la proprietà sopra, si nota che $\ds \sum_{i=1}^{N} \mu(E_i) $ è limitata per ogni $N$, e dunque è limitato anche il suo limite, da cui la tesi.
\qed

\subsection*{Funzioni misurabili rispetto alla misura di Lebesgue}

Si ricorda che le funzioni \textit{continue}, \textit{semplici} e \textit{semicontinue} sono classi di funzioni misurabili.
Due osservazioni sulle funzioni semicontinue.
\begin{itemize}
\item Le funzioni semicontinue sono \textit{boreliane}.

\item La proprietà di misurabilità delle funzioni semicontinue è necessaria per l'enunciato della disuguaglianza di Jensen.
\end{itemize}

\textbf{Controesempio} (\textit{Disuguaglianza di Jensen}).
Notiamo che l'ipotesi di semicontinuità inferiore della funzione $f$ è necessaria per la validità della disuguaglianza di Jensen.
Infatti, definiamo $f$ come segue
%
$$
f(x) = 
\begin{cases}
0 \qquad \; x \in (0,1) \\
+ \infty \quad \text{altrimenti} 
\end{cases}.
$$
%
Osserviamo che la funzione $f$ così definita è convessa ma non semicontinua inferiormente.

Ora definiamo la funzione $u : X \to \R$ con $X = (0,2)$, come la funzione costante di valore $1/2$.
Calcoliamo l'integrale di $u(x)$ su $X$.
%
$$
	\int\limits_{\mathclap{X}} u(x) \dd x = 1. 
$$
%
In tal caso vale $\ds f \left( \int_X u(x) \dd x \right) = + \infty$.
D'altra parte $\ds \int_X f \compose u \dd x = 0$, dunque l'ipotesi di semicontinuità inferiore è necessaria.

\textbf{Fatto.}
Date $\myphi_1, \myphi_2$ funzioni semplici su $\R$ con misura di Lebesgue.
Allora $\myphi_1 \vee \myphi_2$ e $\myphi_1 \wedge \myphi_2$ sono ancora funzioni semplici.

\textbf{Lemma.}
Data $f \colon X \to [0, +\infty]$ misurabile
$$
\int_X f \dd \mu = 0 \quad \longiff \quad f = 0 \; \text{q.o. su } X.
$$

\textbf{Dimostrazione.}
\begin{itemize}

\item[$\boxed{\Rightarrow}$] Dato che $f$ è non negativa, il dominio $X$ può essere riscritto come
$$
	X = \left\{ x \in X \mymid f(x) \geq 0 \right\} = \left\{ x \in X \mymid f(x) > 0 \right\} \cup \left\{ x \in X \mymid f(x) = 0 \right\}
$$
ricordiamo che $(0, +\infty) = \bigcup_{n \geq 1} (\frac{1}{n}, +\infty)$ da cui segue
$$
	\left\{ x \in X \mymid f(x) > 0 \right\} =  \bigcup_{n \in \N \setminus \left\{ 0 \right\}} \left\{ x \in X \mymid f(x) \geq \frac{1}{n} \right\},
$$
e passiamo alle misure
$$
	\mu \left( \left\{ x \in X \mymid f(x) > 0 \right\} \right) 
	= \lim_{n \to +\infty} \mu\left(\left\{ x \in X \mymid f(x) \geq \frac{1}{n} \right\}\right),
$$
in questo modo otteniamo la seguente caratterizzazione dell'insieme su cui $f$ è positiva
$$
	\mu \left( \left\{ x \in X \mymid f(x) > 0 \right\} \right) >0 
	\longiff
	\exists \bar{n} \mid \mu \left( \left\{ x \in X \mymid f(x) \geq 1 / \bar{n} \right\} \right) > 0.
$$

% X @aziis98: Boh magari potremmo definire tipo L_n := { blob sotto l'integrale } per rendere un po' più leggibile quel dominio di integrazione.
% OK @aziis98: Oppure anche in notazione "probabilistica" $\{ f \geq \frac{1}{n} \}$ che è più corto
Allora possiamo maggiorare come segue
$$
	0 = \int_X f \dd \mu 
	\geq \;\int\limits_{\mathclap{\left\{ f \,\geq\, \frac{1}{n} \right\}}} \; f \dd \mu \geq	\frac{1}{n} \mu \left(  \left\{ x \mymid f(x) \geq \frac{1}{n} \right\} \right). 
$$
Dunque abbiamo
$$
	\mu \left(  \left\{ x \mymid f(x) \geq \frac{1}{n} \right\} \right) = 0 \qquad \forall n.
$$
Si conclude osservando che
$$
	\mu \left(  \left\{ x \mymid f(x) > 0 \right\} \right) = \lim_n \mu \left( \left\{ x \mymid f(x) \geq \frac{1}{n} \right\} \right) = 0.
$$

\item[$\boxed{\Leftarrow}$]
Dal fatto che $f$ è positiva possiamo scrivere
$$
	\int_X f \dd \mu = \sup_{\substack{g \leq f \\ g \; \text{semplice}}} \int_X g \dd \mu = \sup \sum_{i}^{} \alpha_i \mu(E_i) = 0. 
$$
\qed

\end{itemize}

\textbf{Osservazione.} (sup essenziale di funzioni misurabili).
Data $f$ misurabile, definiamo
$$
	\norm{ f }_{\infty, X} \coloneqq \inf \left\{ m \in [0,+\infty] \mymid \left| f(x) \right| \leq m \quad \text{quasi ovunque}  \right\}.
$$

Se $\norm{ f }_{\infty} < + \infty$, allora diciamo che esiste una costante $L > 0$ con $L = \norm{ f }_{\infty, X}$, tale che 
$$
	\left| f(x) \right| \leq L
$$
quasi ovunque. 
Infatti, per definizione di $\inf$, $L = \lim_n m_n$, dove $m_n$ verificano
$$
	\left| f(x) \right| \leq m_n \quad \forall x \in X \setminus N_m, \quad \mu(N_m) = 0.
$$
Definiamo $N = \bigcup_{m} N_m$, da cui si ottiene
$$
	\mu(N) \leq \sum_{n=1}^{\infty} \mu (N_m) = 0. 
$$
Ovvero $N$ è trascurabile.
Preso $x \in X \setminus N$, vale
$$
	\left| f(x) \right| \leq m_n \quad \forall n \in \N.
$$


\subsection*{Formula di cambio di variabile applicata a funzioni radiali}

Sia $f \colon [0,+\infty) \to \R$ misurabile (di solito si richiede misurabile e positiva oppure sommabile).
Vala la seguente
$$
	\int\limits_{\mathclap{0}}^{+\infty} f\left( \left| x \right| \right) \dd x = c_n \cdot \int\limits_{\mathclap{0}}^{+\infty} f(\rho) \rho^{n-1} \dd \rho,
$$
dove $\ds c_n = n \mathscr L^n \left( \mathcal{B}(0,1) \right)$.

Applichiamo questa formula alla stima di integrali di funzioni positive.

\textbf{Esercizio.}
Sia
$$
	\psi (x) = \frac{1}{\norm{ x }^{\alpha}}
$$
% X @aziis98: Boh secondo me possiamo usare anche solo B(0, 1) invece di \mathcal B(0, 1), sempre sul tema di fare con \mathcal solo l'insieme delle parti e le sigma-algebre?
su $\mathcal{B}(0,1) \in \R^n$. Notiamo che $\psi(x) = f(\norm{ x })$ con $f = 1 / t^\alpha$.
Usiamo la formula appena introdotta per determinare gli $\alpha \in \R$ per i quali $\psi$ è sommabile su $\mathcal{B}(0,1)$.
%
$$
\int\limits_{\mathclap{\mathcal{B}(0,1)}}^{} \psi(x) \dd x 
= c_n \int\limits_{\mathclap{0}}^{1} \frac{1}{\rho^\alpha} \rho^{n -1} \dd \rho 
= c_n \int\limits_{\mathclap{0}}^{1} \rho^{n-1-\alpha} \dd \rho =
\begin{cases}
	\log (\rho) \quad n = \alpha \\
	\dfrac{\rho^{n-\alpha}}{n - \alpha} \quad \text{altrimenti} 
\end{cases} 
$$
%
Concludendo,
%
$$
	\int\limits_{\mathcal{B}(0,1)}^{} \frac{1}{\norm{ x }^\alpha} \dd x < + \infty \longiff n > \alpha.
$$
%
\textbf{Esercizio.}
Con passaggi analoghi al precedente otteniamo
%
$$
	\int\limits_{\R^n \setminus \; \mathcal{B}(0,1)}^{} \frac{1}{\norm{ x }^\alpha} \dd x < + \infty \longiff n < \alpha.
$$
%
\textbf{Esercizio.}
Vediamo per quali valori di $\beta$ l'integrale
%
$$
	\int\limits_{\mathcal{B}(0,1)}^{} \frac{1}{\left( \norm{ x } + \norm{ x }^2 \right)^\beta} \dd x
$$
%
converge.

Vale la seguente catena di uguaglianze.
%
$$
\int\limits_{\mathclap{\R^n}}^{} \frac{1}{\left( \norm{ x } + \norm{ x }^2 \right)^\beta} \dd x 
= \int\limits_{\mathcal{B}(0,1)}^{} \frac{1}{\left( \norm{ x } + \norm{ x }^2 \right)^\beta} \dd x 
+ \int\limits_{\R^n \setminus \; \mathcal{B}(0,1)}^{} \frac{1}{\left( \norm{ x } + \norm{ x }^2 \right)^\beta} \dd x.
$$
%
Studiamo separatamente i due pezzi dell'integrale.
%
\begin{align*}
	\int\limits_{\mathcal{B}(0,1)}^{} \frac{1}{\left( \norm{ x } + \norm{ x }^2 \right)^\beta} \dd x 
	& = c_n \int\limits_{\mathclap{\mathcal{B}(0,1)}}^{} \frac{1}{(\rho + \rho^2)^\beta} \rho^{n-1} \dd \rho
	= c_n \int\limits_{\mathclap{0}}^{1} \frac{1}{\rho^\beta} \cdot \frac{\rho^{n-1}}{(1 + \rho)^\beta} \dd \rho \\
	& \approx \int\limits_{\mathclap{0}}^{1} \rho^{n-1-\beta} \dd \rho < + \infty \longiff  \beta < n.
\end{align*}
%
Inoltre,
%
$$
	\int\limits_{\mathcal{B}(0,1)}^{} \frac{1}{\left( \norm{ x } + \norm{ x }^2 \right)^\beta} \dd x 
	= \int\limits_{\mathclap{\R^n \setminus \; \mathcal{B}(0,1)}}^{} \frac{1}{\rho^{2\beta}} \cdot \frac{\rho^{n-1}}{\left( \frac{1}{\rho} + 1 \right)^\beta} \dd \rho 
	\approx \int\limits_{\mathclap{1}}^{+\infty} \frac{\rho^{n-1}}{\rho^{2\beta}} \dd rho < + \infty \longiff 2\beta > \alpha.  
$$
%
In conclusione, l'integrale è finito se $n > \beta > n / 2$.

% @aziis98: Molto probabilmente metterò un disegnino con assi $n$ e $\beta$ per far vedere "meglio" l'insieme dei valori buoni

\textbf{Esercizio.}
Studiare l'insieme di finitezza al variare del parametro $\alpha$ dell'integrale
$$
	\int\limits_{\mathclap{[0,1]^n}}^{} \frac{1}{\norm{ x }_1^\alpha} \dd x 
$$
Osserviamo che la norma 1 e 2 sono legate dalle seguenti disuguglianze
$$
	\frac{\norm{ x }_1}{n} \leq \norm{ x }_2 \leq \norm{ x }_1.
$$
%
Studiamo una maggiorazione per l'integrale
%
$$
	\int\limits_{\mathclap{[0,1]^n}}^{} \, \frac{1}{\norm{ x }_1^\alpha} \dd x 
	\leq \;\int\limits_{\mathclap{[0,1]^n}}^{} \, \frac{1}{\norm{ x }^\alpha} \dd x 
	\leq \;\;\int\limits_{\mathclap{B(0,\sqrt{n})}}^{}\;\; \frac{1}{\norm{ x }^\alpha} \dd x < + \infty \longiff \alpha < n,
$$
%
dunque
%
$$
\int\limits_{\mathclap{[0,1]^n}}^{} \, \frac{1}{\norm{ x }_1^\alpha} \dd x < +\infty \quad \text{se} \; \alpha < n.
$$
%
Vediamo ora una minorazione.

$$
	\int\limits_{\mathclap{[0,1]^n}}^{} \frac{1}{\norm{ x }_1^\alpha} \dd x 
= \frac{1}{2^n}	\int\limits_{[-1,1]^n}^{} \frac{1}{\norm{ x }_1^\alpha} \dd x 
\geq \frac{1}{2^n} \ \int\limits_{\mathclap{\mathcal{B}(0,1)}}^{} \frac{1}{\norm{ x }_1^\alpha} \dd x 
\approx \int\limits_{\mathclap{\mathcal{B}(0,1)}}^{} \frac{1}{\norm{ x }^\alpha} \dd x < + \infty 
\longiff \alpha < n.
$$

Dunque l'integrale $\ds \int\limits_{\mathclap{[0,1]^n}}^{} \frac{1}{\norm{x}_1^\alpha} \dd x$ converge se solo se $\alpha < n$.

\newpage

\textbf{Esercizi per casa.}
\begin{enumerate}[label=(\arabic*)]

\item Dimostrare che date $f,g$ misurabili ed $r,p_1,p_2 > 0$ tali che  $1 / r = 1 / p_1 + 1 / p_2$.
Allora vale
$$
	\norm{ f \cdot g }_r \leq \norm{ f }_{p_1} + \norm{ g }_{p_2}.
$$
\textit{Suggerimento.} Usare Holder osservando che $\ds 1 = \frac{r}{p_1} + \frac{r}{p_2} = \frac{1}{\left( p_1/r \right)} + \frac{1}{\left( p_2/r \right)}$.

\item Dimostrare che date $f_1,\ldots, f_n$ misurabili e $p_i > 0$ tali che $1/p_1 + \ldots + 1/p_n = 1$ si ha
$$
	\norm{ f_1 \cdots f_n }_1 \leq \norm{ f_1 }_{p_1} \cdots \norm{ f_n }_{p_n}.
$$
\textit{Suggerimento.} Fare il primo passo dell'induzione e usare la formula precedente scegliendo $r$ in modo corretto.

\end{enumerate}

% @aziis98: Forse ci conviene aggiungere commenti del genere almeno per noi, poi magari aggiungiamo meglio i link per lezione con le date.

%
% Lezione del 6 Ottobre 2021
%

\section{Costruzione spazi $L^p$}

Fissiamo $(X, \mathcal A, \mu)$ come sempre.

\textbf{Definizione.}
Sia $\mathscr L^p$ l'insieme delle funzioni $f \colon X \to \R$ o $\R^d$ misurabili tali che $\norm{f}_p < +\infty$.

\textbf{Osservazioni.}
\begin{itemize}
	\item $\mathscr L^p$ è un sottospazio vettoriale dello spazio vettoriale dato da $\{ f \colon X \to \R \mid f \text{ misurabile} \}$ e $\norm{\curry}_p$ è una semi-norma.

		\textbf{Dimostrazione.}
		\begin{itemize}
			\item $\mathscr L^p$ è chiuso per moltiplicazione per scalari.

			\item $f_1, f_2 \in \mathscr L^p \implies f_1 + f_2 \in \mathscr L^p$

			\item Dalla definizione segue subito $\norm{\lambda f}_p = |\lambda| \cdot \norm{f}_p$ l'omogeneità della norma.

			\item Dalla disuguaglianza di Minkowski segue che $\norm{\curry}_p$ è una semi-norma.
		\end{itemize}

	\item In particolare non è una norma se $\{ 0 \} \subsetneq \{ f \mid \norm{f}_p = 0 \}$ ovvero se $\mathcal A$ contiene insiemi non vuoti di misura nulla.

	\item In generale dato $V$ spazio vettoriale e $\norm{\curry}$ semi-norma su $V$ possiamo inotrdurre $N \coloneqq \{ v \mid \norm{v} = 0 \}$. $N$ risulta essere un sottospazio di $V$ e la norma data da $\norm{[v]} \coloneqq \norm{v}$ per $[v] \in \sfrac{V}{N}$ è ben definita ed è proprio una norma su $\sfrac{V}{N}$.

	\item Nel caso della della norma $\norm{\curry}_p$ abbiamo che $[f_1] = [f_2] \iff [f_1 - f_2] = 0 \iff f_1 - f_2 = 0$ quasi ovunque. 
\end{itemize}

\textbf{Definizione.}
Poniamo $N \coloneqq \{ f \mid \norm{f}_p = 0 \}$ e definiamo gli \textbf{spazi $L^p$} come
$$
L^p := \sfrac{\mathscr L^p}{N} = \sfrac{\mathscr L^p}{\sim} 
\qquad
\norm{[f]}_p \coloneqq \norm{f}_p
$$

\textbf{Notazione.}
Ogni tanto serve precisare meglio l'insieme di partenza e di arrivo degli spazi $L^p$ ed in tal caso useremo le seguenti notazioni
$$
L^p = L^p(X) = L^p(X, \mu) = L^p(X, \mathcal A, \mu) = L^p(X, \mu; \R^d)
$$

\textbf{Nota.}
Nella pratica non si parla mai di ``classi di funzioni'' e si lavora direttamente parlando di ``funzioni in $L^p$''. Le ``operazioni'' comuni non creano problemi però in certi casi bisogna stare attenti di star lavorando con oggetti ben definiti ad esempio:
\begin{itemize}
	\item Preso $x_0 \in X$ consideriamo l'insieme $\{ f \in L^p \mid f(x_0) = 0 \}$ non è un sottoinsieme ben definito (a meno che $\mu(\{ x_0 \}) > 0$) di $L^p$ in quanto possiamo variare $f$ su un insieme di misura nulla.

	\item Invece l'insieme $\{ f \in L^1 \mid \int_X f \dd \mu = 0 \}$ è ben definito.
\end{itemize}

\section{Completezza degli spazi $L^p$}

Vediamo ora la proprietà più importante degli spazi $L^p$.

\textbf{Teorema.}
Per $p \in [1, +\infty]$ lo spazio $L^p$ è completo.

% @aziis98: Per ora mi pare non si possano usare direttamente \label e \ref in questi punti, cioè linka alla sezione.
\hypertarget{prop:completeness_lemma_1}{}
\textbf{Lemma 1.} 
Dato $(Y, d)$ spazio metrico, allora
\begin{enumerate}
	\item
		Ogni successione $(y_n)$ tale che
		$$
		\sum{\infty}_{n=1} d(y_n, y_{n+1}) < +\infty
		$$
		è di Cauchy, e in particolare converge a qualche $y \in Y$ se $Y$ è completo.

	\item \label{item:def_completeness_1}
		Se ogni $(y_n)$ tale che $\sum{\infty}_{n=1} d(y_n, y_{n+1}) < +\infty$ converge allora $Y$ è completo.	
\end{enumerate}

\textbf{Osservazione.} Non tutte le successioni di Cauchy $(y_n)$ soddisfano quella condizione, ad esempio su $\R$ la successione $\sfrac{(-1)^n)}{n}$ è di Cauchy però
$$
\sum_{n=1}^\infty \left| \frac{(-1)^{n+1}}{n+1} - \frac{(-1)^n}{n} \right| 
= \sum_{n=1}^\infty \frac{2n + 1}{n^2 + n}
\approx \sum_{n=1}^\infty \frac{1}{n} \to \infty
$$
ma come abbiamo visto nella \ref{item:def_completeness_1} ci basta per mostrare la completezza dello spazio che è ciò che ci interessa veramente.

\textbf{Dimostrazione.}
\begin{enumerate}
	\item 
		Dati $n > m$ abbiamo che 
		$$
		d(y_m, y_n) \leq \sum_{k=m}^{n-1} d(y_k, y_{k+1}) \leq \sum_{k=m}^\infty d(y_k, y_{k+1}) \to 0
		$$
		in quanto è la \textit{coda di una serie convergente} quindi 
		$$
		\forall \epsilon > 0 \; \exists m_\epsilon \text{ tale che } \sum_{k = m_\epsilon}^\infty d(y_k, y_{k+1})< \epsilon \implies \forall n > m \geq m_\epsilon \; d(y_m, y_n) \leq \epsilon
		$$ 

	\item
		Basta far vedere che data $(y_n)$ di Cauchy esiste una sottosuccessione $y_{n_k}$ tale che
		$$
		\sum_{k=1}^\infty d(y_{n_k}, y_{n_{k+1}}) < +\infty
		$$
		ma $\forall k \; \exists n_k$ tale che $\forall n, m \geq n_k \; d(y_m, y_n) \leq \frac{1}{2^k}$ dunque $d(y_{n_k}, y_{n_{k+1}}) \leq \frac{1}{2^k}$.

		Quindi per ipotesi $y_{n_k}$ converge a qualche $y \in Y$ ed anche $y_n \to y$.
\end{enumerate}
\qed

% @aziis98: Il latex mi vuole male e mi metteva solo Corollario e la prima frase alla fine della pagina e l'enumerate alla nuova, però se aggiungiamo cose prima poi lo togliamo.
\newpage

\hypertarget{prop:completeness_lemma_2}{}
\textbf{Lemma 2.} 
Dato $Y$ spazio normato, i seguenti fatti sono equivalenti
\begin{enumerate}
	\item $Y$ è completo.

	\item $\sum_{n=1}^\infty y_n$ converge in $Y$ per ogni $(y_n)$ tale che $\sum_{n=1}^\infty \norm{y_n} < +\infty$ ovvero $\norm{y - \sum_{n=1}^N y_n} \to 0$.
\end{enumerate}

\textbf{Dimostrazione.} 
È un corollario del lemma precedente. 
\qed

\hypertarget{prop:completeness_lemma_3}{}
\textbf{Lemma 3} 
(Minkowski per somme infinite). 
Date delle funzioni $(g_n)$ funzioni positive su $X$ allora
$$
\norm{\sum_{n=1}^\infty g_n}_p \leq \sum_{n=1}^\infty \norm{g_n}_p
$$

% @aziis98: Si bisognerebbe scrivere qualche parola in più magari a questa dimostrazione.
\textbf{Dimostrazione.}
Per ogni $N$ abbiamo che
$$
\norm{\sum_{n=1}^N g_n}_p^p 
\leq \left( \,\sum_{n=1}^N \norm{g_n}_p \right)^p 
\leq \left( \,\sum_{n=1}^\infty \norm{g_n}_p \right)^p 
$$
e
$$
\norm{\sum_{n=1}^N g_n}_p^p 
= \int_X \left( \sum_{n=1}^N g_n(x) \right)^p \dd \mu(x)
\xrightarrow{\;N\;} \int_X \left( \sum_{n=1}^\infty g_n(x) \right)^p \dd \mu(x)
$$
per \textit{convergenza monotona}.
\qed

\textbf{Dimostrazione} (Completezza spazi $L^p$).
\begin{itemize}
	\item 
		Se $p = +\infty$: si tratta di vedere che data $(f_n)$ di Cauchy in $L^\infty(X)$ esiste $E$ con $\mu(E) = 0$ tale che $(f_n)$ è di Cauchy rispetto allora norma del sup in $X \setminus E$. [TODO: Finire]

	\item 
		Se $p < +\infty$: per il \hyperlink{prop:completeness_lemma_2}{Lemma 2}, basta far vedere che data $(f_n) \subset L^p(X)$ tale che $\sum_{n=1}^\infty \norm{f_n}_p < +\infty$ allora $\sum_n f_n$ converge a qualche $f \in L^p(X)$.

		La dimostrazione è suddivisa in tre passi, prima costruiamo $f$, poi mostriamo che $f_n$ convege a $f$ ed infine mostriamo $f \in L^p(X)$.

		\begin{itemize}
			\item 
				\textit{Passo 1:} 
				Per ipotesi abbiamo
				$$
				\infty 
				> \sum_{n=1}^\infty \norm{f_n}_p 
				= \sum_{n=1}^\infty \norm{|f_n|}_p 
				\geq \norm{\sum_{n=1}^\infty |f_n|}_p 
				= \left( \int \left( \sum_{n=1}^\infty |f_n(x)| \right)^p \dd \mu(x) \right)^{1/p}
				$$
				quindi $\sum_{n=1}^\infty |f_n(x)| < +\infty$ per ogni $x \in X \setminus E$ con $\mu(E) = 0$. Quindi $\sum_{n=1}^\infty f_n(x)$ converge a qualche $f(x)$ per ogni $x \in X \setminus E$ ed a questo punto ci basta estendere $f$ a zero\footnote{Una costruzione alternativa degli spazi $L^p$ potrebbe anche partire da \textit{funzioni definite quasi ovunque}, questo ovvierebbe al problema di estendere a $0$ la funzione $f$ appena costruita. Però diventa più complicato mostrare di essere in uno spazio vettoriale poiché per esempio serve ridefinire $+$ per funzioni definite quasi ovunque.}.
			
			\item 
				\textit{Passo 2:}
				Fissiamo $N$ ed osserviamo che $\forall x \in X \setminus E$ abbiamo
				$$
				\left| f(x) - \sum_{n=1}^N f_n(x) \right| 
				= \left| \sum_{n=N+1}^\infty f_n(x) \right| 
				\leq \sum_{n=N+1}^\infty |f_n(x)|
				$$
				da cui otteniamo
				$$
				\norm{f - \sum_{n=1}^N f_n}_p 
				\leq \norm{\sum_{n=N+1}^\infty |f_n|}_p
				\leq \sum_{n=N+1}^\infty \norm{f_n}_p
				$$
				dove l'ultimo termine è la coda di una serie convergente.
			
			\item 
				\textit{Passo 3:}
				In particolare rileggendo il passo precedente per $N = 0$ otteniamo
				$$
				\norm{f}_p \leq \sum_{n=1}^\infty \norm{f_n}_p < +\infty \implies f \in L^p
				$$

		\end{itemize}
\end{itemize}
\qed

\textbf{Esercizio.}\footnote{In questo corso non è strettamente necessario ricordarsi come si facciano tutti questi esercizietti di teoria della misura ma è bene saperli applicare in automatico quando serve.}
Sia $f \colon X \to [0, +\infty]$ allora $\ds \int_X f \dd \mu < +\infty \implies f(x) < +\infty$ per quasi ogni $x$.

\textbf{Dimostrazione.}
Sia $E := \{ x \mid f(x) = +\infty \}$, allora l'idea è che
$$
\infty > \int_X f \dd \mu \geq \int_E f \dd \mu = +\infty \cdot \mu(E)
$$
più precisamente osserviamo che $\forall m \in [0, +\infty)$ abbiamo $f \cdot \One_E \geq m \cdot \One_E$ quindi integrando ricaviamo
$$
\underbrace{\int_E f \dd \mu}_{I} \geq m \cdot \mu(E) 
\implies \mu(E) \leq \frac{I}{m} \xrightarrow{m \to +\infty} 0
$$
\qed

\section{Nozioni di convergenza per successioni di funzioni}
Fissiamo $X,\mathcal{A},\mu$ e prendiamo $f, f_n \colon X \to \R$ (o $\R^k$) misurabili.

\textbf{Definizione.}
Riportiamo le definizioni di alcune nozioni di convergenza.

\begin{itemize}

\item \textbf{Uniforme} : $\forall \epsilon \; \exists n_{\epsilon}$ tale che $\norm{f(x) - f_n(x)} < \epsilon \mquad n > n_\epsilon$.

\item \textbf{Puntuale} : $f_n \to f \mquad \forall x \in X$.

\item \textbf{Puntuale} $\mu$\textbf{-quasi ovunque} : $f_n \to f$ per $\mu$-q.o. $x \in X$.

\item \textbf{In} $L^p$ : $\norm{f_n - f}_p \to 0$.

\item \textbf{In misura} : $\ds \forall \epsilon > 0 \quad \mu \left( \left\{ x \mymid \left| f_n(x) - f(x) \right| \geq \epsilon \right\} \right) \xrightarrow{n \to +\infty} 0$.

\end{itemize}

\textbf{Osservazione.}
Abbiamo le seguenti implicazioni ovvie delle diverse nozioni di convergenza:

\begin{center}
	uniforme $\Rightarrow$ puntuale $\Rightarrow$ puntuale $\mu \almosteverywhere$
\end{center}

\textbf{Proposizione.}
Valgono le seguenti.
\begin{enumerate}

\item \label{item:convergenza_i} Data $f_n \to f$ q.o. e $\mu(X) < +\infty$, allora $f_n \to f$ in misura.

\item \label{item:convergenza_ii} (\textit{Severini-Egorov}): Data $f_n \to f$ q.o. e $\mu(X) < +\infty$, allora $\forall \delta > 0$ esiste  $E \in \mathcal{A}$ tale che $\mu(E) < \delta$ e $f_n \to f$ uniformemente su $X \setminus E$.

\item \label{item:convergenza_iii} $f_n \to f $ in $L^p$, $p < +\infty$, allora $f_n \to f$ in misura.

\item[iii')] \label{item:convergenza_iv} $f_n \to f \in L^\infty$, allora $\exists E $ tale che $\mu(E) = 0$ e $f_n \to f$ uniformemente su $X \setminus E$.

\item $f_n \to f$ in misura, allora $\exists n_k$ tale che $f_{n_k} \to f$ $\mu$-q.o.

\item $f_n \to f$ in $L^p$, allora $\exists n_k$ tale che $f_{n_k} \to f$ $\mu$-q.o.

\end{enumerate}

\textbf{Osservazione.}
In i) e ii) l'ipotesi $\mu(X) < +\infty$ è necessaria.
Infatti, preso $X = \R$ e $f_n = \One_{[n,+\infty)}$ si ha che $f_n \to 0$ ovunque ma $f_n$ non converge a $0$ in misura, e $f_n$ non converge a $0$ uniformemente in $\R \setminus E$ per ogni $E$ di misura finita.

\textbf{Lemma.} (Disuguaglianza di Markov).
Data $g \colon X \to [0,+\infty]$ misurabile e $m > 0$ si ha
%
$$
\mu \left( \left\{ x \in X \mymid g(x) \geq m \right\} \right) \leq \frac{1}{m} \int_X g \dd \mu
$$
%

\textbf{Dimostrazione.}
Poniamo $\ds E \coloneqq \left\{ x \in X \mymid g(x) \geq m \right\}$.
Osserviamo che $g \geq m \cdot \One_E$.
Dunque vale
%
$$
\int\limits_{\mathclap{X}}^{} g \dd \mu \geq \int\limits_{\mathclap{X}} m \cdot \One_E \dd \mu = m \cdot \mu \left( \left\{ x \in X \mymid g(x) \geq m \right\} \right)
$$
%
da cui la tesi.
\qed

\textbf{Lemma.} (Borel-Cantelli).
Dati $(E_n) \subset \mathcal{A}$ tali che $\sum \mu(E_n) \leq +\infty$, l'insieme
%
$$
E \coloneqq \left\{ x \in X \mymid x \in E_n \; \text{frequentemente} \right\}
$$
%
ha misura nulla.
Cioè per $\mu$-q.o. $x$, $x \notin E_n$ definitivamente (in $n$.)

\textbf{Dimostrazione.}
Osserviamo che
%
$$
E = \bigcap_{m=1}^\infty \Big( \underbrace{\bigcup_{n=m}^\infty E_n}_{F_m} \Big).
$$
%
Allora
%
$$
\mu(E) \quad \underbrace{=}_{\mathclap{F_m \downarrow E \; \& \; \mu(F_1) < +\infty}} \quad  \lim_{m \to \infty} \mu(F_m) \leq \lim_{m \to \infty} \underbrace{\sum_{n=m}^{\infty} \mu(E_n)}_{\mathclap{\text{coda di serie convergente}}} = 0.
$$
%

\textbf{Osservazione.}
L'ipotesi $\sum \mu(E_n) < +\infty$ non può essere sostituita con $\mu(E_n) \to 0$.

Ora dimostriamo la proposizione.

\textbf{Dimostrazione.}

Definiamo gli insiemi
\begin{align*}
A_n^\epsilon & \coloneqq \left\{ x \mymid \left| f_n(x) - f(x) \right| \geq \epsilon \right\}, \\
B_m^\epsilon & \coloneqq \left\{ x \mymid \left| f_n(x) - f(x) \right| \geq \epsilon \; \text{per qualche} \; n \geq m\right\} = \bigcup_{n = m}^\infty A_n^\epsilon, \\
A_n^\epsilon & \coloneqq \left\{ x \mymid \left| f_n(x) - f(x) \right| \geq \epsilon \; \text{frequentemente}  \right\} = \left\{ x \in A_n^\epsilon \; \text{frequentemente}  \right\} = \bigcap_{m = 1}^\infty B_m^\epsilon.
\end{align*}

\begin{enumerate}
\item Per ipotesi, $f_n \to f$ quasi ovunque, cioè $\mu(B^\epsilon) = 0$ per ogni $\epsilon > 0$, ma $B_m^\epsilon \downarrow B^\epsilon$ e $\mu(X) < +\infty$.
Allora
%
$$
\lim_{m \to +\infty} \mu(B_m^\epsilon) = \mu(B^\epsilon) = 0 \Rightarrow \lim_{m \to \infty} \mu(A_m^\epsilon) = 0.
$$
%

\item Dalla dimostrazione precedente, abbiamo $\ds \lim_{m \to \infty} \mu(B_m^\epsilon) = 0$. 
Allora per ogni $k$ esiste un $m_k$ tale che $\mu \left( B_m^{1/k} \right) \leq \delta / 2^k$.
Pongo $E \coloneqq  \bigcup_{k} B_{m_k}^{1/k}$ per ogni $k$; allora $\mu(E) \leq \delta$.
Inoltre,
\begin{align*}
x \in X \setminus E & \Rightarrow x \notin B_{m_k}^{1/k} \; \forall k \iff x \notin A_n^{1/k} \mquad \forall k,n \geq m_ k \\
& \Rightarrow \left| f(x) f_n(x) \right| < \frac{1}{k} \mquad \forall k,n \geq m_k \\
& \Rightarrow \sup_{x \in X \setminus E} \left| f(x) - f_n(x) \right| \leq \frac{1}{k} \mquad \forall k,n \geq m_k \\
& \Rightarrow f - f_m \; \text{uniformemente su} \; X \setminus E.
\end{align*}

\item Dobbiamo mostrare che per ogni $\epsilon > 0$ $\mu(A_n^\epsilon) \xrightarrow{n} 0$.
Usando la disuguaglianza di Markov ottengo

%
$$
\mu \Big( A_n^\epsilon= \Big\{ x \Big| \overbrace{\left| f_n(x) - f(x) \right|}^{g} \geq \epsilon^p \Big\} \Big)
\leq \frac{1}{m} \int\limits_{\mathclap{X}}^{} g \dd \mu = \frac{1}{\epsilon^p} \norm{f_n - f}_p^p \xrightarrow{n \to +\infty} 0.
$$
%

\item[iii')] Definiamo $\ds E_n \coloneqq  \left\{ x \mymid \left| f_n(x) - f(x) \right| > \norm{f_n - f}_\infty \right\}$ per ogni $n$, allora $\mu(E_n) = 0$.
Poniamo $E = \bigcup_{n} E_n$ e $\mu(E) = 0$, dunque
%
$$
\sup_{x \in X\setminus E} \left| f_n(x) - f(x) \right| \leq \norm{f_n - f}_\infty \to 0.
$$
%


\item per ipotesi, $f_n \to f$ in misura, cioè
\begin{align*}
& \forall \epsilon > 0 \quad \mu \left( A_n^\epsilon \right) \xrightarrow{n \to +\infty} 0 \\
& \Rightarrow \forall k \; \exists n_k \colon \mu \left( A_{n_k}^{1/k} \right) \leq \frac{1}{2^k} \\
& \Rightarrow \sum_{k}^{} \mu \left( A_{n_k}^{1/k} \right) < +\infty. 
\end{align*}
Allora per Borel-Cantelli, si ha per $\mu$-quasi ogni $x$, $x \notin A_{n_k}^{1/k}$ definitivamente in $k$, cioè $\norm{f_{n_k}(x) - f(x)} < 1/k$ definitivamente in $k$, cioè $\ds f_{n_k}(x) \xrightarrow{k} f(x)$.

\item[v)] [TODO].

\end{enumerate}

\subsection{Prodotto scalare su $L^2$}

Date $f_1,f_2 \in L^2(X)$ si pone
%
$$
\left<f_1, f_2 \right> \coloneqq \int\limits_{\mathclap{X}}^{} f_1 \cdot f_2 \dd \mu.
$$
%
\textbf{Osservazioni.}

\begin{itemize}
\item La definizione di $\left<f_1, f_2 \right>$ è ben posta.
Infatti, basta far vedere che $\ds \int_X \left| f_1 f_2 \right| \dd \mu < +\infty$, che segue da H\"{o}lder.
%
$$
\int\limits_{\mathclap{X}}^{} \left| f_1 f_2 \right| \dd \mu \leq \norm{f_1}_2 \norm{f_2}_2 < +\infty
$$
%

\item $\norm{f}_2^2 = \left<f,f \right>$ per ogni $f \in L^2(X)$.

\item Inoltre, $\ds \left| \int_X f_1 f_2 \right| \dd \mu \leq \int_X \left| f_1 f_2 \right| \dd \mu$ quindi
%
$$
\left| \left<f_1, f_2 \right> \right| \leq \norm{f_1}_2 \norm{f_2}_2 \quad \; \text{(\textit{Cauchy-Schwartz})}.
$$
%

\item L'operatore $\left< \ , \ \right>$ è un prodotto scalare definito positivo.

\end{itemize}

\textbf{Osservazioni.}
\begin{itemize}
\item Dato $C$ spazio vettoriale reale con prodotto scalare $\left<\ ,\ \right>$, allora $\left<\ ,\ \right>$ si ricava dalla norma associata $\norm{\cdot}$ tramite l'identità di polarizzazione:
%
$$
\left<v_1, v_2 \right> = \frac{1}{4} \left( \norm{v_1 + v_2}^2 - \norm{v_1 - v_2}^2 \right).
$$
%

\item  Dato $V$ come sopra, vale l'identità del parallelogramma:
%
$$
\norm{v_1 + v_2}^2 + \norm{v_1 - v_2}^2 = 2 \norm{v_1}^2 + 2 \norm{v_2}^2 \quad \forall v_1,v_2 \in V.
$$
%
 Usando questa identità di dimostra che la norma di $L^p$ deriva da un prodotto scalare solo per $p=2$.

\end{itemize}

\textbf{Proprietà.}
Sia $V$ uno spazio vettoriale normato con norma $\norm{\cdot}$. Allora vale l'identità del parallelogramma se solo se $\norm{\cdot}$ deriva da un prodotto scalare.

\textbf{Esempio.}
La norma di $L^p \left( [-1,1] \right)$, deriva da un prodotto scalare solo per $p=2$.
Prendiamo $f_1 = \One_{[-1,0]}$ e $f_2 = \One_{[0,+1]}$.
Allora
%
\vspace{-5mm}
%
\begin{align*}
\norm{f_1 + f_2}_p^p = \int\limits_{\mathclap{-1}}^{1} 1 \dd x = 2 \Rightarrow \norm{f_1 + f_2}_p = 2^{1/p} \\
\norm{f_1 - f_2}_p = \norm{f_1 + f_2}_p = 2^{1/p}, \quad \norm{f_1}_p = \norm{f_2}_p = 1
\end{align*}
%
Se vale l'identità del parallelogramma allora
%
$$
\norm{f_1 + f_2}_p^2 + \norm{f_1 - f_2}_p^2 = 2 \norm{f_1}_p^2 + 2 \norm{f_2}_p^2
$$
%
cioè
%
$$
2^{2/p} + 2^{2/p} = 2 \cdot 1 + 2 \cdot 1 \iff p = 2.
$$
%

\textbf{Domanda.} Per quali $X,\mathcal{A},\mu$ vale la stessa conclusione?

%
% Lezione dell'11 Ottobre 2021
%

\section{Controesempi sulle convergenze}

Vediamo un controesempio che mostra che tutte le implicazioni sui vari tipi di convergenza sono ottimali ovvero
\begin{enumerate}
	\item \label{item:ce_1}
		$f_n \to f$ in misura $\centernot\implies f_n \to f$ q.o.
	\item \label{item:ce_2}
		$f_n \to f$ in $L^p$ con $p < +\infty \centernot\implies f_n \to f$ q.o.
	\item \label{item:ce_3}
		$\mu(E_n) \to 0 \centernot\implies$ per q.o $x$ si ha $x \notin E_n$ definitivamente. 
\end{enumerate}

\textbf{Dimostrazione.}
Consideriamo gli insiemi $I_1 = \left[ 1, 1 + \frac{1}{2} \right], I_2 = \left[1 + \frac{1}{2}, 1 + \frac{1}{2} + \frac{1}{3} \right], \dots$
$$
I_n \coloneqq \left[ \; \sum_{k=1}^n \frac{1}{k}, \; \sum_{k=1}^{n+1} \frac{1}{k} \; \right]
$$
e consideriamo la loro proiezione ``modulo'' $[0, 1]$ usando la funzione $p \colon \R \to [0, 1)$ \textit{parte frazionaria} data da
$$
p(x) \coloneqq x - \lfloor x \rfloor
$$
e chiamiamo $E_n \coloneqq p(I_n)$. Per ogni $n$ abbiamo che $|I_n| = |E_n| = 1 / n$ e $\bigcup_n I_n = [1, +\infty)$ (in quanto $\sum_{k=1}^\infty \frac{1}{k} = +\infty$) e quindi ogni $x \in [0, 1)$ appartiene ad $E_n$ per infiniti $n$ ed in particolare questo mostra la \ref{item:ce_3}. 

[TODO: Disegnino]

Per la \ref{item:ce_1} basta consideare $\One_{E_n} \to 0$ in misura (in quanto $|E_n| \to 0$) ma $\One_{E_n} \centernot\to 0$ q.o., anzi $\forall x \in [0, 1) \; \One_{E_n}(x) \centernot\to 0$ e la \ref{item:ce_2} segue analogamente.
\qed

\subsection{Approssimazioni di funzioni in $L^p$}

% Ricordiamo la nozione di insieme denso in uno spazio metrico.
% Sia (X,d) uno spazio metrico e Y ⊆ X. Allora Y è denso in X se solo se
% per ogni x ∈ X, esiste una successione y_n in Y che tale che x = lim_n y_n.

Vediamo ora alcune classi di funzioni dense in $L^p$ che risulteranno essere un utile strumento da usare nelle dimostrazioni.

\textbf{Nota.} Ricordiamo la nozione di insieme denso in uno spazio metrico.
Sia $(X,d)$ uno spazio metrico e $Y \subset X$. Allora Y è denso in X se solo se
per ogni $x \in X$, esiste una successione $(y_n)_{n \in \N}$ in $Y$ che tale che $x = \lim_n y_n$.

Per ora sia $(X, \mathcal A, \mu)$ in generale.

\textbf{Esercizio.} 
Le funzioni limitate in $L^p$ sono dense in $L^p$.

\textbf{Dimostrazione.}
Data $f \in L^p(X)$ cerchiamo una successione di funzioni $f_n \in L^p(X)$ limitate tali che $f_n \to f$ in $L^p$, consideriamo
$$
f(x) (\coloneqq f(x) \land n) \lor (-n)
$$
vorremmo mostrare che $f_n \to f$ in $L^p$ ovvero
$$
\norm{f_n - f}_p^p = \int_X |f_n - f|^p \dd \mu \to 0
$$
intanto vediamo che per la \textit{convergenza puntuale} basta osservare che se $n \geq |f(x)|$ abbiamo che $\forall x \; f_n(x) = f(x) \implies f_n(x) \xrightarrow{n} f(x) \implies |f_n(x) - f(x)|^p \to 0$.

Per concludere basta applicare \textit{convergenza dominata} usando come dominazione direttamente $|f(x) - f_n(x)| \leq |f(x)| \implies |f(x) - f_n(x)|^p \leq |f(x)|^p$ e notiamo che $|f|^p \in L^1(X)$.
\qed

\textbf{Proposizione.}
Sia\footnote{Lo span è inteso come combinazioni lineari} $\tilde{\mathscr S} \coloneqq \operatorname{Span}(\{ \One_E \mid E \in \mathcal A, \mu(E) < +\infty \})$, allora $\tilde{\mathscr S}$ è denso in $L^p(X)$.

\textbf{Dimostrazione.}
Data $f \in L^p(X)$ cerchiamo una successione che approssima $f$ in $\tilde{\mathscr S}$.
\begin{itemize}
	\item 
		\textit{Caso 1}: Se $f \geq 0$ allora fissiamo $\epsilon > 0$ e per ogni $k = 1, 2, \dots$ e poniamo
		$$
		A_k^\epsilon := \{ x \mid k \epsilon \leq f(x) \leq (k+1) \epsilon \}
		$$
		risulta che $A_k^\epsilon$ è misurabile ed ha misura finita. Ora consideriamo la successione di funzioni parametrizzata da $\epsilon$ data da
		$$
		f_\epsilon(x) := \sum_{1 \leq k \leq 1 / \epsilon^2} k \epsilon \cdot \One_{A_\epsilon^k}(x) \in \tilde{\mathscr S}
		$$
		[TODO: Disegnino]

		Osserviamo che vale anche $f_\epsilon(x) = \max\{ k \epsilon \mid k \epsilon \leq f(x) \text{ e } k \leq 1 / \epsilon^2 \}$ e mostriamo la seguente\footnote{Notiamo che qui stiamo applicando il teorema di \textit{convergenza dominata} su una famiglia parametrizzata da $\epsilon$ e non su una successione ma si può verificare facilmente che il teorema (ed anche gli altri risultati di convergenza di successioni di funzioni) si può estendere semplicemente prendendo $\epsilon = 1 / n$ per $n \to \infty$.}
		$$
		\int_X |f(x) - f_\epsilon(x)|^p \dd \mu(x) \xrightarrow{\epsilon \to 0} 0
		$$
		\begin{itemize}
			\item \textit{Convergenza puntuale}: Per l'identità precedente abbiamo che $0 \leq f(x) - f_\epsilon(x) \leq \epsilon$ se $f(x) \leq 1 / \epsilon$.
			% @aziis98: Cioè per me questo passaggio è ancora un po' mistico quindi poi voglio provare a spiegarlo meglio
			% ($f(x) \leq 1 / \epsilon \implies k \epsilon \leq 1 / \epsilon \implies k \leq 1 / \epsilon^2$ [TODO])
			\item \textit{Dominazione}: Possiamo usare nuovamente $|f(x) - f_\epsilon(x)|^p \leq |f(x)|^p < +\infty$ in quanto $f \in L^p(X)$.
		\end{itemize}

		[TODO: Disegnino]

	\item 
		\textit{Caso 2}:
		Sia $f \colon X \to \R$ allora si può rifare la dimostrazione precedente oppure si può semplicemente consideare $f_\epsilon \coloneqq (f^+)_\epsilon - (f^-)_\epsilon$.

	\item 
		\textit{Caso 3}:
		Generalizziamo la proposizione al caso di $f \colon X \to \R^d$ come segue

		\textbf{Proposizione.} (Generalizzata)
		Sia $\tilde{\mathscr S} \coloneqq \{ \sum_i \alpha_i \One_{E_i} \mid \alpha_i \in \R^d, E_i \in \mathcal A, \mu(E_i) < +\infty \} \implies \tilde{\mathscr S}$ è denso in $L^p(X; \R^d)$.

		\textbf{Dimostrazione.} (Idea)
		Basta approssimare componente per componente.
\end{itemize}
\qed

Sia ora $X$ uno \textit{spazio metrico} e $\{ \text{aperti} \} \subset \mathcal A$.

\textbf{Proposizione.}
Sia $\tilde{\mathscr S}_\ell \coloneqq \{ \sum_i \alpha_i \One_{E_i} \mid \alpha_i \in \R^d, E_i \in \mathcal A, \mu(E_i) < +\infty, E_i \text{ limitati} \}$ allora $\tilde{\mathscr S}_\ell$ è denso in $L^p(X; \R^d)$ per $p < +\infty$.

\textbf{Osservazione.} 
In generale l'enunciato non vale per $p = +\infty$. Ad esempio preso $L^\infty(\R)$ e $f = 1$ non si può approssimare con funzioni a supporto limitato (come quelle in $\tilde{\mathscr S}_\ell$. In particolare data $g$ con supporto $A$ limitato $|f - g| = 1$ su $\R \setminus A$ e siccome $|\R \setminus A| > 0$ abbiamo $\norm{f - g}_\infty \geq 1$).

\textbf{Dimostrazione.} ($\tilde{\mathscr S}_\ell$ è denso in $L^p$)
Per prima cosa vediamo un lemma che useremo assieme alla proposizione precedente.

% @aziis98: Boh questo lemma non so se metterlo prima o se lasciarlo qua

\textbf{Lemma.}
Dato $E \in \mathcal A, \mu(E) < +\infty$ esiste $E_n \in \mathcal A$ con $E_n$ limitati tali che $E_n \subset E$ e $\mu(E \setminus E_n) \to 0$ e quindi $\norm{\One_{E} - \One_{E_n}}_p = \mu(E \setminus E_n)^{1/p} \xrightarrow{n} 0$ (e $\One_{E_n} \in \tilde{\mathscr S}_\ell$).

\textbf{Dimostrazione.}
Dato $E$ con $\mu(E) < +\infty$ prendiamo $x_0 \in X$ e poniamo $E_n \coloneqq E \cap \mathcal B(x_0, n)$; $E_n \subset E$ e $E \setminus E_n \downarrow \varnothing \implies \mu(E \setminus E_n) \xrightarrow{n} 0$.

Intuitivamente $\tilde{\mathscr S}_\ell$ è denso in $\tilde{\mathscr S}$ che a sua volta è denso in $L^p$ (usando la definizione di densità topologica la tesi è quasi ovvia mentre usando la definizione per successioni bisogna passare per un procedimento diagonale).
\qed

Ora sia $X \subset \R^n, \mu = \mathscr L^n$ e 
$$
C_C(\R^n) \coloneqq \{ \text{funzioni a supporto compatto} \}
$$
notiamo che $C_C(\R^n) \subset L^p$ per ogni $p$.

\textbf{Proposizione.}
Le funzioni in $C_C(\R^n)$ \textit{ristrette a $X$} sono dense in $L^p(X)$ per $p < +\infty$.

Vediamo prima alcuni lemmi.

\textbf{Lemma.}
Dato $E \subset \R^n$ limitato (e quindi di misura finita) esiste $f_\epsilon \in C_C(\R^n)$ tale che $f_\epsilon \xrightarrow{\epsilon \to 0} \One_E$ in $L^p(\R^n)$ e quindi in $L^p(X)$.

\textbf{Dimostrazione.}
Per regolarità della misura di Lebesgue abbiamo che per ogni $\epsilon$ esistono $C_\epsilon \subset E \subset A_\epsilon$ tali che $|A_\epsilon \setminus C_\epsilon| \leq \epsilon$ e prendiamo $f_\epsilon \colon \R^n \to [0, 1]$ continua tale che
$$
f_\epsilon = 1 \text{ su $C_\epsilon$}
\qquad
f_\epsilon = 0 \text{ su $\R^n \setminus A_\epsilon$}
$$
in particolare sappiamo che su $A_\epsilon \setminus C_\epsilon$ vale $|f_\epsilon - \One_E| \leq 1$
$$
\implies \norm{f_\epsilon - \One_E}_p^p = \int_{A_\epsilon \setminus C_\epsilon} |f_\epsilon - \One_E|^p \dd x
$$

\textbf{Lemma.} (di Urysohn)
Dati $C_0, C_1$ chiusi disgiunti in $X$ spazio metrico esiste una funzione $f \colon X \to [0, 1]$ continua tale che $f = 0$ su $C_0$ e $f = 1$ su $C_1$.

\textbf{Dimostrazione.}
Posta $d(x, C) = \inf \{ d(x, y) \mid y \in C \}$ basta consideare
$$
f(x) =
\frac{d(x, C_0)}{d(x, C_0) + d(x, C_1)}
$$

\textbf{Dimostrazione.} ($C_C(\R^n)$ è denso in $L^p(X)$)

Segue dalla proposizione e dal lemma precedente.

% 
% Lezione del 13 Ottobre 2021
% 

\section{Esercitazione del 13 ottobre}

\subsection{Esercizi su spazi $L^p(X)$ al variare di $p$ e dello spazio $X$}

Sia $X \subset \R^n$, $\mu$ la misura di Lebesgue e $ 1 \leq p_1 \leq p_2$.

\textbf{Domanda.} Possiamo confrontare gli spazi $L^{p_1}(X)$ e $L^{p_2}(X)$?
In generale no. 

Vediamo informalmente perché.
Posto $X = (0,+\infty)$, gli integrali 
%
$$
\int\limits_{\mathclap{0}}^{+\infty} \frac{1}{(1+x)^{\beta p}} \dd x, \qquad \int\limits_{\mathclap{0}}^{+\infty} \frac{1}{x^{\beta p}} \cdot \One_{[0,1]}(x) \dd x = \int\limits_{\mathclap{0}}^{1} \frac{1}{x^{\beta p}} \dd x
$$
%
 sono maggiorati dall'integrale di $1 / x^{\alpha}$ dove l'esponente  $\alpha$ è rispettivamente più piccolo e più grande di $\beta \cdot p$.

Vediamo quanto detto finora più formalmente.

Cerchiamo una funzione $f \in L^{p_1}(0,+\infty) \setminus \, L^{p_2}(0,+\infty)$ e una funzione $g \in L^{p_2}(0,+\infty) \setminus \, L^{p_1}(0,+\infty)$.
La funzione $f$ definita come segue
%
$$
f(x) \coloneqq 
\begin{cases}
1 / x^\beta \mquad x \in (0,1) \\
0 \mquad x \geq 1
\end{cases} 
$$
%
ha integrale 
%
$$
\int\limits_{\mathclap{0}}^{+\infty} f(x)^{p_1} \dd x = \int\limits_{\mathclap{0}}^{1} \frac{1}{x^{\beta p_1}} \dd x < +\infty \longiff \beta \cdot p_1 < 1, \mquad 0 < p_1 < p_2 \longiff \frac{1}{p_2} < \frac{1}{p_1}
$$
e
$$
\int\limits_{\mathclap{0}}^{+\infty} f(x)^{p_2} \dd x = \int\limits_{\mathclap{0}}^{1} \frac{1}{x^{\beta p_2}} \dd x = +\infty \longiff \beta \cdot p_2 \geq 1
$$
%
basta prendere $\beta \in [1/p_2, 1/p_1)$.

Ora cerco $g \in L^2 (0,+\infty) \setminus \, L^{p_1}(0,+\infty)$.
Definisco $g(x)$ come segue
$$
g(x) \coloneqq \frac{1}{(1+x)^\alpha}
$$
da cui
$$
\int\limits_{\mathclap{0}}^{+\infty} g(x)^{p_2} \dd x < +\infty \longiff \alpha \cdot p_2 > 1
\quad
\text{e}
\quad
\int\limits_{\mathclap{0}}^{+\infty} g(x)^{p_1} \dd x = +\infty \longiff \alpha \cdot p_1 \leq 1
$$

\textit{Conclusione.} In generale non c'è confrontabilità fra gli spazi $L^p$. La confrontabilità, dipende infatti dall'insieme $X$ su cui sono definiti.

Un caso particolare è dato ponendo $p_1 < p_2$ e $\mu(X) < +\infty$. In tal caso $L^{p_2}(X) \subset L^{p_1}(X) $.

Data $f \in L^{p_2}(X)$, cioè con $\int_X \left| f \right|^{p_2} \dd \mu < +\infty$ vediamo che  $\int_X \left| f \right|^{p_1} \dd \mu < +\infty$.

Usiamo Holder:
\begin{align*}
\int_{X} \left| f \right|^{p_1} \dd \mu & \leq \Bigg( \int_{X} \overbrace{\left| h(x) \right|^p}^{\left| f(x) \right|^{p_1 p}}  \dd \mu  \Bigg)^{1/p} \cdot \left( \int_{X} 1^q \dd \mu  \right)^{1/q}
\underbrace{\leq}_{\mathclap{p = p_1 / p_2}} \left( \int_{X} \left| f \right|^{p_1} \dd \mu  \right)^{p_1 /p_2} \left( \int_{X} 1^q \dd \mu  \right)^{1/q} \\
& \underbrace{=}_{\mathclap{q = (1 - \frac{1}{p})^{-1} = \frac{p}{p-1} = \frac{p_2 / p_1}{p_2 - p_1}}} \norm{f}_{L^{p_2}(X)}^{p_1} \cdot \mu(X)^{\frac{p_2 - p_1}{p_2}}.
\end{align*}
Dunque
 %
$$
\norm{f}_{L^{p_1}(X)} \leq \norm{f}_{L^{p_2}(X)}\cdot \mu(X)^{\frac{p_2 - p_1}{p_1 p_2}}.
$$
%
L'inclusione
%
\begin{align*}
i \colon L^{p_2} & \to L^{p_1}(X) \\
f & \mapsto f
\end{align*}

è ben definita per quanto fatto sopra. Per esercizio vedere con quale topologia risulta continua. [TO DO]

\textbf{Esercizio.} [TO DO] Dato $p \geq 1$, stabilire se esistono $X, \mu,f \in L^p(X)$ e $f \notin L^q(X)$ per ogni $q \neq p$, $q \geq 1$. \\
\textit{Suggerimento.} pensare a $X = (0,+\infty)$, $\mu$ misura di Lebesgue.

\textbf{Osservazione.} $L^p(X)$ è uno spazio vettoriale di dimensione infinita, ossia ogni base algebrica ha cardinalità infinita. 
Vediamo il caso $X = (0,1)$.
Per trovare una base infinita, cerchiamo per ogni $N \in \N$, $f_1,\ldots , f_N \in L^p(0,1)$ tali che siano linearmente indipendenti.
Vale a dire, presi $\lambda_1,\ldots ,\lambda_N \in \R$ vale $\lambda_1 f_1 + \ldots +f_N = 0$ se solo se $\lambda_1 = \ldots = \lambda_N = 0$.

Ad esempio, definisco $f_i \coloneqq \One_{i/N, (i+1)/N}$ (questa costruzione si può riprodurre per ogni $N \in \N$).

Ricordiamo che, essendo $L^p(X)$ uno spazio metrico, dato $Y \subset L^p$ vale la seguente caratterizzazione:
\begin{center}
$Y$ è compatto $\longiff$ $Y$ è compatto per successioni $\longiff $ $Y$ chiuso e totalmente limitato.
\end{center}

\textbf{Osservazione.} $Y \subset L^p(X)$ è un sottoinsieme che eredita la norma $\norm{\cdot}_{L^p}$ :
\begin{center}
$Y$ è completo $\longiff$ $Y$ è chiuso.
\end{center}

\textbf{Osservazione.} In $L^p$ i sottoinsiemi chiusi e limitati non sono compatti!
In particolare le palle
%
$$
Y = \left\{ f \in L^p \mymid \norm{f}_{L^p} \leq 1 \right\}
$$
%
non sono compatte.

Ad esempio, mostriamo che in $L^p(0,1)$ le palle 
%
$$
B = \left\{ f \in L^p \mymid \norm{f}_{L^p} \leq 1 \right\}
$$
%
non sono compatte.
Per farlo, esibiamo una successione $\left\{ f_n \right\}_{n \in \N} \subset B$ che non ammette sottosuccessioni convergenti.
La costruiamo in modo che non abbia sottosuccessioni di Cauchy
%
$$
f_n \colon (0,1) \to \R, \quad \norm{f_n - f_m}_{L^p} \geq c_0 > 0 \; \forall n \neq m.
$$
%
Cerco $A_n \subset (0,1)$ tale che $\left| A_n \cap A_m \right| = 0$ per ogni $n \neq m$.
Definiamo $f_n$ come segue
%
$$
f_n(x) \coloneqq 
\begin{cases}
0 \quad  \text{se} \; x \in (0,1) \setminus (1 / (n+1), 1/ n) \\
c_n > 0 \quad \text{altrimenti}
\end{cases} 
$$
%
dove $c_n$ è tale che 
%
$$
\left( \int_{1 / n+1}^{1 / n} c_n^p  \right)^{1/p} = 1 \longiff 
c_n^p \cdot (1/n - 1/(n+1)) = 1 \longiff c_n^p = n \cdot (n+1).
$$
%
Calcoliamo ora $\norm{f_n - f_m}^p_{L^p}$ con $n \neq m$ :
%
$$
\int\limits_{\mathclap{0}}^{1} \left| f_n(x) - f_m(x) \right|^p \dd x = \int\limits_{\mathclap{(1/n,1/n+1) \cup (1/ m+1,1/m)}} \left| f_n - f_m \right|^p \dd x = \int\limits_{\mathclap{1 / n+1}}^{1 / n} \left| f_n \right|^p \dd x + \int\limits_{\mathclap{0}}^{1} \left| f_m \right|^p \dd x = 1 + 1 = 2.
$$
%

Si osserva che quanto detto sopra vale anche per $p = + \infty$.

\textbf{Esercizio.} [TO DO] Sia $E = \left\{ f \in L^1(1,+\infty) \mymid \left| f(x) \right| \leq 1 / x^2 \mquad \text{e} \;x \in [1,+\infty) \right\}$.

\begin{itemize}

\item $E$ è limitato in $L^1$?

\item $E$ è chiuso in $L^1$?

\item $E$ è compatto in $L^1$?

\end{itemize}

\textbf{Esercizio.} [TO DO] 
\begin{itemize}
\item Dire se $f_n(x) = x^n$, $n = 0,\ldots , N$ è un insieme di funzioni linearmente indipendenti in $L^p([0,1])$.

\item Dire se $\left\{ f_n \right\} \subset L^p(0,1)$ è compatta in $L^p(0,1)$.
\end{itemize}
\textit{Suggerimento.} Studiare il limite puntuale.

\subsection{Spazi $\ell^p$}

Prendiamo $X = \N$ e $\mu = \#$ la misura che conta i punti.

\textbf{Osservazione.} Definiamo
%
$$
\ell^p = L^p(\N, \#) = \left\{ \left( x_n \right)_{n \in \N} \mymid \sum_{n=0}^{+\infty} \left| x_n \right|^p < +\infty  \right\}
$$
con $p \geq 1$ e $p \neq +\infty$, e
%
$$
l^{\infty} = \left\{ \text{successioni limitate} \right\} = \left\{ \left( x_n \right) \mymid \sup_{n \in \N}\left| x_n \right| < +\infty \right\}.
$$
%

\textbf{Esempio} (di insieme non compatto in $\ell^1$). Consideriamo la successione $\left( e_i \right)$ definita come
%
$$
(e_i)_n \coloneqq 
\begin{cases}
0 \quad \text{se} \; n \neq i \\
1 \quad \text{se} \; n = i
\end{cases} 
$$
%
si osserva inoltre che le successioni così definite sono linearmente indipendenti e generano se sono infiniti.

\textbf{Esempio} (di insieme compatto in $\ell^1$). Sia $F = \left\{ (x_n)_n \in \ell^1 \mymid \left| x_n \right| \leq 1 / n^2 \quad \forall n \in \N \right\}$.
Noto subito che $F$ è limitato, infatti, presa
%
$$
\underline{x} = (x_n) \in F, \quad  \norm{\underline{x}}_{\ell^1} = \sum_{n=0}^{+\infty} \left| x_n \right| \leq
\sum_{n=0}^{+\infty} 1 / n^2 < +\infty.  
$$
%
$F$ è anche chiuso.

\textbf{Osservazione.} Data una successione $(\underline{x}^k) \subset \ell^1$, se $\underline{x}^k \xrightarrow{\ell^1} \underline{x}^{\infty}$, vuol dire che
%
$$
\norm{\underline{x}^k - \underline{x}^\infty}_{\ell^1} = \sum_{n = 0}^{+\infty}  \left| x_n^k - x_n^\infty \right| \xrightarrow{k} 0. 
$$
%
In particolare, per ogni $n \in \N$ fissato, $\lim_k (x_n^k - x_n^\infty) = 0$.

$F$ è chiuso perché se $(\underline{x}^k) \subset F$ e $\underline{x}^k \xrightarrow{\ell^1} \underline{x}^\infty$, allora per ogni $n \in \N$ vale 
%
$$
\left| x_n^k \right| \leq 1 / n^2 \quad \text{e} \quad \underbrace{\lim_{n \to +\infty} \left| x_n^k  \right|}_{x_n^\infty} \leq 1/n^2.
$$
%

Dimostriamo che è compatto per successioni.
Prendiamo $( \underline{x}^k ) \subset F$, ogni componente $x_n$ è equilimitata a meno di sottosuccessioni $x_n^{x_j}$ converge a $x_n^\infty$.
A meno di diagonalizzare, posso supporre che le successione $k_j$ non dipenda da $n$.
Otteniamo che $x_n^{k_j}$ sono dominate da $y = (1 / n^2)$. Concludiamo usando il teorema di Lebesgue.

% 
% Lezione del 14 Ottobre 2021
% 

\section{Complementi su approssimazioni di funzioni in $L^p$}

Sia $X$ misurabile in $\R^n$ con $\mu = \mathscr L^n$ su $X$, in precedenza abbiamo visto che

\textbf{Proposizione 3.} Le funzioni in $C_C(\R^n)$ \textit{ristrette a $X$} sono dense in $L^p$ se $p < +\infty$.

[TODO: la seguente osservazione è da rilocare probabilmente]

\textbf{Osservazione.} 
Le funzioni $C_C(\R^n)$ sono le funzioni a supporto compatto, dove il supporto è definito come la chiusura dell'insieme dei punti in cui la funzione è non zero
$$
\operatorname{supp}(f) := \overline{\{ x \mid f(x) \neq 0 \}}
$$
in quanto per le funzioni continue l'insieme $\{ x \mid f(x) \neq 0 \}$ è sempre aperto e dunque mai veramente compatto a parte quando è vuoto.

\textbf{Osservazione.}
Si vede facilmente che $C_C(\R^n) \subset L^p(\R^n)$.

\textbf{Domanda.} Vale un risultato analogo per le funzioni $C_C(X)$?

Notiamo che dato $X \subset \R^n$ le funzioni continue su $X$ hanno supporto compatto solo se $X$ è aperto in quanto il supporto ha veramente distanza non nulla dal bordo e possiamo estendere la funzione a $0$ fuori da $X$, altrimenti... [TODO: Esempio con un chiuso in cui le cose non fungono?]


[TODO: Disegnino]

\textbf{Proposizione 4.} 
Sia $X$ aperto di $\R^n, \mu = \mathscr L^n$ allora $C_C(X)$ è denso in $L^p$ per ogni $p < +\infty$

\textbf{Dimostrazione.}
\begin{itemize}
	\item
		$\mathscr S_C := \{ \text{funzioni semplici con supporto compatto in $X$} \}$ è denso in $L^p(X)$ per ogni $p < +\infty$.

	\item
		Dato $E$ relativamente compatto in $X$ esiste $f_n \in C_C(X)$ tale che $f_n \to \One_E$ in $L^p$ per ogni $p < +\infty$.
\end{itemize}

La Proposizione 3 non vale per $p = +\infty$, intuitivamente in quanto data $f \in L^\infty(X)$ discontinua, se trovassimo $f_n \to f$ in $L^\infty(X)$ con $f_n$ continue avremmo $f_n \to f$ \textit{uniformemente} e dunque $f$ continua.

\textbf{Fatto.} 
In generale vale che data $f \colon X \to \R$ misurabile, $\norm{f}_\infty \leq \sup_{x \in X} |f(x)|$ (detta anche \textit{norma del sup})

\textbf{Esercizio.} 
Se $X$ è aperto in $\R^n$ e $\mu = \mathscr L^n$ e $f \colon X \to \R$ continua, allora $\norm{f}_\infty = \sup_{x \in X} |f(x)|$.

\textbf{Soluzione.}
Se per assurdo $\exists x \in X$ tale che $\norm{f}_\infty < |f(x)|$ allora la continuità di $f$ implica che esiste un intorno di $x$ in cui $|f| > \norm{f}_\infty$ ma un intorno contiene una palla aperta di misura positiva \absurd

In particolare possiamo anche estenderci a $X \subseteq \R^n$ tali che ogni $A$ aperto relativamente a $X$ abbia misura positiva.

[TODO: Disegnino di $X$ quadrato e quadrato + una linea chiusa]

Per spiegare meglio il perché la Proposizione 3 non si estende al caso $p = +\infty$ consideriamo
$$
f(x) =
\begin{cases}
	1 & x \geq 0 \\
	0 & x < 0
\end{cases}
$$
e vediamo che $\nexists f_n \colon \R \to \R$ tale che $f_n \to f$ in $L^\infty$. 

Se esistesse $(f_n)_n$, allora sarebbe di Cauchy rispetto alla norma $\norm{\curry}_\infty$ allora per continuità $(f_n)_n$ è di Cauchy anche rispetto alla norma del sup $\implies f_n \to \tilde f$ uniformemente con $\tilde f$ continua, quindi $\tilde f = f$ quasi ovunque ma questo non è possibile per la $f$ definita sopra.

(In particolare dato $E = \{ x \mid f(x) = \tilde f(x) \}$, prendiamo $x_n, y_n \in E$ tali che $x_n \uparrow 0$ e $y_n \downarrow 0$ ma i limiti di $f$ sono $0$ e $1$ \absurd)

\textbf{Teorema.} (di Lusin)
Dato $X \subset \R^d, \mu = \mathscr L^d$ e data $f \colon X \to \R$ o $\R^m$ misurabile e $\epsilon > 0$, esiste $E$ aperto in $X$ con $|E| \leq \epsilon$ tale che $f$ è continua su $X \setminus E$ (la restrizione di $f$ a $X \setminus E$ è continua)

\textbf{Osservazione.} 
In generale $f$ può essere non continua in tutti i punti di $X$, infatti $E$ può essere denso e $X \setminus E$ avere parte interna vuota.

\textbf{Lemma.} (di estensione di Tietze) Dato $X$ spazio metrico e $C \subset X$ chiuso, $f \colon C \to \R$ continua allora $f$ si estende a una funzione continua su $X$.

Usando questo lemma possiamo rienunciare il teorema precedente come segue

\textbf{Teorema.} (di Lusin$'$)
Data $f \colon X \to \R$ misurabile e $\epsilon > 0$, $\exists E$ aperto con $|E| \leq \epsilon$ e $g \colon X \to \R$ continua tale che $f = g$ su $X \setminus E$, inoltre se $f \in L^p(X)$ e $p < +\infty$ si può anche chiuedere che $\norm{f - g}_p \leq \epsilon$.

\textbf{Dimostrazione.}
Basta trovare $E$ misurabile (per ottenere $E$ aperto si usa la regolarità della misura)
\begin{itemize}
	\item \textit{Caso 1}:
		$f \in L^1(X)$ e $|X| < +\infty$

		Abbiamo che $f \in L^1 \implies \exists f_n$ continue tali che $f_n \to f$ in $L^1 \implies f_n \to f$ in misura e per Severini-Egorov esiste $E$ tale che $|E| \leq \epsilon$ e $f_n \to f$ uniformemente su $X \setminus E \implies f$ è continua su $X \setminus E$.

	\item \textit{Caso 2}:
		$f$ qualunque misurabile e $|X| < +\infty$

		\textbf{Lemma.}
		Dati $X, \mathcal A, \mu$ con $\mu(X) < +\infty$ e data $f \colon X \to \R$ misurabile e $\epsilon > 0$ esiste $F$ misurabile con $\mu(F) \leq \epsilon$ tale che $f$ è limitata su $X \setminus F$.
		
		\textbf{Dimostrazione.}
		$\forall m > 0$ sia $F_m := \{ x \mid |f(x)| > m \}$ allora $F_m \downarrow \varnothing \implies \mu(F_m) \downarrow 0$ e quindi esiste $m$ tale che $\mu(F_m) \leq \epsilon$.

		Quindi data $f$ qualunque misurabile e $|X| < +\infty$ esiste $F$ misurabile tale che $|F| \leq \epsilon / 2$ e con $f$ limitata su $X \setminus F \implies f \in L^\infty(X \setminus F) \subset L^1(X \setminus F)$, dunque per il \textit{Caso 1} esiste $E$ misurabile tale che $|E| \leq \epsilon / 2$ e $f$ è continua su $X \setminus (E \cup F)$ e $\mu(E \cup F) \leq \epsilon$

	\item \textit{Caso 3}:
		$f$ qualunque misurabile

		Per ogni $n$ poniamo $X_n \coloneqq X \cap B(0, n)$ per il \textit{Caso 2} esistono $E_n$ misurabili con $|E_n| \leq \epsilon / 2^n$ tali che $f$ è continua su $X_n \setminus E_n$, infine prendo $E \coloneqq \bigcup_{n=1}^\infty E_n$ con $\mu(E) \leq \epsilon \implies f$ è continua su $X_n \setminus E$ per ogni $n \implies f$ è continua su $X \setminus E$. 

\end{itemize}
\qed

%
% Lezione dell'18 Ottobre 2021
%

\section{Appendice}

\textbf{Proposizione.} Siano $V,W$ spazi normati, $T \colon V \to W$ lineare.
Sono fatti equivalenti
\begin{enumerate}
\item $T$ è continua in $0$.

\item $T$ è continua.

\item $T$ è lipschitziana, cioè esiste una costante $c < +\infty$ tale che $\norm{Tv - Tv'}_W \leq \norm{v - v'}_V$.

\item esiste una costante $c$ tale che $\norm{Tv'} \leq c \norm{v}$ per ogni $v \in V$.

\item esiste una costante $c$ tale che $\norm{Tv}_W \leq c$ per ogni $v \in V$, $\norm{v}_V = 1$.
\end{enumerate}

\textbf{Dimostrazione.}
v) $\Rightarrow$ iv). Vale la seguente
%
$$
\norm{Tv}_W \underbrace{=}_{v = \lambda \tilde{v}, \norm{v}_V = 1} \left| \lambda \right| \norm{T \tilde{v}}_W \leq c \lambda = c \norm{v}_V \leq 1.
$$
%
iv) $\Rightarrow$ iii). Vale la seguente
%
$$
\norm{Tv - Tv'}_W = \norm{T(v - v')}_W \leq c \norm{v - v'}_W.
$$
%
iii) $\Rightarrow$ ii). \\
i) $\Rightarrow$ v). $T$ continua in $0$, dunque esiste $\delta > 0$ tale che
%
$$
\norm{Tv - T0}_W \leq 1 \quad \text{se} \quad \norm{v - 0}_V \leq \delta,
$$
%
cioè
%
$$
\norm{Tv} \leq 1 \quad \text{se} \quad \norm{v} \leq \delta,
$$
%
da cui segue che $\norm{Tv} \leq 1/ \delta$ se $\norm{v} \leq 1$.
\qed

\textbf{Osservazione.} Le costanti ottimali iii), iv), v) sono uguali e valgono
%
$$
c = \sup_{\norm{v}_V \leq 1} \norm{Tv}_W.
$$
%

\textbf{Esempi di utilizzo.}
\begin{enumerate}
\item Sia $X, \mathcal{A}, \mu$ coma al solito, con $\mu(X) < +\infty$.
Allora, dati $1 \leq p_1 < p_2 \leq +\infty$, vale
\begin{equation} \tag{$\star$} \label{eq:star_1}
L^{p_2}(X) \subset L^{p_1}(X).
\end{equation}
Inoltre, l'inclusione $i \colon L^{p_2}(X) \to L^{p_1}(X)$ è continua.

\textbf{Dimostrazione.} La dimostrazione di \eqref{eq:star_1} segue dalla stima
%
$$
\norm{u}_{p_1} \underbrace{\leq}_{\mathclap{\text{Holder generalizzato}}} \norm{\One_X}_q \norm{u}_{p_2} \quad \text{dove} \quad q = \frac{p_1 p_2}{p_2 - p_1}.
$$
%
Dove
%
$$
\norm{\One_X}_{\frac{p_1 p_2}{p_2 - p_1}} \norm{u}_{p_2} = \left( \mu(X) \right)^{\frac{1}{p_1} - \frac{1}{p_2}} \norm{u}_{p_2}.
$$
%
Quanto sopra soddisfa la condizione al punto iv).
\qed

\item L'applicazione $\ds L^1(X) \ni u \mapsto \int u \dd \mu \in \R$ è continua.

\textbf{Dimostrazione.} Infatti, vale
%
$$
\left| \int\limits_{\mathclap{X}} u \dd \mu \right| \leq \int\limits_{\mathclap{X}} \left| u \right| \dd \mu = \norm{u}_1.
$$
%
Quanto sopra soddisfa la condizione al punto iv).
\qed

\item Cosa possiamo dire invece dell'applicazione $\ds L^p(X) \ni u \mapsto \int u \dd \mu \in \R$?
Se $\mu(X) < +\infty$ la continuità segue dagli esempi i) e ii) sopra.
Se invece $\mu(X) = +\infty$? Per esempio $L^2(\R)$? [TO DO].
\end{enumerate}

\section{Convoluzione}

\textbf{Definizione.} Date $f_1,f_2 \colon  \R^d \to \R$ misurabili, il \textbf{prodotto di convoluzione} $f_1 \ast f_2$ è la funzione (da $\R^d$ a $\R$) data da
%
\begin{equation} \label{eq:star_def_convoluzione}
	f_1 \ast f_2(x) = \int\limits_{\mathclap{\R^d}} f_1(x-y) f_2(y) \dd y
	\tag{$\star$}
\end{equation}
%
\textbf{Osservazioni.}
\begin{enumerate}
\item La definizione \eqref{eq:star_def_convoluzione} è ben posta se $f_1,f_2 \geq 0$ ($f_1 \ast f_2(x)$ può essere anche $+\infty$).
In generale non è ben posta per funzioni a valori reali (non è detto che l'integrale esista).

\item Se $f_1 \ast f_2(x)$ esiste, allora $\ds f_1 \ast f_2(x) = f_2 \ast f_1(x)$, infatti
%
$$
f_1 \ast f_2 (x) 
= \int\limits_{\mathclap{\R^d}} f_1(x-y) f_2(y) \dd y 
% \underbrace{=}_{} 
= \left( 
{\footnotesize \begin{gathered}
	t \coloneqq x - y \\ 
	\dd t = \dd y
\end{gathered}}
\right) =
\int\limits_{\mathclap{\R^d}} f_1(t) f_2(x-t) \dd t 
= f_2 \ast f_1(x).
$$
%

\item È importante che $f_1,f_2$ siano definite su $\R^d$ e che la misura sia quella di Lebesgue.

In realtà, si può generalizzare quanto sopra rimpiazzando $(\R^d, L^d)$ con $(G,\mu)$, dove $G$ è un gruppo commutativo e $\mu$ una misura su $G$ invariante per traslazione. Per esempio, $\Z$ con la misura che conta i punti. Cioè $f_1,f_2 \colon \Z \to \R$, vale
%
$$
f_1 \ast f_2(n) \coloneqq \sum_{n \in \Z} f_1(n - m) f_2(m).
$$
%

\item Data $f$ distribuzione di massa (continua) su $\R^3$, il potenziale gravitazionale generato è
%
$$
v(x) = \int\limits_{\mathclap{y \in \R^d}} \frac{1}{\left| x - y \right|} \rho(y) \dd y
$$
%
cioè $v = g \ast \rho$, dove  $g (x) = 1 / \left| x \right|$ è il potenziale di una massa puntuale in $0$.

\item Se $X_1, X_2$ sono variabili aleatorie (reali) con distribuzione di probabilità continua $p_1,p_2$ e $X_1,X_2$ sono indipendenti, allora $X_1 + X_2$ ha distribuzione di probabilità $p_1 \ast p_2$. (Facile per $X_1,X_2$ in $\Z$).

\end{enumerate}

%
% Lezione dell'20 Ottobre 2021
%

% \textbf{Definizione.}
% Date $f_1, f_2 \colon \R^d \to \R$ misurabile allora il \textbf{prodotto di convoluzione} è dato da
% $$
% f_1 \ast f_2 (x) \coloneqq \int_{\R^d} f_1(x - y) f_2(y) \dd y
% $$
% e se $f_1$ e $f_2$ sono positive allora $f_1 \ast f_2(x) \in [0, +\infty]$. Ma ad esempio se prendiamo $f_1 = 1$ e $f_2 = \sin x$ con $d = 1$ allora $f_1 \ast f_2(x)$ non è definito per alcun $x$.

\textbf{Proposizione 1.}
Se $|f_1| \ast |f_2| (x) < +\infty$ allora $f_1 \ast f_2(x)$ è ben definito in quanto
$$
|f_1 \ast f_2(x)| \leq |f_1| \ast |f_2|(x)
$$
\textbf{Dimostrazione.}
Basta osservare che
$$
\int_{\R^d} |f_1(x - y) \ast f_2(y)| \dd y < +\infty 
\implies \int_{\R^d} f_1(x - y) f_2(y) \dd y
$$
e dunque esiste.
\qed

\textbf{Corollario 2.}
Se $|f_1| \ast |f_2| \in L^p(\R^d)$ con $1 \leq p \leq +\infty$ allora $f_1 \ast f_2(x)$ è ben definito per quasi ogni $x \in \R^d$ e $\norm{f_1 \ast f_2}_p \leq \norm{|f_1| \ast |f_2|}_p$.

\textbf{Dimostrazione.}
Segue subito dalla proposizione precedente.
\qed

\textbf{Teorema 3} \textit{(Disuguaglianza di Young per la convoluzione)}.
Se $f_1 \in L^{p_1}$ e $f_2 \in L^{p_2}$ e preso $r \geq 1$ tale che
\begin{equation}\label{eqn:conv_th3_cond}
	\frac{1}{r} = \frac{1}{p_1} + \frac{1}{p_2} - 1
	\tag{$\star$}
\end{equation}
allora $f_1 \ast f_2$ è ben definito quasi ovunque e
\begin{equation}\label{eqn:conv_th3_thesis}
	\norm{f_1 \ast f_2}_r \leq \norm{f_1}_{p_1} \cdot \norm{f_2}_{p_2}
	\tag{$\star\star$}
\end{equation}

\textbf{Osservazioni.}
\begin{itemize}
	\item 
		Nel caso di prima $1$ e $\sin x$ sono solo in $L^\infty$ infatti viene $r = -1$ e la disuguaglianza non ha senso.

	\item
		Supponiamo di avere $\norm{f_1 \ast f_2} \leq C \cdot \norm{f_1}_{p_1}^{\alpha_1} \cdot \norm{f_2}_{p_2}^{\alpha_2}$ allora vediamo che per ogni $f_1, f_2$ positiva deve valere necessariamente $\alpha_1 = \alpha_2 = 1$ e la condizione (\ref{eqn:conv_th3_cond}).

		\textbf{Dimostrazione.}
		Per ogni $\lambda > 0$ consideriamo $\lambda f_1$ e $f_2$, allora 
		$$
		\norm{(\lambda f_1) \ast f_2}_r = \norm{\lambda (f_1 \ast f_2)}_r = \lambda \norm{f_1 \ast f_2}_r
		$$
		ma abbiamo anche
		$$
		\norm{(\lambda f_1) \ast f_2}_r \leq C \cdot \norm{f_1}_{p_1}^{\alpha_1} \cdot \norm{f_2}_{p_2}^{\alpha_2} = C \cdot \lambda^{\alpha_1} \norm{f_1}_{p_1} \cdot \norm{f_2}_{p_2}
		$$
		A questo punto richiediamo anche che $f_1$ e $f_2$ siano tali che $\norm{f_1}_{p_1}, \norm{f_2}_{p_2} < +\infty$ e $\norm{f_1 \ast f_2} > 0$ (questo possiamo farlo in quanto basta prendere $f_1 = f_2 = \One_B$ con $B$ una palla, nel caso segue proprio che $f_1 \ast f_2 (x) > 0$ se $|x| < 1$).

		Data $f \colon \R^d \to \R$ e $\lambda > 0$ poniamo $R_{\lambda} f(x) \coloneqq f(\frac{x}{\lambda})$ allora abbiamo
		$$
		\norm{(R_\lambda f_1) \ast (R_\lambda f_2)}_r 
		= \lambda^{d \left( 1 + \frac{1}{r} \right)} \norm{f_1 \ast f_2}_r 
		$$
		ma anche
		$$
		\norm{(R_\lambda f_1) \ast (R_\lambda f_2)}_r 
		\leq C \cdot \norm{R_\lambda f_1}_{p_1} \cdot \norm{R_\lambda f_2}_{p_2}
		= \lambda^{d(\frac{1}{p_1} + \frac{1}{p_2})} \cdot \norm{f_1}_{p_1} \cdot \norm{f_2}_{p_2}
		$$
		dunque sicuramente abbiamo $\lambda^{d \left(1 + {1 / r} \right)} \leq C \cdot \lambda^{d\left( {1 / p_1} + {1 / p_2} \right)}$ per ogni $\lambda > 0$ e quindi $1 + {1 / r} = {1 / p_1} + {1 / p_2} \iff$ (\ref{eqn:conv_th3_cond}).
		\qed

	\item
		$\norm{R_\lambda f}_p = \lambda^{d / p} \norm{f}_p$ ed in realtà possiamo ricavare l'esponente $d / p$ per \textit{analisi dimensionale}\footnote{Ovvero studiando le potenze delle unità di misura delle varie quantità.}\footnote{In particolare ad Istituzioni di Analisi si vedono le disuguglianze di Sobolev ed anche in quel caso tutte le condizioni sugli esponenti si riescono a ricavare per analisi dimensionale...}. Consideriamo l'espressione
		$$
		\norm{f}_p^p = \int_{\R^d} f(x) \dd x
		$$
		se $f(x)$ è una \textit{quantità adimensionale} e $\int_{\R^d} f \dd x$ ha dimensione di una \textit{lunghezza} $L^d$ allora $\norm{f}_p$ ha dimensione di $L^{d / p}$.

		Similmente per ottenere $\norm{R_\lambda(f_1 \ast f_2)}_r = \lambda^{d(1 + 1 / r)} \norm{f_1 \ast f_2}_r$ basta osservare che nell'espressione
		$$
		f_1 \ast f_2 (x) = \int_{\R^d} f_1(x - y) f_2(y) \dd y
		$$
		dunque $f_1 \ast f_2 (x)$ ha dimensione $L^d$ da cui
		$$
		\norm{f_1 \ast f_2}_r = \bigg( \int_{\R^d} \underbrace{|f_1 \ast f_2|^r}_{L^{dr}} \underbrace{\dd x}_{L^d} \bigg)^{1 / r}
		$$
		e quindi $\norm{f_1 \ast f_2}_r$ ha dimensione di $L^{d(1 + 1/r)}$.
\end{itemize}

\textbf{Dimostrazione Teorema 3.}
Per via del Corollario 2. ci basta dimostrare (\ref{eqn:conv_th3_thesis}) se $f_1, f_2 \geq 0$.
\begin{itemize}
	\item
		\textit{Caso facile.} Se $p_1 = p_2 = 1$ e $r = 1$
		$$
		\begin{aligned}
			\norm{f_1 \ast f_2}_1
			&= \int f_1 \ast f_2 (x) \dd x 
			= \iint f_1(x - y) f_2(y) \dd y \dd x 
			= \int f_2(y) \int f_1(x - y) \dd x \dd y = \\
			&= \int \norm{f_1}_1 \cdot f_2(y) \dd y 
			= \norm{f_1}_1 \cdot \norm{f_2}_1
		\end{aligned}
		$$

	\item
		\textit{Caso leggermente meno facile.} Se $p_1 = p, p_2 = 1$ e $r = p$.
		Vogliamo vedere che
		$$
		\norm{f_1 \ast f_2}_p \leq \norm{f_1}_p \cdot \norm{f_2}_1
		$$
		allora
		$$
		\begin{aligned}
			\norm{f_1 \ast f_2}_p
			&= \int_{\R^d} (\underbrace{f_1 \ast f_2}_{h})^p \dd x
			= \int h \cdot h^{p-1} \dd x 
			= \iint f_1(x - y) f_2(y) h^{p-1}(x) \dd y \dd x = \\
			&= \iint f_1(y - x) h^{p-1}(x) \dd x f_2(y) \dd y 
			\overset{\text{H\"older}}{\leq} 
			\int \norm{f_1(y - \curry)}_p {\| h^{p-1} \|}_{p'} f_2(y) \dd y
		\end{aligned}
		$$
		con $p'$ esponente coniugato a $p$. Inoltre notiamo che $\norm{f_1(y - \curry)}_p = \norm{f_1}$ per invarianza di $\mathscr L^d$ per riflessioni e traslazioni, infine otteniamo
		$$
		= \norm{f_1}_p {\| h^{p-1} \|}_{p'} \norm{f_2}_1
		= \norm{f_1}_p \norm{h}_{p'}^{p-1} \norm{f_2}_1
		$$
		$\implies \norm{f_1 \ast f_2}_p^p \leq \norm{f_1 \ast f_2}_p^{p-1} \norm{f_1}_p \norm{f_2}_1 \implies \norm{f_1 \ast f_2}_p \leq \norm{f_1}_p \norm{f_2}_1$. Questo però solo nel caso in cui valga $0 < \norm{f_1 \ast f_2}_p < +\infty$, resterebbero da controllare i due casi in cui la norma è $0$ oppure $+\infty$, il primo è ovvio, il secondo invece si fa per approssimazione e passando al limite.

		Consideriamo $f_1, f_2$ e approssimiamole con $f_{1,n}, f_{2,n}$ limitate a supporto compatto, allora vale $\norm{f_{1,n} \ast f_{1,n}}_p \leq \norm{f_{1,n}}_p \cdot \norm{f_{2,n}}_1$ e passando al limite si ottiene la tesi. In particolare possiamo costruire le $f_n$ come
		$$
		f_n(x) \coloneqq (f(x) \cdot \One_{\mathcal B(0, n)}(x)) \land n
		$$

		\textbf{Osservazione.}
		Se $f_2 \geq 0$ e $\int f_2 \dd x = 1$ allora $\norm{f_1 \ast f_2}_p \leq \norm{f_1}_p$ è una versione semplificata della proposizione precedente, in particolare la dimostrazione si semplifica in quanto possiamo pensare a $f_2$ come distribuzione di probabilità e quindi $f_1 \ast f_2$ è una ``media pesata'' delle traslazioni di $f_1$ o più precisamente una combinazione convessa ``integrale''.

	\item
		\textit{Caso generale.} Non lo facciamo perché servono mille mila parametri e non è troppo interessante.
\end{itemize}
\qed

\textbf{Teorema 4.}
Se $p_1$ e $p_2$ sono coniugati e $r = +\infty$ abbiamo un risultato più forte ovvero valgono
\begin{enumerate}
	\item \label{item:20ott_th4_1} 
		$f_1 \ast f_2(x)$ è ben definito per ogni $x \in \R^d$

	\item \label{item:20ott_th4_2}
		$|f_1 \ast f_2(x)| \leq \norm{f_1}_{p_1} \norm{f_2}_{p_2}$

	\item \label{item:20ott_th4_3} 
		$f_1 \ast f_2$ è uniformemente continua

	\item \label{item:20ott_th4_4}
		Se $1 < p_1, p_2 < +\infty$ allora $f_1 \ast f_2 \to 0$ per $|x| \to +\infty$
\end{enumerate}

\textbf{Dimostrazione \ref{item:20ott_th4_1} e \ref{item:20ott_th4_2}.}
Seguono subito da (\ref{eqn:conv_th3_cond}) per $f_1, f_2 \geq 0$ (con il Corollario 2.), se $f_1, f_2 \geq 0$ allora
$$
f_1 \ast f_2 (x) 
= \int_{\R^d} f_1(x - y) f_2(y) \dd y 
\leq \norm{f_1(x - \curry)}_{p_1} \norm{f_2}_{p_2} 
= \norm{f_1}_{p_1} \norm{f_2}_{p_2}
$$

\textbf{Proposizione 5.}
Data $f \in L^p(\R^d)$ con $p < +\infty$ la mappa
$$
\begin{array}{cccc}
	\tau_h f : & \R^d & \to & L^p(\R^d) \\
	& h & \mapsto & f(\curry - h)
\end{array}
$$
è continua.

\textbf{Lemma 6.}
Lo spazio $C_0(\R^d) = \{ f \colon \R^d \to \R \text{ continue con } f(x) \to 0 \text{ per } |x| \to 0 \}$ è chiuso rispetto alla convergenza uniforme.

\textbf{Dimostrazione \ref{item:20ott_th4_3}.} 
Supponiamo $p_1 < +\infty$ allora
$$
\begin{aligned}
	|f_1 \ast f_2(x + h) - f_1 \ast f_2(x)|
	&\leq \int |f_1(x + h - y) - f_1(x - y)| \cdot |f_2(y)| \dd y \\
	&\leq \norm{f_1(x + h - \curry) - f(x - \curry)}_{p_1} \norm{f_2}_{p_2} \\
	&= \norm{\tau_h f_1 - f_1}_{p_2} \norm{f_2}_{p_2}
\end{aligned}
$$
\qed

%
% Lezione del 25 Ottobre 2021
%

% @aziis98: Secondo me possiamo rilocarle abbastanza le cose di questa lezione boh
\section{Aggiunte sulle lezioni precedenti}

\textbf{Proposizione.}
Data $f \in L^p(\R^d)$ con $1 \leq p < +\infty$ allora la funzione $\tau_h f \colon \R^d \to L^p(\R^d)$ data da $\tau_h f(x) \coloneqq f(x - h)$ è continua.

\textbf{Dimostrazione.}
Per prima cosa notiamo che basta vedere solo la continuità in $0$ in quanto
$$
\tau_{h'} f - \tau_h f = \tau_{h} (\tau_{h' - h} f - f) 
\implies \norm{\tau_{h'} f - \tau_{h} f}_p = \norm{\tau_{h' - h} f - f}_p
$$
dimostriamo ora la proposizione in due passi
\begin{itemize}
	\item
		\textit{Caso 1:} $f \in C_C(\R^d)$
		$$
		\norm{\tau_h f - f}_p^p 
		= \int_{\R^d} |f(x - h) - f(x)|^p \dd x \xrightarrow{|h| \to 0} 0
		$$
		per convergenza dominata, verifichiamo però che siano rispettate le ipotesi
		\begin{enumerate}
			\item
				La convergenza puntuale, ovvero $|f(x - h) - f(x)|^p \xrightarrow{|h| \to 0} 0$ segue direttamente dalla continuità di $f$.
			\item
				Come dominazione invece usiamo $|f(x - h) - f(x)|^p \leq (2 \norm{f}_\infty)^p \cdot \One_{\mathcal B(0, R + 1)}$ usando che $f \in C_C \implies \operatorname{supp}(f) \subset \overline{B(0, R)}$ e poi che 
				$$
				\operatorname{supp}(f(\curry - h) - f(\curry)) \subset \overline{\mathcal B(0, R + |h|)}
				$$
				infine se $|h| < 1$ come raggio ci basta prendere $R + 1$.
		\end{enumerate}
	\item 
		\textit{Caso 2:} $f$ qualunque
		Dato $\epsilon > 0$ prendiamo $g \in C_C(\R^d)$ tale che $\norm{g - f} \leq \epsilon$ allora aggiungiamo a sottraiamo $g + \tau_h g$ e raggruppiamo in modo da ottenere
		$$
		\begin{gathered}
			\tau_h f - f = \tau_h(f - g) + (\tau_h g - g) + (g - f) \\
			\implies \norm{\tau_h f - f}_p 
			\leq \underbrace{\norm{\tau_h(f - g)}_p}_{\leq \epsilon} 
			+ \norm{\tau_h g - g}_p
			+ \underbrace{\norm{g - f}_p}_{\leq \epsilon} 
			\leq 2 \epsilon + \underbrace{\norm{\tau_h g - g}_p}_{\to 0 \text{ per \textit{Caso 1}}}
		\end{gathered}
		$$
		dunque $\limsup_{|h| \to 0} \norm{\tau_h f - f}_p \leq 2\epsilon$ ma per arbitrarietà di $\epsilon$ otteniamo anche che $\norm{\tau_h f - f}_p \to 0$ per $|h| \to 0$.
\end{itemize}
\qed

\textbf{Teorema.}
Siano $f_1 \in L^{p_1}(\R^d)$ e $f_2 \in L^{p_2}(\R^d)$ con $p_1$ e $p_2$ esponenti coniugati, allora $f_1 \ast f_2$ è definita per ogni $x$ e uniformemente continua e
$$
\forall x \quad |f_1 \ast f_2(x)| \leq \norm{f_1}_{p_1} \cdot \norm{f_2}_{p_2}
$$

\textbf{Dimostrazione.}
Prendiamo $f_{1,n}, f_{2, n} \in C_C(\R^d)$ tali che $f_{1, n} \to f_1$ in $L^{p_1}$ e $f_{2, n} \to f_2$ in $L^{p_2}$.
\begin{itemize}
	\item 
		Per prima cosa notiamo che $f_{1,n} \ast f_{2,n}$ ha supporto limitato, infatti se $\supp(f_{i,n}) \subset \overline{\mathcal B(0, r_{i,n})}$ per $i = 1, 2$ allora
		$$
		\supp(f_{1,n} \ast f_{2,n}) \subset \overline{\mathcal B(0, r_{1,n} + r_{2,n})}
		$$
		e basta notare che l'espressione
		$$
		f_1 \ast f_2(x) = \int_{\R^d} f_1(x - y) f_2(y) \dd y
		$$
		ha integranda nulla per ogni $y$ se $|x| \geq r_{1,n} + r_{2,n}$.
	
	\item
		Vediamo che $f_{1,n} \ast f_{2,n} \to f_1 \ast f_2$ uniformemente
		$$
		f_{1,n} \ast f_{2,n} - f_1 \ast f_2 
		= (f_{1,n} - f_1) \ast f_{2,n} - f_1 \ast (f_{2,n} - f_2)
		$$
		$$
		\begin{aligned}
			\norm{f_{1,n} \ast f_{2,n} - f_1 \ast f_2}_p
			&\leq \norm{(f_{1,n} - f_1) \ast f_{2,n}}_\infty - \norm{f_1 \ast (f_{2,n} - f_2)}_\infty \\
			&\leq 
			\underbrace{\norm{f_{1,n} - f_1}_{p_1}}_{\to 0}
			\cdot \underbrace{\norm{f_{2,n}}_{p_2}}_{\to \norm{f_2}_{p_2}}
			+ \underbrace{\norm{f_1}_{p_1}}_{\text{cost.}}
			\cdot \underbrace{\norm{f_{2,n} - f_2}_{p_2}}_{\to 0}
			\to 0
		\end{aligned}
		$$

	\item 
		$C_0(\R^d)$ è chiuso per convergenza uniforme [TODO: da fare per esercizio]
\end{itemize}

\section{Derivata e Convoluzione}

\textbf{Osservazione.}
Osserviamo che la convoluzione si comporta bene con l'operatore di traslazione definito precedentemente, infatti $\tau_h (f_1 \ast f_2) = (\tau_h f_1) \ast f_2$ in quanto
$$
f_1 \ast f_2 (x - h) 
= \int f_1(x - h - y) \cdot f_2(y) \dd y = \int \tau_h f(x - y) \cdot f_2(y) \dd y
= (\tau_h f_1) \ast f_2
$$
quindi ``formalmente'' possiamo calcolare il seguente rapporto incrementale
$$
\frac{\tau_h(f_1 \ast f_2) - f_1 \ast f_2}{h}
= \frac{\tau_h f_1 - f_1}{h} \ast f_2
\implies (f_1 \ast f_2)' = (f_1)' \ast f_2
$$

Vediamo ora di formalizzare questo risultato

\textbf{Teorema.}
Dati $p_1$ e $p_2$ esponenti coniugati
\begin{itemize}
	\item se $f_1 \in C^1(\R^d)$ allora $f_1, \nabla f_1 \in L^{p_1}(\R^d)$

	\item se $f_2 \in L^{p_2}(\R^d)$ allora $f_1 \ast f_2 \in C^1$ con $\nabla(f_1 \ast f_2) = (\nabla f_1) \ast f_2$ cioè
		$$
		\frac{\pd}{\pd x}(f_1 \ast f_2) = \left( \frac{\pd f_1}{\pd x_i} \right) \ast f_2 
		\quad
		\text{per } i = 1, \dots, d
		$$

\end{itemize}

\textbf{Dimostrazione.}
\begin{itemize}
	\item $d = 1$:
		Sappiamo che $f_1 \ast f_2$ è continua e $f_1' \ast f_2$ è continua, vediamo che coincidono usando il teorema fondamentale del calcolo integrale, infatti $(f_1 \ast f_2)' = f_1' \ast f_2$ segue da
		$$
		\int_a^b f_1' \ast f_2 \dd x = f_1 \ast f_2(b) - f_1 \ast f_2(a)
		\quad \forall a < b
		$$
		ed in effetti
		$$
		\begin{aligned}
			\int_a^b f_1 \ast f_2 (x) \dd x
			&= \int_a^b \int_{-\infty}^\infty f_1'(x - y) f_2(y) \dd y \dd x \\
			&\overset{\text{($*$)}}{=} \int_{-\infty}^\infty \int_a^b f_1'(x - y) \dd x \cdot f_2(y) \dd y \\
			&= \int_{-\infty}^\infty (f_1(b - y) - f_1(a - y)) \cdot f_2(y) \dd y \\
			&= \int_{-\infty}^\infty f_1(b - y) f_2(y) \dd y - \int_{-\infty}^\infty f_1(a - y) f_2(y) \dd y \\
			&= f_1 \ast f_2(b) - f_1 \ast f_2(a) \\
		\end{aligned}
		$$
		in particolare in ($*$) stiamo usando Fubini-Tonelli in quanto
		$$
		\int_a^b \int_{-\infty}^\infty |f_1'(x-y)| \cdot |f_2(y)| \dd y
		\leq \int_a^b \norm{f_1'(x - \curry)}_{p_1} \cdot \norm{f_2}_{p_2} \dd x 
		= \norm{f_1'}_{p_1} \cdot \norm{f_2}_{p_2} \cdot (b - a)
		$$

	\item
		per $d > 1$ dato $i = 1, \dots, d$ basta semplicemente considerare le proiezioni infatti
		$$
		\int_a^b \frac{\pd f_1}{\pd x_i} \ast f_2 (x_1, \dots, \overset{\text{($i$)}}{t}, \dots, x_d) \dd t
		= f_1 \ast f_2 (x_1, \dots, \overset{\text{($i$)}}{b}, \dots, x_d) - f_1 \ast f_2 (x_1, \dots, \overset{\text{($i$)}}{a}, \dots, x_d)
		$$
\end{itemize}

\textbf{Corollario.}
Data $f_1 \in C_C^\infty(\R^d)$ (da cui segue $\nabla^k \in L^q(\R^d)$ per ogni $k = 0, 1, \dots$ e $1 \leq q < +\infty$) e $f_2 \in L^p(\R^d)$ allora $f_1 \ast f_2 \in C^\infty(\R^d)$ (anzi $\nabla^k(f_1 \ast f_2) \in C_0(\R^d)$ per ogni $k$) e vale la formula nota\footnote{Vista in termini di gradienti la formulazione è più compatta ma non poi così intuitiva, bisognerebbe definire la convoluzione tre una funzione a valori vettoriali ed uno scalare etc... Altrimenti basta scrivere le singole identità usando \textit{derivate parziali e multiindici}.}
$$
\nabla^k (f_1 \ast f_2) = (\nabla^k f_1) \ast f_2
$$

\textbf{Dimostrazione.}
Dimostriamo il corollario per approssimazione usando il seguente teorema

Per prima cosa definiamo data $g \colon \R^d \to \R$ e $\delta \neq 0$ poniamo
$$
\sigma_\delta g(x) \coloneqq \frac{1}{\delta^d} g\left( \frac{x}{\delta} \right)
$$
e notiamo che questa trasformazione preserva la norma $L^1$.

[TODO: Disegnino di $\sigma_{\frac{1}{2}} g$]

\textbf{Teorema.}
Data $g \in L^p(\R^d)$ e $g \in L^1(\R^d)$ con $1 \leq p < +\infty$ e posto
$$
m \coloneqq \int_{\R^d} g(x) \dd x
$$
allora $f \ast \sigma_\delta g \xrightarrow{\delta \to 0} m f$ in $L^p(\R^d)$.

\textbf{Osservazione.}
Se $g_2 \geq 0$ con $\int g \dd x = 1$ (dunque $g$ distribuzione di probabilità) allora $f \ast g$ possiamo pensarla come media pesata di traslate di $f$, dunque facendo $f \ast \sigma_\delta g$ stiamo pesando sempre di più i valori delle traslate vicino a $0$. 

Inoltre per $p = +\infty$ non vale ed il controesempio è sempre il solito.

\textbf{Dimostrazione.}
Per ora consideriamo $g$ generica e ripercorriamo una dimostrazione simile a quella fatta per la disuguaglianza di Young [TODO: ricontrollare: o Minkowski??]
$$
\begin{aligned}
	\norm{f \ast g - m f}_p^p 
	&= \int_{\R^d} {\underbrace{|f \ast g - m f|}_h}^p \dd x \\
	&= \int |f \ast g - m f| \cdot h^{p-1} \dd x \\
	&= \int \left| \int \left( f(x - y) g(y) - f(x) \int g(y) \right) \dd y \right| \cdot h^{p-1}(x) \dd x \\
	&\leq \int \int |f(x - y) - f(x)| \cdot |g(y)| \dd y \cdot h^{p-1}(x) \dd x \\
	&\overset{\text{($*$)}}{=} \int \left(\int |f(x - y) - f(x)| h^{p-1}(x) \dd x \right) |g(y)| \dd y
\end{aligned}
$$
dove in ($*$) abbiamo usato Fubini-Tonelli, ora prendiamo $q$ tale che $1/p + 1/q = 1$ allora per H\"older abbiamo
$$
\begin{aligned}
	&\leq \int \norm{f(\curry - y) - f(\curry)}_p \| h^{p-1} \|_q \cdot |g(y)| \dd y \\
	&= \norm{h}_p^{p-1} \int_{\R^d} \norm{\tau_y f - f}_p \cdot |g(y)| \dd y \\
\end{aligned}
$$
dunque abbiamo ricavato che
$$
\norm{f \ast g - m f}_p^p 
\leq \norm{f \ast g - m f}_p^{p-1} \int_{\R^d} \norm{\tau_y f - f}_p \cdot |g(y)| \dd y
$$
ed ora applicando questa stima a $\sigma_\delta g$ invece che a $g$ otteniamo
$$
\norm{f \ast \sigma_\delta g - m f}_p
\leq \int_{\R^d} \norm{\tau_y f - f}_p \cdot |\sigma_\delta g(y)| \dd y
$$
infine ponendo $z = y / \delta$ e $\dd z = 1/\delta^d \dd y$ e sostituendo nell'integrale
$$
= \int_{\R^d} \norm{\tau_{\delta z} f - f}_p \cdot |\sigma_\delta g(y)| \dd y \xrightarrow{\delta \to 0} 0
$$
per \textit{convergenza dominata}, verifichiamone le ipotesi
\begin{enumerate}
	\item La convergenza puntuale segue in quanto $\norm{\tau_{\delta z} f - f}_p \xrightarrow{\delta \to 0} 0$ per ogni $z$.
	\item Come dominazione prendiamo $2 \norm{f}_p \cdot |g| \in L^1$.
\end{enumerate}
\qed

\textbf{Corollario.}
Sia $g \in C_C^\infty(\R^d)$ con $\int g \dd x = 1$ e $f \in L^p(\R^d)$ e $1 \leq p < +\infty$ allora $\sigma_\delta g \ast f \xrightarrow{\delta \to 0} f$ in $L^p(\R^d)$ e $\sigma_\delta g \ast f \in C^\infty(\R^d)$.














































\chapter{Spazi di Hilbert}

% TODO

\chapter{Serie di Fourier}

% TODO

\chapter{Applicazioni della serie di Fourier}

% TODO

\chapter{Trasformata di Fourier}

% TODO

\chapter{Funzioni armoniche}

% TODO

\chapter{Integrazione di superfici}

% TODO

\newpage

\section{Indice Analitico}

Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod
tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam,
quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo
consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse
cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non
proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

\begin{multicols*}{2}

\makebox[3cm][l]{\absurd} Assurdo

\makebox[3cm][l]{\absurd} Assurdo

\makebox[3cm][l]{\absurd} Assurdo

\makebox[3cm][l]{\absurd} Assurdo

\vfill\null\columnbreak

\makebox[3cm][l]{\absurd} Assurdo

\makebox[3cm][l]{\absurd} Assurdo

\makebox[3cm][l]{\absurd} Assurdo

\makebox[3cm][l]{\absurd} Assurdo

\end{multicols*}

\section*{Esempi di figure}

\subsection*{Semplici}

Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod
tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam,
quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.

% Moralmente "example" corrisponde ad un file "src/figures/example.svg", in realtà la magia è che "example" diventa "example.pdf_tex" attraverso "\inputfigure" e poi quello il latex lo va a cercare dentro ".cache/figures/.pdf_tex/" come impostato in "prelude.tex".
\begin{figure}[h]
	\centering
	\inputfigure{example} 
\end{figure}

Duis aute irure dolor in reprehenderit in voluptate velit esse
cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non
proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

\subsection*{Wrappate}

Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod
tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam,
quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.

% La pagina del file "example.svg" è larga 300pt e qui sotto va lo stesso valore, per motivi estetici i due vspace negativi riducono un po' il margine di default che sta sopra e sotto l'ambiente "wrapfigure".
\begin{wrapfigure}{r}{300pt}
	\centering
	\vspace{-1.5\baselineskip}
	\inputfigure{example}
	\vspace{-2.5\baselineskip}
\end{wrapfigure}

Duis aute irure dolor in reprehenderit in voluptate velit esse
cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non
proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod
tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam,
quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo
consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse
cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non
proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

\subsection*{Con caption o descrizione}

Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod
tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam,
quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.

\begin{figure}[h]
	\centering
	\inputfigure{example}
	\caption{
		Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod
		tempor incididunt ut labore et dolore magna aliqua.
	}
\end{figure}

Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod
tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam,
quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.

\begin{wrapfigure}{r}{300pt}
	\centering
	\vspace{-1.5\baselineskip}
	\inputfigure{example}
	{\footnotesize
		Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod
		tempor incididunt ut labore et dolore magna aliqua.
	}
	\vspace{-1\baselineskip}
\end{wrapfigure}

Duis aute irure dolor in reprehenderit in voluptate velit esse
cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non
proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod
tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam,
quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo
consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse
cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non
proident, sunt in culpa qui officia deserunt mollit anim id est laborum.


\end{document}
